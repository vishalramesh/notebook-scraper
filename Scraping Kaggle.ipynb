{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import ast\n",
    "import cssselect\n",
    "import urllib\n",
    "import requests\n",
    "import pprint\n",
    "import math\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.plotting import figure\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "from lxml import html\n",
    "from selenium.webdriver import Chrome, ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "pp = pprint.PrettyPrinter(indent=4).pprint\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver = 'chromedriver_win32/chromedriver.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Chrome(webdriver)#, options=chrome_options)\n",
    "url = \"https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/kernels\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ActionChains(driver)\n",
    "driver.find_element_by_class_name(\"dataset-header-v2__title\").click()\n",
    "while (driver.find_element_by_class_name(\"smart-list__message\").text != 'No more notebooks to show'):\n",
    "    actions.key_down(Keys.PAGE_DOWN).perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID-19 Case Study - Analysis, Viz & Comparisons\n",
      "CoronaWhy.org - Global Collaboration (join slack)\n",
      "Browsing research papers with a BM25 search engine\n",
      "CORD-19: Explore Drugs Being Developed\n",
      "Topic Modeling: Finding Related Articles\n",
      "\"Learning\" Medicine with Word Embeddings ‚öïÔ∏èüíäüíâ\n",
      "COVID-19 Transmission and incubation\n",
      "Visualization of Virus Origin & Genetic Evolution\n",
      "Air Temperature and COVID-19\n",
      "Anserini+BERT-SQuAD for context corpus search\n",
      "COVID-19 Four different epidemic situations\n",
      "covid-19-incubation-time\n",
      "A CORD19 Research Paper Search Engine\n",
      "Age Dependent Incubation Period\n",
      "Asking questions with a BM25/BERT\n",
      "Corona Virus Data Visualization\n",
      "3D World Heat Map of Cumulative Confirmed Case\n",
      "Exploratory Data Analysis covid-19 from eCDC\n",
      "CORD-19 Metadata Enrich [2/x]: Altmetric API\n",
      "Convert COVID-19 papers to Entity Vectors\n",
      "CORD-19 Topic Modelling\n",
      "NLP Text Mining - Disease behavior\n",
      "COVID-2019-ID Paper version\n",
      "CORD-19 Analysis with Sentence Embeddings\n",
      "Utilizing BioBERT for K-means Topic Clustering\n",
      "A Brief Talk on COVID-19\n",
      "COVID-19 Literature Clustering\n",
      "SciBERT Embeddings\n",
      "CORD-19: EDA, parse JSON and generate clean CSVüßπ\n",
      "covid-19 research paper language model\n",
      "Creating a Good Analytics Report\n",
      "COVID-19 Dataset : Gaining actionable insights üìä\n",
      "covsum\n",
      "Languages...\n",
      "Abstract Summarization with Transformers & BART\n",
      "üò∑Mining COVID-19 scientific papersü¶†\n",
      "CORD-19 Solution Toolbox\n",
      "CORD : Tools and Knowledge graphs\n",
      "COVID-19 text mining\n",
      "CORD-19 Match articles to tasks w/ Doc2Vec\n",
      "COVID-19 Analysing Growth Factor & Inflection\n",
      "COVID-19 - Temperature, Air Travel & Transmission\n",
      "A few peek\n",
      "CoronaVirus (COVID-19) Outbreak Data Analysis\n",
      "CORD-19-LDA-Topic-modeling-reccomendation-system\n",
      "CORD-19:Understanding papers with TextAnalyticsüî¨\n",
      "COVID19_Italy_PatientZeros\n",
      "CORD-19 Challenge: Titles topic modelling\n",
      "CORD-19 - Data extraction functions\n",
      "COVID-19 Thematic tagging with Regular Expressions\n",
      "A Comprehensive Resource Notebook For Beginners\n",
      "Most Common Words in the CORD-19 Dataset\n",
      "Hyperion\n",
      "kernel4a6616c22b\n",
      "Country-Based Study on COVID-19\n",
      "incubation_pediatric\n",
      "CORD-19: Create Dataframe\n",
      "abstracts clustering, LDA, NMF, SciBERT embeddings\n",
      "Clean Metadata file\n",
      "summary page COVID-19 risk factors\n",
      "COVID-19 - AutoComplete Search Bar\n",
      "COVID-2019-ID\n",
      "CORD-19 : FastText words clustering\n",
      "Create Corona .csv File\n",
      "COVID-19-BERT-ResearchPapers-Semantic-Search\n",
      "PySpark DataFrame Preprocessing for CORD-19\n",
      "COVID-19 Genome Variations\n",
      "COVID 19- TASKS FILTERING\n",
      "COVID-19-xray-DL\n",
      "World Covid-19 EDA\n",
      "COVID EDA: Initial Exploration Tool\n",
      "incubation_times_mean\n",
      "COVID-19 CT-Scan & Xray CNN Detector\n",
      "COVID-19: Knowledge Graph (Starter)\n",
      "Epidemiological curves using ECDC data\n",
      "CORD-19 Metadata Evaluation\n",
      "fatality and cure rate\n",
      "COVID19\n",
      "Most mentioned antivirals\n",
      "Covid-19 Mentioned Drugs Analysis Vol 2.0\n",
      "BioBERT+CorEx Topic Search\n",
      "ElasticSearch/SciBERT ensemble\n",
      "A references-based atlas of COVID-19 research\n",
      "Combine_Final_Graph\n",
      "CORD-19 Metadata Enrichment [1/x]\n",
      "Consolidating Effects of Risk Factors on COVID-19\n",
      "COVID-19 - Top Scholarly Journals\n",
      "LDA & Information Visualization from CORD-19\n",
      "Vaccine data filter\n",
      "Map Search of Places in CORD-19 Full Text\n",
      "Non-pharmaceutical interventions Covid-19\n",
      "COVID-19 Full Text Article KeyPhrase Extraction\n",
      "Getting_Started_with_Cosine_Similarity\n",
      "CORD-19 : LDA Topic Model - Abstracts\n",
      "COVID19 Temporal Summarization Tool Version 1\n",
      "Covid-Literature-Survey\n",
      "Topic Modelling: Journals Content About COVID-19üìÑ\n",
      "Question answering using Semantic roles\n",
      "Risks of COVID-19 - AI driven Q&A\n",
      "Covids Incubation & Transmission Related Articles\n",
      "Corona virus latest analysis\n",
      "Combine Embedding Data and Citations Article\n",
      "COVID-19 Search Engine for all Queries, USE\n",
      "corona_text_mining_spacy\n",
      "User-Friendly: Finding Related Articles\n",
      "I-COVID19-NLP Data Parsing\n",
      "Covid-19 subset of articles\n",
      "CORD-19: Abstract and Conclusion Word Embedding\n",
      "summary page transmission incubation environment\n",
      "COVID-19 EDA including NLP with Spacy\n",
      "Basic Setup to import the JSON files\n",
      "Match Papers To Tasks\n",
      "Task Question Search\n",
      "Creating A Doc2Vec Model\n",
      "CORD-19-research-challenge: Relevant doc search\n",
      "II-COVID19-Citation Network\n",
      "CORD-19\n",
      "COVID-19 - Temperature and Transmission Rates\n",
      "COVID-19: Knowledge Graph Embeddings\n",
      "covid-19-mortality\n",
      "COVID-19 Ultimate: Chronology + Patients analysis\n",
      "COVID-19 using TF-IDF\n",
      "Covid-19 epidemiological curves at regional level\n",
      "COVID-19 Pandemic EDA üìä\n",
      "Extract Entities from Abstracts\n",
      "Demo of using Custom NER model on COVID-19 dataset\n",
      "CORD-19 Sources unification with pyspark SQL\n",
      "CORD-19 Metadata\n",
      "BIO-NER on COVID 19 data\n",
      "Viral agents. S100A12 marker.\n",
      "summary page virus genetics, origin, and evolution\n",
      "CORD-19-parse-docs-R\n",
      "CORD-19 Human Genes Insights\n",
      "COVID-19 Detection from X Ray Images of Lungs\n",
      "Diagnosing Covid-19\n",
      "Keywords on the subject - Ethical and social\n",
      "Train a Word2Vec\n",
      "COVID-19, Find the Right Research Paper, with tags\n",
      "Topic Modeling (LDA) on CORD-19 Paper Abstracts\n",
      "Covid-19 citation graph - embedding using DeepWalk\n",
      "Covid-19 literature query tool\n",
      "Extracting entities linked to UMLS with scispaCy\n",
      "Evidence Gap Map for Risk Areas\n",
      "summary page vaccines and therapeutics\n",
      "COVID-19 Open Research Dataset (CORD-19)-Analysis\n",
      "Improve quiries using W2V algorithms\n",
      "COVID-19 - Search Engine with Bert\n",
      "Comfirmed bar chart race depending on country\n",
      "COVID-19 what is risk?\n",
      "COVID-19 : Searching for the papers about vaccines\n",
      "Agglomerative Document Clustering on CORD-19\n",
      "Using Whoosh for Indexing and Querying\n",
      "Search COVID-19 papers for particular information\n",
      "Create Corona .csv File\n",
      "COVID2020\n",
      "Weather and Covid 19 Outbreak\n",
      "Covid(RAN) - Research & Analytics Notebook\n",
      "Data analysis on Coronavirus\n",
      "Train Fasttext on COVID papers\n",
      "Covid19 Ascending Phase Growth Model\n",
      "COVID-19 Recent Questions\n",
      "Beat Corona\n",
      "Insights - focus and experimental findings\n",
      "DoxCompass-Visualization and EDA\n",
      "COVID-19 : Biomedical Semantic Search - Q&A System\n",
      "CORD-19 Citation Network with Deduping\n",
      "CORD-19 Articles Clustering\n",
      "Searching data using KNN neighbors, topic modeling\n",
      "Training Set Labeling Jump-start (UMLS Linking)\n",
      "CORD-19: Disease-Chemical Co-occurrence Matrix\n",
      "COVID-19 Papers Text Summarization\n",
      "Medical NER : Using Spacy\n",
      "BioBERT Embeddings + Demo\n",
      "[CORD-19] Parse Data to Flat Format\n",
      "Mat2Vec/COVID papers: Unexpected word asociations\n",
      "Exploring_corona_abstracts\n",
      "Analyzing the COVID-19 corpus with LDA and PCoA\n",
      "III-COVID19-Collecting Virus Proteins from Uniprot\n",
      "get_data_from_all_papers\n",
      "COVID-19 Reference public data\n",
      "covid-19_create_dataset\n",
      "ACE2_protein_receptor_information\n",
      "cord_19\n",
      "COVID-19 in OH: measuring the response 2020_03_16\n",
      "COVID-19 Retrieval via Sentence Similarity\n",
      "Exploratory data analysis via NLP\n",
      "Most mentioned antivirals 622022\n",
      "How Good is a Drug Against The Corona Virus\n",
      "COVID-19 Data Preprocessing\n",
      "CORD19 - Input Data Exploration\n",
      "Hybrid Search Model - Annoy bio-w2v + BM25 EDA\n",
      "Search system for top article using wikipedia DB\n",
      "Sentence similarity\n",
      "COVID-related v4\n",
      "CORD-19 ngrams insights origin evolution\n",
      "Visualise and Calculate word frequencies COVID-19\n",
      "COVID19_ABSG_AD\n",
      "CORONA Challenge - Analysing Incubation Time in R\n",
      "CORD-19 Keyword Search in Abstracts\n",
      "Participations by country\n",
      "Unsupervised Text Segment Group Discovery\n",
      "Build CSV of Reference Entries\n",
      "Worldwide_Data_and_Graphs\n",
      "CORD-19 Simple Parsing to Dataframes\n",
      "CORD-19:EDA,duplicated papers discovery,resolution\n",
      "Parquet and BigQuery dataset for CORD-19\n",
      "COVID-19 clustering (Infersent-UMAP-HDBScan)\n",
      "Naive Lookup / Save Documents\n",
      "Interactive Abstract and Expert Finder\n",
      "CORD-19: Search Papers Referring to Antivirals\n",
      "coronavirus_jargon_vocabulary\n",
      "COVID19 Challenge Notebook\n",
      "Pandemic Ethics - Covid19\n",
      "CORD-19 Duplicate body_text.text\n",
      "Quick summary and integrated task detail\n",
      "Exploring_corona_competition\n",
      "CORD-19-research-challenge - Using NLP Search\n",
      "COVID Papers\n",
      "bag of words apply for abstract and text fields\n",
      "CORD-19: EDA, LDA and BERT (unsupervised)\n",
      "01 Exploring The Folder-Structure\n",
      "CORVID-19 TRACKING THE KENYA SPREAD\n",
      "Checkout the COVID 19 Word2Vec model\n",
      "CORD-19 : publication analysis\n",
      "War on Covid-19\n",
      "COVID-19: Journal Analysis and Wordcloud\n",
      "COVID-19 - Russia\n",
      "pd.read_csv\n",
      "SpaCy: Aspect Based and Compound Nouns Key Words\n",
      "CoronaVirus\n",
      "First-Notebook-CORD-19-Research\n",
      "CORD-19 beginner EDA\n",
      "Covid-19 - MetaData Overview\n",
      "start with covid-19 data\n",
      "add_pub_types_to_metadata_df\n",
      "COVID-19: data_qa\n",
      "COVID-19\n",
      "COVID-19 Russia details\n",
      "Covid-19 NLP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORD-19: interactive word2vec paragraph search\n",
      "COVID-19 (Task 01)\n",
      "COVID-19 Word Embedding Approach\n",
      "[CORD-19] Embeddings üìô from abstracts with SpaCy\n",
      "symptoms word cloud\n",
      "Detecting and Visualizing covid-19\n",
      "[CORD-19] Embeddings üìô from abstracts with SpaCy\n",
      "NG-EDA-COVID-19-v2\n",
      "COVID-19 World Statistics\n",
      "Extract Tika cTAKES Features\n",
      "Covid-19 Analysis\n",
      "Extractive text summarization\n",
      "COVID-19: Extracting the Hidden Topics With Gensim\n",
      "COVID-19 - Interactive Cluster Graph\n",
      "Papers on Virus Genetics\n",
      "Enigma Covid-19\n",
      "BM25 Search + Query Similarity Ranking\n",
      "COVID parameter study - India & others\n",
      "naive LSTM model test for covid19\n",
      "Search functions for cord19-challenge\n",
      "Browsing research papers with a BM25 search engine\n",
      "COVID-19 Dataset : Gaining actionable insights üìä\n",
      "What Are The Treatments?\n",
      "Tracking the spread of the Coronavirus\n",
      "Clustering Papers using K-Means and t-SNE\n",
      "Find similar COVID-19 Research Articles\n",
      "COVID-19 Classify articles-Doc2vec PCA\n",
      "Build CSV of Body Text\n",
      "betweenness_centrality_of_the_bibliography\n",
      "COVID-19-Word2Vec\n",
      "Protein Sequence Analysis with ProtLearn\n",
      "Extract Related Documents using Bert\n",
      "Metadata_basic_statistics\n",
      "COVID-19 - Find mentions of mortality rates\n",
      "Trying to extract table data from the paper\n",
      "clustering abstracts using fasttext\n",
      "Covid-19 1st transmission\n",
      "COVID-19 - Find keywords using Word2Vec\n",
      "02 Exploring The Article-Metadata-CSV\n",
      "CORD-19: Match SJR Rank journals\n",
      "Corona(nCOVID-19 ) Detection inspect_nucleus_model\n",
      "[CORD-19] Cleaning and EDA\n",
      "Fixing the metadata\n",
      "COVID-19_Genetics_Origin_Evolution\n",
      "All papers sorted by their citation count\n",
      "COVID-19 paper exploration\n",
      "Covid Research\n",
      "Using NLP with answer extraction\n",
      "ResearchPaperAPI (Data Exploitation API)\n",
      "Enigma_Covid19\n",
      "coronavirus factors research\n",
      "COVID-19: Analysing Research Papers (NLP)\n",
      "Covid - Analyzing the Symptoms\n",
      "Classification of articles by Matrix Factorization\n",
      "COVID_19_NER extraction\n",
      "CORD-19 - Data extraction functions\n",
      "High level articles grouping: Topic Modeling & EDA\n",
      "CORD-19_research_challenge\n",
      "COVID-19 simple spread research\n",
      "CoronaVirus EDA\n",
      "Data manipulation with cotools\n",
      "COVID19_EDA_Study1\n",
      "Super hacky regex search engine\n",
      "COVID-19 Research-Clustering\n",
      "Word-embedding\n",
      "Screening for most relevant articles\n",
      "01_data_explore_get_abstracts\n",
      "üò∑ COVID-19 Social Sciences, Vaccines, and Origins\n",
      "Covid-19 EDA in detail\n",
      "COVID-19 Cases Acceleration by Country\n",
      "COVID-19 research NPI\n",
      "QualityOfCovidData\n",
      "Fastai Language Model only COVID-19 papers\n",
      "cord19 data exploration\n",
      "Novel Corona Virus\n",
      "Extractive summary\n",
      "EDA + Preprocessing/Cleaning CORD-19 metadata\n",
      "Export Cleaned Dataset\n",
      "CORD19-EDA extended to all available datasets\n",
      "Recommend a paper by using word embeddings\n",
      "Range of incubation periods for the disease\n",
      "COVID-19 Incubation period\n",
      "count_pmids_per_journal_no_full_text\n",
      "Citation Analysis - Environmental Factors\n",
      "COVID-19-Visualization by co-occurrence network.\n",
      "draft\n",
      "Preprocessing NER, SRL, BERT\n",
      "COVID-19 (Task 09)\n",
      "COVID-19 (Task 08)\n",
      "COVID-19 (Task 06)\n",
      "COVID-19 (Task 07)\n",
      "COVID-19 (Task 04)\n",
      "COVID-19 (Task 03)\n",
      "nCOVID-19 Therapeutics\n",
      "COVID19-Alpha to Omega\n",
      "revs1_covid19_notebook\n",
      "First Exploration of the Weather articles\n",
      "Simple Search by Keywords Using TF-IDF\n",
      "Covid-19 research\n",
      "COV Literature Word Cloud\n",
      "develop-lsi-search\n",
      "Generating Topics using LDA\n",
      "Predict NER and SRL on abstracts\n",
      "CORD-19 Solution\n",
      "COVID-EDA\n",
      "Comparison of COVID-19 virus growth per country\n",
      "Papers on Medical Care\n",
      "Papers on Information Sharing and Collaboration\n",
      "Papers on Ethical and Social Considerations\n",
      "Covid-19 @Zhijie\n",
      "Papers on vaccines and therapeutics\n",
      "Get_file_details\n",
      "CORD-19 EDA on Literature(Kaggle's Dataset)\n",
      "Covid-19 Paper Analysis Part I\n",
      "CORD-19 Clustering documents using Abstract\n",
      "COVID - Task 1 - Analysis - Submission\n",
      "Transmission Filtering v1\n",
      "EDA: Cleaning the CORD-19 Dataset\n",
      "Covid19\n",
      "covid-19-analysis\n",
      "Kaggle COVID Roppsters\n",
      "Question Generation + tune bert + telegrambot\n",
      "An√°lise Explorat√≥ria - Coronavirus\n",
      "Cord-19ResearchC-Analysis\n",
      "Semantic Search of Covid Content\n",
      "Top 10 antiretroviral C19\n",
      "Leitura de dados e clustering -medxiv\n",
      "Could citations be used to link papers?\n",
      "COVID-19 Data Visualisation\n",
      "CORD-19-Topic Modelling\n",
      "03 Create A Collaboration Network Of Scientists\n",
      "CORONA Data Analysis\n",
      "Initial start\n",
      "Critical Epidemic Term Visualization w/ WordCloud\n",
      "CORD-19 EDA + Question & Topic Modeling\n",
      "Citation embeddings with visualization\n",
      "kernela990a37deb\n",
      "Outbreak Data Analysis\n",
      "kernel7457cf1f41\n",
      "A Simple, Direct COVID-19 QA engine\n",
      "Coronavirus (CoVid19) - Exploratory Analysis\n",
      "CORD-19: interactive search tool\n",
      "COVID19Frame\n",
      "Topic Modeling BERT+LDA\n",
      "Topic Modeling with LDA and NMF\n",
      "Papers on Non-pharmaceutical Interventions\n",
      "Papers on Diagnostics and Surveillance\n",
      "kernel154a79be15\n",
      "Corona_19_Clustering_and_TopicWise_Search\n",
      "Abstract Similarity for COVID-19\n",
      "kernel2400a64d5a\n",
      "[CORD-19] Embeddings üìô from abstracts (Notebook)\n",
      "COVID19 exploration and paper recommendation\n",
      "wordcloud\n",
      "kernel6aeadef153\n",
      "kernel666a075559\n",
      "risk factors word cloud\n",
      "kernel162450d46d\n",
      "COVID-19: Clustering\n",
      "[CORD-19] Parse Data to Flat Format\n",
      "kernel6f28923430\n",
      "Papers on Transmission and Incubation\n",
      "Papers on Risk Factors\n",
      "kernel35d406586c\n",
      "COVID-19 Graph Clustering\n",
      "COVID-19 Drug and chemical mentions\n",
      "Laura Edell Walk Through of COVID19\n",
      "BM25 Index Search\n",
      "CORD-19 Solution Toolbox\n",
      "TFIDF sklearn model\n",
      "I - COVID19-NLP-Data-Parsing_Animals\n",
      "Covid19_JAM\n",
      "chloroquine COVID-19\n",
      "Incubation Question (query) design\n",
      "COVID-19: Topic Modelling and Search with Top2Vec\n",
      "Virus Variations\n",
      "Testing Positive After Recovery\n",
      "surface persistence\n",
      "COVID-19 Pandemic in Pakistan and Other\n",
      "To Put a LAMP on COVID-19\n",
      "AaaAaa\n",
      "covid_add_sjr_if_to_metadata\n",
      "COVID-19 (Task 10)\n",
      "Task 02: CORD-19 Challenge (COVID-19)\n",
      "COVID-19 Unsupervised Literature Understanding\n",
      "COVID-19 Dataset : Insights\n",
      "Similarity between docs (20/3 update)\n",
      "Query2Vec: Creating Query-Context Embeddings\n",
      "CORD-19 Competition - Final Submission\n",
      "kernel41a29f6692\n",
      "COVID-19 Literature Clustering\n",
      "COVID-19 Challenge Notebook\n",
      "SciBERT+sentence similarity\n",
      "CORD-19 Search articles with Doc2Vec\n",
      "CORVID interactive\n",
      "cord-19-LDA\n"
     ]
    }
   ],
   "source": [
    "items = driver.find_elements_by_xpath('//*[@id=\"site-content\"]/div[2]/div[2]/div/div/div/div[1]/div[2]/div[2]/div/div/div/div')\n",
    "for each in items:\n",
    "    print(each.find_element_by_class_name(\"kernel-list-item__name\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"kernel-list-item__meta\"><div class=\"kernel-list-item__votes\"><div class=\"vote-button__container \"><div class=\"vote-button vote-button--enabled\"><div class=\"vote-button__button vote-button__button--up vb-upvote\"><span class=\"fa fa-caret-up\"></span></div><div class=\"vote-button__button vote-button__button--up vote-button__vote-count-container\"><span class=\"vote-button__vote-count\">57</span></div><div class=\"vote-button__button-placeholder\"></div></div></div></div><div class=\"kernel-list-item__image-wrapper\"><span class=\"tooltip-container\" data-tooltip=\"David Mezzetti\"><a class=\"avatar\" href=\"/nofoosports\" style=\"width: 36px; position: relative; z-index: 2; pointer-events: auto;\"><img class=\"avatar__thumbnail\" src=\"https://storage.googleapis.com/kaggle-avatars/thumbnails/555186-kg.png\" alt=\"David Mezzetti\" width=\"36\" height=\"36\" style=\"border-radius: 3.6px;\"><img class=\"avatar__tier\" src=\"/static/images/avatier/avatier-contributor@2x.png\" alt=\"contributor tier\" width=\"36\" style=\"margin-top: 0.01px;\"></a></span></div></div> <div class=\"kernel-list-item__synopsis\"><div class=\"kernel-list-item__info\"><span class=\"kernel-list-item__name\"><img class=\"kernel-list-item__medals\" src=\"/static/images/medals/notebooks/silvers@1x.png\" title=\"silver\"><div class=\"kernel-list-item__name false\">CORD-19 Analysis with Sentence Embeddings</div></span><div class=\"kernel-list-item__details\"><span title=\"Fri Mar 27 2020 11:17:10 GMT-0400 (Eastern Daylight Time)\">1d ago</span>&nbsp;<span class=\"Tag_Wrapper-sc-9nhn9u imhvKB\"><span class=\"Tag_Icon-sc-58yxs biBlCf fa fa-tag\"></span><span><a class=\"Tag_TextAnchor-sc-hezo17 fXiRgA\" style=\"position: relative; z-index: 2; pointer-events: auto;\">eda</a>, </span><span><a class=\"Tag_TextAnchor-sc-hezo17 fXiRgA\" style=\"position: relative; z-index: 2; pointer-events: auto;\">nlp</a>, </span><span><a class=\"Tag_TextAnchor-sc-hezo17 fXiRgA\" style=\"position: relative; z-index: 2; pointer-events: auto;\">covid19</a></span></span></div></div><div class=\"kernel-list-item__info-blocks\"><span class=\"tooltip-container\" data-tooltip=\"This Notebook outputs 4 visualizations and 13 data file.\"><a class=\"kernel-list-item__info-block--link\" style=\"position: relative; z-index: 2; pointer-events: auto;\"><img src=\"/static/images/kernel-viz-and-data-output.svg\"></a></span><span class=\"tooltip-container\" data-tooltip=\"This Notebook is written in Python\"><a class=\"kernel-list-item__info-block--link\" style=\"position: relative; z-index: 2; pointer-events: auto;\">Py</a></span><span class=\"tooltip-container\" data-tooltip=\"This Notebook has 32 comments.\"><a class=\"kernel-list-item__info-block--comment\" href=\"/nofoosports/cord-19-analysis-with-sentence-embeddings/comments\" style=\"position: relative; z-index: 2; pointer-events: auto;\"><span class=\"fa fa-comment-o\"></span>&nbsp;32</a></span></div></div> <div class=\"kernel-list-item__no-delete-placeholder\"></div>\n"
     ]
    }
   ],
   "source": [
    "print(items[23].get_attribute('innerHTML'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "- votes\n",
    "- user\n",
    "- tier\n",
    "- notebook_name\n",
    "- time_published\n",
    "- relative_time_published\n",
    "- tags\n",
    "- outputs\n",
    "- language\n",
    "- num_comments\n",
    "- link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'votes': [], 'user_link': [], 'tier': [], 'notebook_name': [], \n",
    "            'num_visualizations': [], 'num_datafiles': [], 'time_published': [], \n",
    "            'relative_time_published': [], 'tags': [], 'language': [], \n",
    "            'num_comments': [], 'notebook_link': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "https://www.kaggle.com/ajrwhite\n",
      "contributor\n",
      "COVID-19 Transmission and incubation\n",
      "Sat Mar 28 2020 13:50:24 GMT-0400 (Eastern Daylight Time)\n",
      "4h ago\n",
      "['covid19']\n",
      "vis 0\n",
      "data 1\n",
      "Python\n",
      "4\n",
      "https://www.kaggle.com/ajrwhite/covid-19-transmission-and-incubation\n"
     ]
    }
   ],
   "source": [
    "tidx = 6 #test index of items\n",
    "print(items[tidx].find_element_by_class_name(\"vote-button__vote-count\").text)\n",
    "print(items[tidx].find_element_by_class_name('avatar').get_attribute(\"href\"))\n",
    "print(items[tidx].find_element_by_class_name('avatar__tier').get_attribute('alt').split(' ')[0])\n",
    "print(items[tidx].find_element_by_class_name('kernel-list-item__name').text)\n",
    "print(items[tidx].find_element_by_class_name('kernel-list-item__details').\\\n",
    "                  find_element_by_xpath('.//*[@title]').get_attribute('title'))\n",
    "print(items[tidx].find_element_by_class_name('kernel-list-item__details').\\\n",
    "                  find_element_by_xpath('.//*[@title]').text)\n",
    "print([each.text for each in items[tidx].find_elements_by_class_name('Tag_TextAnchor-sc-hezo17') if each.text != ''])\n",
    "tooltip = items[tidx].find_element_by_class_name('kernel-list-item__info-blocks')\\\n",
    "                  .find_element_by_xpath('.//span[1]').get_attribute('data-tooltip')[:-1].split(' ')\n",
    "                                                                     # remove the period\n",
    "if ('visualizations' in tooltip) or ('visualization' in tooltip):\n",
    "    for i, v in enumerate(tooltip):\n",
    "        if ((v == 'visualizations' or v == 'visualization') and (tooltip[i-1].isdigit())):\n",
    "            print('vis', tooltip[i-1])\n",
    "        elif ((v == 'visualizations' or v == 'visualization') and (not tooltip[i-1].isdigit())):\n",
    "            print('vis', 0)\n",
    "else:\n",
    "    print('vis', 0)\n",
    "if ('data' in tooltip):\n",
    "    for i, v in enumerate(tooltip):            \n",
    "        if ((v == 'data') and (tooltip[i-1].isdigit())):\n",
    "            print('data', tooltip[i-1])\n",
    "        elif ((v == 'data') and (not tooltip[i-1].isdigit())):\n",
    "            print('data', 0)\n",
    "else:\n",
    "    print('data', 0)\n",
    "#always (visualizations then data files) when both present\n",
    "\n",
    "print(items[tidx].find_element_by_class_name('kernel-list-item__info-blocks')\\\n",
    "                  .find_element_by_xpath('.//span[2]').get_attribute(\"data-tooltip\").split(' ')[-1:][0])\n",
    "print(re.sub('\\D', '', items[tidx].find_element_by_class_name('kernel-list-item__info-blocks')\\\n",
    "                  .find_element_by_xpath('.//span[3]').get_attribute(\"data-tooltip\")))\n",
    "print(items[tidx].find_element_by_xpath('.//a').get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'block-link block-link--bordered'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[0].get_attribute('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<div class=\"block-link block-link--bordered\"><a class=\"block-link__anchor\" href=\"/dgunning/browsing-research-papers-with-a-bm25-search-engine\"></a><span><div class=\"kernel-list-item\"><div class=\"kernel-list-item__meta\"><div class=\"kernel-list-item__votes\"><div class=\"vote-button__container \"><div class=\"vote-button vote-button--enabled\"><div class=\"vote-button__button vote-button__button--up vb-upvote\"><span class=\"fa fa-caret-up\"></span></div><div class=\"vote-button__button vote-button__button--up vote-button__vote-count-container\"><span class=\"vote-button__vote-count\">287</span></div><div class=\"vote-button__button-placeholder\"></div></div></div></div><div class=\"kernel-list-item__image-wrapper\"><span class=\"tooltip-container\" data-tooltip=\"DwightGunning\"><a class=\"avatar\" href=\"/dgunning\" style=\"width: 36px; position: relative; z-index: 2; pointer-events: auto;\"><img class=\"avatar__thumbnail\" src=\"https://storage.googleapis.com/kaggle-avatars/thumbnails/396930-gp.jpg\" alt=\"DwightGunning\" width=\"36\" height=\"36\" style=\"border-radius: 3.6px;\"><img class=\"avatar__tier\" src=\"/static/images/avatier/avatier-novice@2x.png\" alt=\"novice tier\" width=\"36\" style=\"margin-top: 0.01px;\"></a></span></div></div> <div class=\"kernel-list-item__synopsis\"><div class=\"kernel-list-item__info\"><span class=\"kernel-list-item__name\"><img class=\"kernel-list-item__medals\" src=\"/static/images/medals/notebooks/golds@1x.png\" title=\"gold\"><div class=\"kernel-list-item__name false\">Browsing research papers with a BM25 search engine</div></span><div class=\"kernel-list-item__details\"><span title=\"Mon Mar 30 2020 09:00:51 GMT-0400 (Eastern Daylight Time)\">8h ago</span>&#160;<span class=\"Tag_Wrapper-sc-9nhn9u imhvKB\"><span class=\"Tag_Icon-sc-58yxs biBlCf fa fa-tag\"></span><span><a class=\"Tag_TextAnchor-sc-hezo17 fXiRgA\" style=\"position: relative; z-index: 2; pointer-events: auto;\">beginner</a>, </span><span><a class=\"Tag_TextAnchor-sc-hezo17 fXiRgA\" style=\"position: relative; z-index: 2; pointer-events: auto;\">eda</a>, </span><span><a class=\"Tag_TextAnchor-sc-hezo17 fXiRgA\" style=\"position: relative; z-index: 2; pointer-events: auto;\">starter code</a></span></span></div></div><div class=\"kernel-list-item__info-blocks\"><span class=\"tooltip-container\" data-tooltip=\"This Notebook doesn\\'t output any visualizations or data files.\"><div class=\"kernel-list-item__info-block--link\"><span class=\"kernel-list-item__info-block--bullet\"> &#8226; </span></div></span><span class=\"tooltip-container\" data-tooltip=\"This Notebook is written in Python\"><a class=\"kernel-list-item__info-block--link\" style=\"position: relative; z-index: 2; pointer-events: auto;\">Py</a></span><span class=\"tooltip-container\" data-tooltip=\"This Notebook has 32 comments.\"><a class=\"kernel-list-item__info-block--comment\" href=\"/dgunning/browsing-research-papers-with-a-bm25-search-engine/comments\" style=\"position: relative; z-index: 2; pointer-events: auto;\"><span class=\"fa fa-comment-o\"></span>&#160;32</a></span></div></div> <div class=\"kernel-list-item__no-delete-placeholder\"></div></div></span></div>'\n"
     ]
    }
   ],
   "source": [
    "print(html.tostring(items[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<span><span><div class=\"ToolTip_ToolTipContainer-sc-f0vhmk eHUYTV\"><span class=\"fa fa-users kernel-list-item__collaboration-icon\" data-tip=\"true\" data-for=\"tooltip_1\" currentitem=\"false\"></span><div class=\"__react_component_tooltip place-top type-dark \" id=\"tooltip_1\" data-id=\"tooltip\"><div class=\"ToolTip_ToolTipView-sc-1ci7zcv johoye\"><span>This Notebook has collaborators.</span></div></div></div></span></span>'"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.tostring(tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/span[1]\")[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 30 2020 09:00:51 GMT-0400 (Eastern Daylight Time) 0\n",
      "Mon Mar 30 2020 10:58:23 GMT-0400 (Eastern Daylight Time) 1\n",
      "Mon Mar 30 2020 10:12:42 GMT-0400 (Eastern Daylight Time) 2\n",
      "Mon Mar 30 2020 16:31:53 GMT-0400 (Eastern Daylight Time) 3\n",
      "Mon Mar 30 2020 06:35:53 GMT-0400 (Eastern Daylight Time) 4\n",
      "Sun Mar 29 2020 23:32:57 GMT-0400 (Eastern Daylight Time) 5\n",
      "Mon Mar 30 2020 12:10:39 GMT-0400 (Eastern Daylight Time) 6\n",
      "Mon Mar 30 2020 14:56:48 GMT-0400 (Eastern Daylight Time) 7\n",
      "Mon Mar 30 2020 16:05:26 GMT-0400 (Eastern Daylight Time) 8\n",
      "Mon Mar 30 2020 08:35:19 GMT-0400 (Eastern Daylight Time) 9\n",
      "Mon Mar 30 2020 14:15:38 GMT-0400 (Eastern Daylight Time) 10\n",
      "Mon Mar 30 2020 14:14:08 GMT-0400 (Eastern Daylight Time) 11\n",
      "Mon Mar 30 2020 15:02:03 GMT-0400 (Eastern Daylight Time) 12\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-489-c3aa591f0e04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/span[1]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._Attrib.__getitem__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "for i, each in enumerate(tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/span[1]\")):\n",
    "    print (each.attrib['title'], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HtmlElement' object has no attribute 'find_elements_by_class_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-d5a38cdd20a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tag_TextAnchor-sc-hezo17'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0meach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'HtmlElement' object has no attribute 'find_elements_by_class_name'"
     ]
    }
   ],
   "source": [
    "[each.text for each in items[0].find_elements_by_class_name('Tag_TextAnchor-sc-hezo17') if each.text != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element a at 0x27b59d75e08>,\n",
       " <Element a at 0x27b59d77818>,\n",
       " <Element a at 0x27b59d77688>,\n",
       " <Element a at 0x27b59d77908>,\n",
       " <Element a at 0x27b59d77a48>,\n",
       " <Element a at 0x27b59d77ae8>,\n",
       " <Element a at 0x27b59d77b38>,\n",
       " <Element a at 0x27b59d77b88>,\n",
       " <Element a at 0x27b59d77bd8>,\n",
       " <Element a at 0x27b59d77c28>,\n",
       " <Element a at 0x27b59d77c78>,\n",
       " <Element a at 0x27b59d77cc8>,\n",
       " <Element a at 0x27b59d77d18>,\n",
       " <Element a at 0x27b59d77d68>,\n",
       " <Element a at 0x27b59d77db8>,\n",
       " <Element a at 0x27b59d77e08>,\n",
       " <Element a at 0x27b59d77e58>,\n",
       " <Element a at 0x27b59d77ea8>,\n",
       " <Element a at 0x27b59d77ef8>,\n",
       " <Element a at 0x27b59d77f48>,\n",
       " <Element a at 0x27b59d77f98>,\n",
       " <Element a at 0x27b59d6f048>,\n",
       " <Element a at 0x27b59d6f098>,\n",
       " <Element a at 0x27b59d6f0e8>,\n",
       " <Element a at 0x27b59d6f138>,\n",
       " <Element a at 0x27b59d6f188>,\n",
       " <Element a at 0x27b59d6f1d8>,\n",
       " <Element a at 0x27b59d6f228>,\n",
       " <Element a at 0x27b59d6f278>,\n",
       " <Element a at 0x27b59d6f2c8>,\n",
       " <Element a at 0x27b59d6f318>,\n",
       " <Element a at 0x27b59d6f368>,\n",
       " <Element a at 0x27b59d6f3b8>,\n",
       " <Element a at 0x27b59d6f408>,\n",
       " <Element a at 0x27b59d6f458>,\n",
       " <Element a at 0x27b59d6f4a8>,\n",
       " <Element a at 0x27b59d6f4f8>,\n",
       " <Element a at 0x27b59d6f548>,\n",
       " <Element a at 0x27b59d6f598>,\n",
       " <Element a at 0x27b59d6f5e8>,\n",
       " <Element a at 0x27b59d6f638>,\n",
       " <Element a at 0x27b59d6f688>,\n",
       " <Element a at 0x27b59d6f6d8>,\n",
       " <Element a at 0x27b59d6f728>,\n",
       " <Element a at 0x27b59d6f778>,\n",
       " <Element a at 0x27b59d6f7c8>,\n",
       " <Element a at 0x27b59d6f818>,\n",
       " <Element a at 0x27b59d6f868>,\n",
       " <Element a at 0x27b59d6f8b8>,\n",
       " <Element a at 0x27b59d6f908>,\n",
       " <Element a at 0x27b59d6f958>,\n",
       " <Element a at 0x27b59d6f9a8>,\n",
       " <Element a at 0x27b59d6f9f8>,\n",
       " <Element a at 0x27b59d6fa48>,\n",
       " <Element a at 0x27b59d6fa98>,\n",
       " <Element a at 0x27b59d6fae8>,\n",
       " <Element a at 0x27b59d6fb38>,\n",
       " <Element a at 0x27b59d6fb88>,\n",
       " <Element a at 0x27b59d6fbd8>,\n",
       " <Element a at 0x27b59d6fc28>,\n",
       " <Element a at 0x27b59d6fc78>,\n",
       " <Element a at 0x27b59d6fcc8>,\n",
       " <Element a at 0x27b59d6fd18>,\n",
       " <Element a at 0x27b59d6fd68>,\n",
       " <Element a at 0x27b59d6fdb8>,\n",
       " <Element a at 0x27b59d6fe08>,\n",
       " <Element a at 0x27b59d6fe58>,\n",
       " <Element a at 0x27b59d6fea8>,\n",
       " <Element a at 0x27b59d6fef8>,\n",
       " <Element a at 0x27b59d6ff48>,\n",
       " <Element a at 0x27b59d6ff98>,\n",
       " <Element a at 0x27b59d7c048>,\n",
       " <Element a at 0x27b59d7c098>,\n",
       " <Element a at 0x27b59d7c0e8>,\n",
       " <Element a at 0x27b59d7c138>,\n",
       " <Element a at 0x27b59d7c188>,\n",
       " <Element a at 0x27b59d7c1d8>,\n",
       " <Element a at 0x27b59d7c228>,\n",
       " <Element a at 0x27b59d7c278>,\n",
       " <Element a at 0x27b59d7c2c8>,\n",
       " <Element a at 0x27b59d7c318>,\n",
       " <Element a at 0x27b59d7c368>,\n",
       " <Element a at 0x27b59d7c3b8>,\n",
       " <Element a at 0x27b59d7c408>,\n",
       " <Element a at 0x27b59d7c458>,\n",
       " <Element a at 0x27b59d7c4a8>,\n",
       " <Element a at 0x27b59d7c4f8>,\n",
       " <Element a at 0x27b59d7c548>,\n",
       " <Element a at 0x27b59d7c598>,\n",
       " <Element a at 0x27b59d7c5e8>,\n",
       " <Element a at 0x27b59d7c638>,\n",
       " <Element a at 0x27b59d7c688>,\n",
       " <Element a at 0x27b59d7c6d8>,\n",
       " <Element a at 0x27b59d7c728>,\n",
       " <Element a at 0x27b59d7c778>,\n",
       " <Element a at 0x27b59d7c7c8>,\n",
       " <Element a at 0x27b59d7c818>,\n",
       " <Element a at 0x27b59d7c868>,\n",
       " <Element a at 0x27b59d7c8b8>,\n",
       " <Element a at 0x27b59d7c908>,\n",
       " <Element a at 0x27b59d7c958>,\n",
       " <Element a at 0x27b59d7c9a8>,\n",
       " <Element a at 0x27b59d7c9f8>,\n",
       " <Element a at 0x27b59d7ca48>,\n",
       " <Element a at 0x27b59d7ca98>,\n",
       " <Element a at 0x27b59d7cae8>,\n",
       " <Element a at 0x27b59d7cb38>,\n",
       " <Element a at 0x27b59d7cb88>,\n",
       " <Element a at 0x27b59d7cbd8>,\n",
       " <Element a at 0x27b59d7cc28>,\n",
       " <Element a at 0x27b59d7cc78>,\n",
       " <Element a at 0x27b59d7ccc8>,\n",
       " <Element a at 0x27b59d7cd18>,\n",
       " <Element a at 0x27b59d7cd68>,\n",
       " <Element a at 0x27b59d7cdb8>,\n",
       " <Element a at 0x27b59d7ce08>,\n",
       " <Element a at 0x27b59d7ce58>,\n",
       " <Element a at 0x27b59d7cea8>,\n",
       " <Element a at 0x27b59d7cef8>,\n",
       " <Element a at 0x27b59d7cf48>,\n",
       " <Element a at 0x27b59d7cf98>,\n",
       " <Element a at 0x27b59d7a048>,\n",
       " <Element a at 0x27b59d7a098>,\n",
       " <Element a at 0x27b59d7a0e8>,\n",
       " <Element a at 0x27b59d7a138>,\n",
       " <Element a at 0x27b59d7a188>,\n",
       " <Element a at 0x27b59d7a1d8>,\n",
       " <Element a at 0x27b59d7a228>,\n",
       " <Element a at 0x27b59d7a278>,\n",
       " <Element a at 0x27b59d7a2c8>,\n",
       " <Element a at 0x27b59d7a318>,\n",
       " <Element a at 0x27b59d7a368>,\n",
       " <Element a at 0x27b59d7a3b8>,\n",
       " <Element a at 0x27b59d7a408>,\n",
       " <Element a at 0x27b59d7a458>,\n",
       " <Element a at 0x27b59d7a4a8>,\n",
       " <Element a at 0x27b59d7a4f8>,\n",
       " <Element a at 0x27b59d7a548>,\n",
       " <Element a at 0x27b59d7a598>,\n",
       " <Element a at 0x27b59d7a5e8>,\n",
       " <Element a at 0x27b59d7a638>,\n",
       " <Element a at 0x27b59d7a688>,\n",
       " <Element a at 0x27b59d7a6d8>,\n",
       " <Element a at 0x27b59d7a728>,\n",
       " <Element a at 0x27b59d7a778>,\n",
       " <Element a at 0x27b59d7a7c8>,\n",
       " <Element a at 0x27b59d7a818>,\n",
       " <Element a at 0x27b59d7a868>,\n",
       " <Element a at 0x27b59d7a8b8>,\n",
       " <Element a at 0x27b59d7a908>,\n",
       " <Element a at 0x27b59d7a958>,\n",
       " <Element a at 0x27b59d7a9a8>,\n",
       " <Element a at 0x27b59d7a9f8>,\n",
       " <Element a at 0x27b59d7aa48>,\n",
       " <Element a at 0x27b59d7aa98>,\n",
       " <Element a at 0x27b59d7aae8>,\n",
       " <Element a at 0x27b59d7ab38>,\n",
       " <Element a at 0x27b59d7ab88>,\n",
       " <Element a at 0x27b59d7abd8>,\n",
       " <Element a at 0x27b59d7ac28>,\n",
       " <Element a at 0x27b59d7ac78>,\n",
       " <Element a at 0x27b59d7acc8>,\n",
       " <Element a at 0x27b59d7ad18>,\n",
       " <Element a at 0x27b59d7ad68>,\n",
       " <Element a at 0x27b59d7adb8>,\n",
       " <Element a at 0x27b59d7ae08>,\n",
       " <Element a at 0x27b59d7ae58>,\n",
       " <Element a at 0x27b59d7aea8>,\n",
       " <Element a at 0x27b59d7aef8>,\n",
       " <Element a at 0x27b59d7af48>,\n",
       " <Element a at 0x27b59d7af98>,\n",
       " <Element a at 0x27b59d7e048>,\n",
       " <Element a at 0x27b59d7e098>,\n",
       " <Element a at 0x27b59d7e0e8>,\n",
       " <Element a at 0x27b59d7e138>,\n",
       " <Element a at 0x27b59d7e188>,\n",
       " <Element a at 0x27b59d7e1d8>,\n",
       " <Element a at 0x27b59d7e228>,\n",
       " <Element a at 0x27b59d7e278>,\n",
       " <Element a at 0x27b59d7e2c8>,\n",
       " <Element a at 0x27b59d7e318>,\n",
       " <Element a at 0x27b59d7e368>,\n",
       " <Element a at 0x27b59d7e3b8>,\n",
       " <Element a at 0x27b59d7e408>,\n",
       " <Element a at 0x27b59d7e458>,\n",
       " <Element a at 0x27b59d7e4a8>,\n",
       " <Element a at 0x27b59d7e4f8>,\n",
       " <Element a at 0x27b59d7e548>,\n",
       " <Element a at 0x27b59d7e598>,\n",
       " <Element a at 0x27b59d7e5e8>,\n",
       " <Element a at 0x27b59d7e638>,\n",
       " <Element a at 0x27b59d7e688>,\n",
       " <Element a at 0x27b59d7e6d8>,\n",
       " <Element a at 0x27b59d7e728>,\n",
       " <Element a at 0x27b59d7e778>,\n",
       " <Element a at 0x27b59d7e7c8>,\n",
       " <Element a at 0x27b59d7e818>,\n",
       " <Element a at 0x27b59d7e868>,\n",
       " <Element a at 0x27b59d7e8b8>,\n",
       " <Element a at 0x27b59d7e908>,\n",
       " <Element a at 0x27b59d7e958>,\n",
       " <Element a at 0x27b59d7e9a8>,\n",
       " <Element a at 0x27b59d7e9f8>,\n",
       " <Element a at 0x27b59d7ea48>,\n",
       " <Element a at 0x27b59d7ea98>,\n",
       " <Element a at 0x27b59d7eae8>,\n",
       " <Element a at 0x27b59d7eb38>,\n",
       " <Element a at 0x27b59d7eb88>,\n",
       " <Element a at 0x27b59d7ebd8>,\n",
       " <Element a at 0x27b59d7ec28>,\n",
       " <Element a at 0x27b59d7ec78>,\n",
       " <Element a at 0x27b59d7ecc8>,\n",
       " <Element a at 0x27b59d7ed18>,\n",
       " <Element a at 0x27b59d7ed68>,\n",
       " <Element a at 0x27b59d7edb8>,\n",
       " <Element a at 0x27b59d7ee08>,\n",
       " <Element a at 0x27b59d7ee58>,\n",
       " <Element a at 0x27b59d7eea8>,\n",
       " <Element a at 0x27b59d7eef8>,\n",
       " <Element a at 0x27b59d7ef48>,\n",
       " <Element a at 0x27b59d7ef98>,\n",
       " <Element a at 0x27b59d7f048>,\n",
       " <Element a at 0x27b59d7f098>,\n",
       " <Element a at 0x27b59d7f0e8>,\n",
       " <Element a at 0x27b59d7f138>,\n",
       " <Element a at 0x27b59d7f188>,\n",
       " <Element a at 0x27b59d7f1d8>,\n",
       " <Element a at 0x27b59d7f228>,\n",
       " <Element a at 0x27b59d7f278>,\n",
       " <Element a at 0x27b59d7f2c8>,\n",
       " <Element a at 0x27b59d7f318>,\n",
       " <Element a at 0x27b59d7f368>,\n",
       " <Element a at 0x27b59d7f3b8>,\n",
       " <Element a at 0x27b59d7f408>,\n",
       " <Element a at 0x27b59d7f458>,\n",
       " <Element a at 0x27b59d7f4a8>,\n",
       " <Element a at 0x27b59d7f4f8>,\n",
       " <Element a at 0x27b59d7f548>,\n",
       " <Element a at 0x27b59d7f598>,\n",
       " <Element a at 0x27b59d7f5e8>,\n",
       " <Element a at 0x27b59d7f638>,\n",
       " <Element a at 0x27b59d7f688>,\n",
       " <Element a at 0x27b59d7f6d8>,\n",
       " <Element a at 0x27b59d7f728>,\n",
       " <Element a at 0x27b59d7f778>,\n",
       " <Element a at 0x27b59d7f7c8>,\n",
       " <Element a at 0x27b59d7f818>,\n",
       " <Element a at 0x27b59d7f868>,\n",
       " <Element a at 0x27b59d7f8b8>,\n",
       " <Element a at 0x27b59d7f908>,\n",
       " <Element a at 0x27b59d7f958>,\n",
       " <Element a at 0x27b59d7f9a8>,\n",
       " <Element a at 0x27b59d7f9f8>,\n",
       " <Element a at 0x27b59d7fa48>,\n",
       " <Element a at 0x27b59d7fa98>,\n",
       " <Element a at 0x27b59d7fae8>,\n",
       " <Element a at 0x27b59d7fb38>,\n",
       " <Element a at 0x27b59d7fb88>,\n",
       " <Element a at 0x27b59d7fbd8>,\n",
       " <Element a at 0x27b59d7fc28>,\n",
       " <Element a at 0x27b59d7fc78>,\n",
       " <Element a at 0x27b59d7fcc8>,\n",
       " <Element a at 0x27b59d7fd18>,\n",
       " <Element a at 0x27b59d7fd68>,\n",
       " <Element a at 0x27b59d7fdb8>,\n",
       " <Element a at 0x27b59d7fe08>,\n",
       " <Element a at 0x27b59d7fe58>,\n",
       " <Element a at 0x27b59d7fea8>,\n",
       " <Element a at 0x27b59d7fef8>,\n",
       " <Element a at 0x27b59d7ff48>,\n",
       " <Element a at 0x27b59d7ff98>,\n",
       " <Element a at 0x27b59d81048>,\n",
       " <Element a at 0x27b59d81098>,\n",
       " <Element a at 0x27b59d810e8>,\n",
       " <Element a at 0x27b59d81138>,\n",
       " <Element a at 0x27b59d81188>,\n",
       " <Element a at 0x27b59d811d8>,\n",
       " <Element a at 0x27b59d81228>,\n",
       " <Element a at 0x27b59d81278>,\n",
       " <Element a at 0x27b59d812c8>,\n",
       " <Element a at 0x27b59d81318>,\n",
       " <Element a at 0x27b59d81368>,\n",
       " <Element a at 0x27b59d813b8>,\n",
       " <Element a at 0x27b59d81408>,\n",
       " <Element a at 0x27b59d81458>,\n",
       " <Element a at 0x27b59d814a8>,\n",
       " <Element a at 0x27b59d814f8>,\n",
       " <Element a at 0x27b59d81548>,\n",
       " <Element a at 0x27b59d81598>,\n",
       " <Element a at 0x27b59d815e8>,\n",
       " <Element a at 0x27b59d81638>,\n",
       " <Element a at 0x27b59d81688>,\n",
       " <Element a at 0x27b59d816d8>,\n",
       " <Element a at 0x27b59d81728>,\n",
       " <Element a at 0x27b59d81778>,\n",
       " <Element a at 0x27b59d817c8>,\n",
       " <Element a at 0x27b59d81818>,\n",
       " <Element a at 0x27b59d81868>,\n",
       " <Element a at 0x27b59d818b8>,\n",
       " <Element a at 0x27b59d81908>,\n",
       " <Element a at 0x27b59d81958>,\n",
       " <Element a at 0x27b59d819a8>,\n",
       " <Element a at 0x27b59d819f8>,\n",
       " <Element a at 0x27b59d81a48>,\n",
       " <Element a at 0x27b59d81a98>,\n",
       " <Element a at 0x27b59d81ae8>,\n",
       " <Element a at 0x27b59d81b38>,\n",
       " <Element a at 0x27b59d81b88>,\n",
       " <Element a at 0x27b59d81bd8>,\n",
       " <Element a at 0x27b59d81c28>,\n",
       " <Element a at 0x27b59d81c78>,\n",
       " <Element a at 0x27b59d81cc8>,\n",
       " <Element a at 0x27b59d81d18>,\n",
       " <Element a at 0x27b59d81d68>,\n",
       " <Element a at 0x27b59d81db8>,\n",
       " <Element a at 0x27b59d81e08>,\n",
       " <Element a at 0x27b59d81e58>,\n",
       " <Element a at 0x27b59d81ea8>,\n",
       " <Element a at 0x27b59d81ef8>,\n",
       " <Element a at 0x27b59d81f48>,\n",
       " <Element a at 0x27b59d81f98>,\n",
       " <Element a at 0x27b59d83048>,\n",
       " <Element a at 0x27b59d83098>,\n",
       " <Element a at 0x27b59d830e8>,\n",
       " <Element a at 0x27b59d83138>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.xpath(\".//span/div/div[2]/div/div/span[2]/*/*[self::a]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"site-content\"]/div[2]/div[2]/div/div/div/div[1]/div[2]/div[2]/div/div/div[1]/div/span/div/div[2]/div[2]/span[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['epidemiology', 'health', 'data visualization', 'starter code', 'covid19'],\n",
       " ['beginner', 'eda', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['nlp', 'classification', 'clustering'],\n",
       " ['eda', 'nlp', 'covid19'],\n",
       " [],\n",
       " ['nlp', 'data visualization', 'classification', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['health', 'beginner', 'nlp', 'data visualization', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " ['data visualization'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['tutorial', 'data visualization', 'starter code'],\n",
       " ['epidemiology', 'text mining', 'recommendation', 'spaCy', 'covid19'],\n",
       " [],\n",
       " ['data journalism'],\n",
       " ['beginner', 'eda', 'data cleaning'],\n",
       " [],\n",
       " [],\n",
       " ['covid19'],\n",
       " ['medicine', 'eda', 'nlp', 'text data', 'covid19'],\n",
       " ['eda', 'nlp', 'feature engineering', 'starter code', 'covid19'],\n",
       " [],\n",
       " ['covid19'],\n",
       " ['covid19'],\n",
       " ['covid19'],\n",
       " ['covid19'],\n",
       " [],\n",
       " ['covid19'],\n",
       " ['covid19'],\n",
       " ['covid19'],\n",
       " ['data cleaning', 'data management', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " ['covid19'],\n",
       " [],\n",
       " [],\n",
       " ['research', 'nlp', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['nlp', 'spaCy'],\n",
       " ['covid19'],\n",
       " [],\n",
       " ['utility script'],\n",
       " [],\n",
       " ['data cleaning', 'nlp', 'text mining', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'eda', 'nlp', 'churn analysis', 'language resources'],\n",
       " ['healthcare', 'biology', 'covid19'],\n",
       " [],\n",
       " ['search engines', 'nlp', 'covid19'],\n",
       " ['eda', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " ['data cleaning', 'data visualization'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['text mining', 'data visualization', 'clustering', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['epidemiology', 'data visualization', 'statistical analysis', 'covid19'],\n",
       " ['epidemiology', 'medicine', 'eda', 'starter code'],\n",
       " ['beginner', 'nlp', 'clustering', 'pca', 'starter code'],\n",
       " ['search engines', 'nlp', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['medicine', 'beginner', 'nlp', 'data visualization', 'covid19'],\n",
       " [],\n",
       " ['computer science', 'data cleaning', 'social networks', 'covid19'],\n",
       " ['data cleaning', 'preprocessing', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['data cleaning', 'nlp', 'covid19'],\n",
       " [],\n",
       " ['healthcare', 'epidemiology', 'eda', 'data visualization'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['data visualization', 'covid19'],\n",
       " [],\n",
       " ['research', 'tutorial', 'beginner', 'nlp', 'covid19'],\n",
       " ['medicine', 'beginner', 'eda', 'starter code'],\n",
       " ['healthcare', 'geospatial analysis', 'data visualization', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'classification', 'deep learning', 'starter code', 'covid19'],\n",
       " [],\n",
       " ['covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'data cleaning', 'nlp', 'covid19'],\n",
       " [],\n",
       " ['research', 'tutorial', 'nlp', 'deep learning', 'starter code'],\n",
       " [],\n",
       " ['beginner', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['epidemiology', 'beginner', 'covid19'],\n",
       " ['beginner', 'network analysis', 'feature engineering', 'covid19'],\n",
       " ['covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['epidemiology', 'health', 'eda', 'starter code', 'covid19'],\n",
       " ['eda', 'nlp', 'data visualization', 'deep learning', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'eda', 'data visualization', 'starter code'],\n",
       " [],\n",
       " ['human genetics'],\n",
       " [],\n",
       " ['epidemiology', 'statistical analysis', 'covid19'],\n",
       " ['time series', 'eda', 'data visualization', 'covid19'],\n",
       " ['healthcare', 'biology', 'covid19'],\n",
       " [],\n",
       " ['preprocessing', 'covid19'],\n",
       " ['nlp', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['research', 'nlp', 'clustering', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['data cleaning', 'data visualization', 'classification', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['text mining', 'text data'],\n",
       " ['nlp', 'preprocessing', 'starter code', 'spaCy', 'covid19'],\n",
       " ['research tools and topics',\n",
       "  'nlp',\n",
       "  'hospitals and treatment centers',\n",
       "  'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['search engines', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['medicine', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " ['pharmaceutical industry', 'space', 'nlp', 'deep learning'],\n",
       " ['data cleaning', 'network analysis', 'feature engineering', 'covid19'],\n",
       " [],\n",
       " ['eda', 'nlp'],\n",
       " ['nlp', 'text data', 'covid19'],\n",
       " [],\n",
       " ['text mining', 'data visualization', 'covid19'],\n",
       " [],\n",
       " ['research', 'deep learning', 'starter code'],\n",
       " ['data cleaning'],\n",
       " [],\n",
       " [],\n",
       " ['databases', 'data cleaning', 'feature engineering'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['eda', 'starter code', 'covid19'],\n",
       " [],\n",
       " ['nlp'],\n",
       " ['biology', 'medicine', 'beginner', 'starter code', 'covid19'],\n",
       " ['data visualization', 'feature engineering'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['data cleaning', 'nlp', 'data visualization', 'text data'],\n",
       " ['epidemiology', 'text data', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'text data', 'starter code', 'covid19'],\n",
       " [],\n",
       " ['feature engineering', 'starter code', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['tutorial', 'data cleaning', 'nlp'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['eda', 'nlp'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['eda', 'nlp'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['eda',\n",
       "  'nlp',\n",
       "  'data visualization',\n",
       "  'clustering',\n",
       "  'dimensionality reduction'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['russia', 'diseases', 'epidemiology', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'eda', 'data cleaning', 'data visualization', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['eda', 'clustering'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'text data', 'starter code', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'text mining', 'starter code'],\n",
       " [],\n",
       " ['clustering', 'covid19'],\n",
       " [],\n",
       " ['text mining', 'starter code', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'eda', 'data cleaning', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['eda', 'nlp'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['starter code'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['covid19'],\n",
       " ['research'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['beginner', 'eda', 'data cleaning', 'preprocessing', 'starter code'],\n",
       " [],\n",
       " [],\n",
       " ['nlp', 'clustering', 'recommender systems', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['data cleaning', 'preprocessing', 'clustering'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['health', 'beginner', 'eda', 'starter code', 'covid19'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[each.text for each in block.xpath(\".//span/div/div[2]/div/div/span[2]/*/*[self::a]\")] for block in tree.xpath(\"//*[@class='block-link block-link--bordered']\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.kaggle.com/dgunning'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_class_name('avatar').get_attribute(\"href\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LXML rewrite, i think over 100x speed increase lol (maybe not, but still pretty fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsevis(tooltip):\n",
    "    vis = 0\n",
    "    if ('visualizations' in tooltip) or ('visualization' in tooltip):\n",
    "        for i, v in enumerate(tooltip):\n",
    "            if ((v == 'visualizations' or v == 'visualization') and (tooltip[i-1].isdigit())):\n",
    "                vis = int(tooltip[i-1])\n",
    "            elif ((v == 'visualizations' or v == 'visualization') and (not tooltip[i-1].isdigit())):\n",
    "                vis = 0\n",
    "    else:\n",
    "        vis = 0\n",
    "    return vis\n",
    "\n",
    "def parsedata(tooltip):\n",
    "    data = 0\n",
    "    if ('data' in tooltip):\n",
    "        for i, v in enumerate(tooltip):            \n",
    "            if ((v == 'data') and (tooltip[i-1].isdigit())):\n",
    "                data = int(tooltip[i-1])\n",
    "            elif ((v == 'data') and (not tooltip[i-1].isdigit())):\n",
    "                data = 0\n",
    "    else:\n",
    "        data = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'votes': [], 'user_link': [], 'tier': [], 'notebook_name': [], \n",
    "            'num_visualizations': [], 'num_datafiles': [], 'time_published': [], \n",
    "            'relative_time_published': [], 'tags': [], 'language': [], \n",
    "            'num_comments': [], 'notebook_link': []}\n",
    "metadata['votes'] = [each.text for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*/*/*[@class='vote-button__vote-count']\")]\n",
    "metadata['user_link'] = ['https://kaggle.com'+ each.attrib['href'] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*[@class='avatar']\")]\n",
    "metadata['tier'] = [each.attrib['alt'].split(' ')[0] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*/*[@class='avatar__tier']\")]\n",
    "metadata['notebook_name'] = [each.text for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*[@class ='kernel-list-item__name false']\")]              \n",
    "metadata['time_published'] = [each.attrib['title'] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*[@title and self::span]\")]\n",
    "metadata['relative_time_published'] = [each.text for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*[@title and self::span]\")]\n",
    "metadata['tags'] = [[each.text for each in block.xpath(\".//span/div/div[2]/div/div/span[2]/*/*[self::a]\")] for block in tree.xpath(\"//*[@class='block-link block-link--bordered']\")]\n",
    "metadata['language'] = [each.attrib['data-tooltip'].split(' ')[-1:][0] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/span/div/div[2]/div[2]/span[2]\")]\n",
    "metadata['num_comments'] = [re.sub('\\D','',each.attrib['data-tooltip']) for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/span/div/div[2]/div[2]/span[3]\")]\n",
    "metadata['notebook_link'] = ['https://kaggle.com' + each.attrib['href'] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*[self::a]\")]\n",
    "metadata['num_visualizations'] = np.array([parsevis(each.attrib['data-tooltip'][:-1].split(' ')) for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/span/div/div[2]/div[2]/span[1]\")])\n",
    "metadata['num_datafiles'] = np.array([parsedata(each.attrib['data-tooltip'][:-1].split(' ')) for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/span/div/div[2]/div[2]/span[1]\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/dgunning', '/mobassir', '/dirktheeng', '/mlconsult', '/phyothuhtet', '/nofoosports', '/yuanso', '/marcusgawronsky', '/tarunkr', '/dannellyz', '/jiripodivin', '/psrajput', '/gatunnopvp', '/maria17', '/duttadebadri', '/arturkiulian', '/raymondjia', '/maonanwang', '/ajrwhite', '/ritam3144', '/maksimeren', '/mlconsult', '/chuntolee', '/darensin01', '/danielwolffram', '/mikehatchi', '/narasimha1997', '/jpmiller', '/xhlulu', '/nofoosports', '/nofoosports', '/nofoosports', '/ajrwhite', '/nofoosports', '/isaacmg', '/nofoosports', '/nofoosports', '/nofoosports', '/nofoosports', '/daxman', '/tarunpaparaju', '/ahmedewida', '/nofoosports', '/izzatalsmadi', '/uplytics', '/ravitatakc', '/lalitapatel', '/gpreda', '/shahules', '/something4kag', '/nofoosports', '/dannellyz', '/latong', '/sixteenpython', '/cstefanache', '/ratan123', '/saga21', '/group16', '/d4v1d3', '/chaker1', '/ztsincom', '/tanulsingh077', '/paultimothymooney', '/dangelov', '/fmitchell259', '/anuraagsaini', '/ivanegapratama', '/hamid3731', '/dattaraj', '/robbieedwards', '/cedna198', '/danielwolffram', '/zoupet', '/chirag9073', '/mlconsult', '/mlconsult', '/arturkiulian', '/thebooort', '/dangelov', '/albertoferrari', '/fschilder', '/cheenguyen', '/theamrzaki', '/panosc', '/docxian', '/luisblanche', '/mlconsult', '/khoongweihao', '/psrajput', '/nabeelsajid917', '/jdparsons', '/adelfdelvalleperez', '/acmiyaguchi', '/andreamorgar', '/rohailsyed', '/tintedblast', '/crprpr', '/salmanhiro', '/trilabs', '/tylersuard', '/yuanso', '/bs2537', '/mpwolke', '/hamditarek', '/mmoeller', '/mikehoney', '/puneetkochar', '/slander', '/vikassingh1996', '/salmanhiro', '/karankrishna', '/ajrwhite', '/karthikmohan27', '/adityakaushal98', '/willem99', '/alizahidraja', '/ajtamayoh', '/sourojit', '/sourojit', '/raihan1319', '/sunmoon', '/danielwolffram', '/beatrizyumi', '/vasuji', '/ajayago', '/mimisun', '/group16', '/aruncps', '/fmitchell259', '/sandeepbhogaraju', '/andyh47', '/jazivxt', '/onyonixch', '/vasuji', '/salikhussaini49', '/blasteraj', '/ahmednassour', '/stormliucong', '/romangaev', '/shanmukha99', '/somertonman', '/albertoferrari', '/michtyson', '/charlieharper', '/franciswolinski', '/shiromiyuki', '/panosc', '/raheelsyed', '/tourist800', '/dattaraj', '/jonathanbesomi', '/elsonidoq', '/khotijahs1', '/mpwolke', '/arpitrathi', '/dgunning', '/daxman', '/mlconsult', '/umar47', '/midnitekoder', '/otayeby', '/mpwolke', '/guymitch2007', '/houssemayed', '/jonathancarvalho', '/alizahidraja', '/gkaraman', '/rocket95', '/peronneaumoliere', '/edopredo', '/daking', '/youhanlee', '/nishimoto', '/hongzhix', '/tchainzzz', '/mxfeinberg', '/nexussoftware', '/cogitae', '/mpwolke', '/dabrom55', '/etonydev', '/umar47', '/nanar69m', '/mlconsult', '/janthiemen', '/aestheteaman01', '/mayukhdutta', '/qiurui96', '/jitu38', '/acmiyaguchi', '/cristianfat', '/rishav123', '/bgoss541', '/kicksomeasphalt', '/kranzfafka', '/finalepoch', '/doggydev', '/imbano', '/sklasfeld', '/highflyingbird', '/vasuji', '/styluseater', '/goooodday', '/andretc83', '/giuliac', '/priteshraj10', '/thiscuriousquest', '/krups5', '/sunzihao', '/dannellyz', '/candyke', '/eb0x143839', '/dmlombar', '/ranlevy', '/mohamedboussakssou', '/abashareter', '/yatinece', '/modoucair', '/fireballbyedimyrnmom', '/gtteixeira', '/eslambaset', '/adwivedi', '/tschango', '/docxian', '/davidbetancur8', '/shayanfl', '/charlieharper', '/anandsinha2031', '/anthony358', '/samusram', '/acmiyaguchi', '/e0032186', '/fmitchell259', '/jdparsons', '/andrewyue', '/midnitekoder', '/radenkovic', '/mpwolke', '/jeremiahharmsen', '/raymondjia', '/sklasfeld', '/nageshsomayajula', '/anuraglahon', '/dulangaheshan', '/jonathanbesomi', '/morrisb', '/edwardnyameri', '/elsonidoq', '/julienbarthelat', '/mpwolke', '/yjunwoo14', '/eliasgreen', '/danielcruz97', '/sidharthkumar', '/eladwar', '/pierregoutorbe', '/latimerb', '/joeptummers', '/donkeys', '/leonwolber', '/mlconsult', '/takercena', '/sapal6', '/yatinece', '/jbofill', '/mohamedramzi', '/thedocs', '/mlconsult', '/pegger', '/adrianegli', '/volody', '/aaleksei', '/anbu3003', '/kapral42', '/gyimre', '/chahinezounoughi', '/chahinezounoughi', '/imdeepmind', '/pranjalya', '/davidbetancur8', '/iamabdulrazak', '/jonathanbesomi', '/tombresee', '/ronetswaminathan', '/chrismattmann', '/manojkumarvk', '/beatrizyumi', '/lalitapatel', '/jamespatten719', '/ideanlabib', '/subhamrath', '/gpiyama2119', '/leoncz', '/longnguyen2306', '/murthycvln', '/andyh47', '/tajalagawani', '/adhok93', '/cuongnguyen2k', '/aftabuw', '/charlieharper', '/mlutz153', '/noalubin', '/lauraeannielytics', '/thomasadorfer', '/kezhenchen', '/evasnow', '/highflyingbird', '/osciiart', '/induraj2020', '/roadblock', '/highflyingbird', '/morrisb', '/mrclnndrd', '/muhammetfaik', '/imbano', '/kaceywan', '/kaggleperson1', '/beatrandom', '/elfaruq', '/yuelong', '/clmentbisaillon', '/brarajit18', '/jamespatten719', '/zengrun', '/ashish244co', '/henrifroese', '/jaydeepsb', '/vishalsiram50', '/nsteenv', '/kiransubramaniams', '/saisandeepkantareddy', '/eliasgreen', '/amanagr', '/jdj8af', '/hugokce', '/elsonidoq', '/jagannathrk', '/adriensas', '/kamalch', '/garland3', '/something4kag', '/something4kag', '/ivandebono', '/gregcullen2', '/erikinwest', '/skylord', '/joeptummers', '/moazmohammed', '/mlconsult', '/yatinece', '/ekaakurniawan', '/tiashadhar', '/railit', '/tchanda', '/mandeep419', '/edrushton', '/dangizzi', '/dextorkaushik', '/acordova', '/leonardosavasta', '/reyesaldasoro', '/msmelguizo', '/koneill1994', '/bono1020', '/mahtabkamali', '/kdu4108', '/mnaylor5', '/aadharsh0428', '/mathijs02', '/ekaterinamihaylova', '/slander', '/acmiyaguchi', '/kiyoshin', '/menglu', '/nanar69m', '/chahinezounoughi', '/chahinezounoughi', '/chahinezounoughi', '/chahinezounoughi', '/chahinezounoughi', '/wasb143', '/bhagirathl', '/revs96', '/diyoyo', '/thiagodma', '/ducale', '/mtmeanmachine', '/mnaylor5', '/nahdazeez', '/nanar69m', '/rcd1693', '/allen1985', '/lalitapatel', '/lalitapatel', '/lalitapatel', '/zjwa127', '/lalitapatel', '/ashimak01', '/deepshekhar', '/zhcf1ess', '/ajayago', '/anandsrinivasan', '/alexmulo', '/pgromano', '/siddheshkadam', '/ramprakasism', '/enygmasciences', '/aadityaura', '/gabrielmv', '/unzule', '/cotega', '/himanshisingh', '/hiagoaraujo', '/koalabearski', '/harshilkothari', '/sumirp', '/morrisb', '/pathtoai', '/billyzhaoyh', '/brarajit18', '/amogh05', '/something4kag', '/ezekielyovel', '/keshavdudhe', '/ravijoe', '/csierraf', '/mmerino', '/philipalexanderlees', '/psrajput', '/furqanrustam118', '/lalitapatel', '/lalitapatel', '/teju4405', '/yazeenyuvvh', '/tfolkman', '/rahulsarkar906', '/acmiyaguchi', '/rashaddism', '/stanhamster', '/shivampanchal', '/edrushton', '/dskswu', '/pranjalya', '/thebooort', '/manishajain', '/deeshantk', '/ashwininadupuri', '/davidbetancur8', '/vaccine24', '/umar47', '/nerdyaditya', '/verasativa', '/lalitapatel', '/lalitapatel', '/suchivijay', '/joseantoniomanuel', '/manasindia', '/washingtongold', '/aurelepo', '/adriensas', '/shacharosn', '/joseantoniomanuel', '/donkeys', '/candyke', '/mikehoney', '/yuanso', '/mlconsult', '/mlconsult', '/mlconsult', '/mlconsult', '/mlconsult', '/zeeshankeerio', '/slander', '/danich329', '/chahinezounoughi', '/chahinezounoughi', '/processor', '/selfflow', '/pranjalya', '/tchainzzz', '/ramonrw', '/kendelsignore', '/sudhendu', '/anand795', '/srulikbd', '/sudhendu', '/mobasshir', '/skblaz', '/jajsmith']"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['user_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = html.fromstring(driver.page_source)\n",
    "items = tree.xpath(\"//*[@class='block-link block-link--bordered']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = driver.find_elements_by_xpath('//*[@id=\"site-content\"]/div[2]/div[2]/div/div/div/div[1]/div[2]/div[2]/div/div/div/div')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Selenium Parsing :thumbsdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "metadata = {'votes': [], 'user_link': [], 'tier': [], 'notebook_name': [], \n",
    "            'num_visualizations': [], 'num_datafiles': [], 'time_published': [], \n",
    "            'relative_time_published': [], 'tags': [], 'language': [], \n",
    "            'num_comments': [], 'notebook_link': []}\n",
    "tree = html.fromstring(driver.page_source)\n",
    "items = tree.xpath(\"//*[@class='block-link block-link--bordered']\")\n",
    "for i, each in enumerate(items):\n",
    "    if (i%50==0):\n",
    "        print(i)\n",
    "    metadata['votes'].append(int(each.find_element_by_class_name(\"vote-button__vote-count\").text))\n",
    "    metadata['user_link'].append(each.find_element_by_class_name('avatar').get_attribute(\"href\"))\n",
    "    metadata['tier'].append(each.find_element_by_class_name('avatar__tier').get_attribute('alt').split(' ')[0])\n",
    "    metadata['notebook_name'].append(each.find_element_by_class_name('kernel-list-item__name').text)\n",
    "    tooltip = each.find_element_by_class_name('kernel-list-item__info-blocks')\\\n",
    "              .find_element_by_xpath('.//span[1]').get_attribute('data-tooltip')[:-1].split(' ')\n",
    "    if ('visualizations' in tooltip) or ('visualization' in tooltip):\n",
    "        for i, v in enumerate(tooltip):\n",
    "            if ((v == 'visualizations' or v == 'visualization') and (tooltip[i-1].isdigit())):\n",
    "                metadata['num_visualizations'].append(int(tooltip[i-1]))\n",
    "            elif ((v == 'visualizations' or v == 'visualization') and (not tooltip[i-1].isdigit())):\n",
    "                metadata['num_visualizations'].append(0)\n",
    "    else:\n",
    "        metadata['num_visualizations'].append(0)\n",
    "    if ('data' in tooltip):\n",
    "        for i, v in enumerate(tooltip):            \n",
    "            if ((v == 'data') and (tooltip[i-1].isdigit())):\n",
    "                metadata['num_datafiles'].append(int(tooltip[i-1]))\n",
    "            elif ((v == 'data') and (not tooltip[i-1].isdigit())):\n",
    "                metadata['num_datafiles'].append(0)\n",
    "    else:\n",
    "        metadata['num_datafiles'].append(0)\n",
    "    metadata['time_published'].append(each.find_element_by_class_name('kernel-list-item__details').\\\n",
    "                                          find_element_by_xpath('.//*[@title]').get_attribute('title'))\n",
    "    metadata['relative_time_published'].append(each.find_element_by_class_name('kernel-list-item__details').\\\n",
    "                                              find_element_by_xpath('.//*[@title]').text)\n",
    "    metadata['tags'].append([each.text for each in\\\n",
    "                             each.find_elements_by_class_name('Tag_TextAnchor-sc-hezo17')\\\n",
    "                             if each.text != ''])\n",
    "    metadata['language'].append(each.find_element_by_class_name('kernel-list-item__info-blocks')\\\n",
    "                  .find_element_by_xpath('.//span[2]').get_attribute(\"data-tooltip\").split(' ')[-1:][0])\n",
    "    metadata['num_comments'].append(re.sub('\\D', '', each.find_element_by_class_name('kernel-list-item__info-blocks')\\\n",
    "                  .find_element_by_xpath('.//span[3]').get_attribute(\"data-tooltip\")))\n",
    "    metadata['notebook_link'].append(each.find_element_by_xpath('.//a').get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started webdriver, loading elements\n",
      "loaded elements, scraping\n",
      "done scraping, writing csv\n",
      "done writing csv\n"
     ]
    }
   ],
   "source": [
    "def parsevis(tooltip):\n",
    "    vis = 0\n",
    "    if ('visualizations' in tooltip) or ('visualization' in tooltip):\n",
    "        for i, v in enumerate(tooltip):\n",
    "            if ((v == 'visualizations' or v == 'visualization') and (tooltip[i-1].isdigit())):\n",
    "                vis = int(tooltip[i-1])\n",
    "            elif ((v == 'visualizations' or v == 'visualization') and (not tooltip[i-1].isdigit())):\n",
    "                vis = 0\n",
    "    else:\n",
    "        vis = 0\n",
    "    return vis\n",
    "\n",
    "def parsedata(tooltip):\n",
    "    data = 0\n",
    "    if ('data' in tooltip):\n",
    "        for i, v in enumerate(tooltip):            \n",
    "            if ((v == 'data') and (tooltip[i-1].isdigit())):\n",
    "                data = int(tooltip[i-1])\n",
    "            elif ((v == 'data') and (not tooltip[i-1].isdigit())):\n",
    "                data = 0\n",
    "    else:\n",
    "        data = 0\n",
    "    return data\n",
    "\n",
    "webdriver = 'chromedriver_win32/chromedriver.exe'\n",
    "\n",
    "driver = Chrome(webdriver)#, options=chrome_options)\n",
    "url = \"https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/kernels\"\n",
    "driver.get(url)\n",
    "print ('started webdriver, loading elements')\n",
    "\n",
    "actions = ActionChains(driver)\n",
    "driver.find_element_by_class_name(\"dataset-header-v2__title\").click()\n",
    "while (driver.find_element_by_class_name(\"smart-list__message\").text != 'No more notebooks to show'):\n",
    "    actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "print('loaded elements, scraping')\n",
    "    \n",
    "tree = html.fromstring(driver.page_source)\n",
    "metadata = {'votes': [], 'user_link': [], 'tier': [], 'notebook_name': [], \n",
    "            'num_visualizations': [], 'num_datafiles': [], 'time_published': [], \n",
    "            'relative_time_published': [], 'tags': [], 'language': [], \n",
    "            'num_comments': [], 'notebook_link': []}\n",
    "metadata['votes'] = [each.text for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*/*/*[@class='vote-button__vote-count']\")]\n",
    "metadata['user_link'] = ['https://kaggle.com'+ each.attrib['href'] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*[@class='avatar']\")]\n",
    "metadata['tier'] = [each.attrib['alt'].split(' ')[0] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*/*[@class='avatar__tier']\")]\n",
    "metadata['notebook_name'] = [each.text for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*[@class ='kernel-list-item__name false']\")]              \n",
    "metadata['time_published'] = [each.attrib['title'] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*[@title and self::span]\")]\n",
    "metadata['relative_time_published'] = [each.text for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*/*/*/*/*/*[@title and self::span]\")]\n",
    "metadata['tags'] = [[each.text for each in block.xpath(\".//span/div/div[2]/div/div/span[2]/*/*[self::a]\")] for block in tree.xpath(\"//*[@class='block-link block-link--bordered']\")]\n",
    "metadata['language'] = [each.attrib['data-tooltip'].split(' ')[-1:][0] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/span/div/div[2]/div[2]/span[2]\")]\n",
    "metadata['num_comments'] = [re.sub('\\D','',each.attrib['data-tooltip']) for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/span/div/div[2]/div[2]/span[3]\")]\n",
    "metadata['notebook_link'] = ['https://kaggle.com' + each.attrib['href'] for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/*[self::a]\")]\n",
    "metadata['num_visualizations'] = np.array([parsevis(each.attrib['data-tooltip'][:-1].split(' ')) for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/span/div/div[2]/div[2]/span[1]\")])\n",
    "metadata['num_datafiles'] = np.array([parsedata(each.attrib['data-tooltip'][:-1].split(' ')) for each in tree.xpath(\"//*[@class='block-link block-link--bordered']/span/div/div[2]/div[2]/span[1]\")])\n",
    "print('done scraping, writing csv')\n",
    "\n",
    "meta_df = pd.DataFrame.from_dict(metadata)\n",
    "meta_df.to_csv(\"covid-kernels.csv\", index = False)\n",
    "print('done writing csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'votes': [111,\n",
       "  87,\n",
       "  272,\n",
       "  36,\n",
       "  181,\n",
       "  3,\n",
       "  6,\n",
       "  1,\n",
       "  3,\n",
       "  13,\n",
       "  10,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  44,\n",
       "  0,\n",
       "  57,\n",
       "  4,\n",
       "  1,\n",
       "  404,\n",
       "  12,\n",
       "  283,\n",
       "  0,\n",
       "  265,\n",
       "  199,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  97,\n",
       "  95,\n",
       "  94,\n",
       "  1,\n",
       "  18,\n",
       "  15,\n",
       "  63,\n",
       "  1,\n",
       "  25,\n",
       "  48,\n",
       "  55,\n",
       "  0,\n",
       "  0,\n",
       "  52,\n",
       "  28,\n",
       "  46,\n",
       "  43,\n",
       "  0,\n",
       "  0,\n",
       "  24,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  13,\n",
       "  10,\n",
       "  0,\n",
       "  17,\n",
       "  27,\n",
       "  6,\n",
       "  16,\n",
       "  1,\n",
       "  2,\n",
       "  6,\n",
       "  15,\n",
       "  23,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  19,\n",
       "  19,\n",
       "  0,\n",
       "  0,\n",
       "  17,\n",
       "  2,\n",
       "  17,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  15,\n",
       "  5,\n",
       "  5,\n",
       "  15,\n",
       "  6,\n",
       "  14,\n",
       "  14,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  13,\n",
       "  3,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  1,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  6,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'user_link': ['https://www.kaggle.com/tarunkr',\n",
       "  'https://www.kaggle.com/arturkiulian',\n",
       "  'https://www.kaggle.com/dgunning',\n",
       "  'https://www.kaggle.com/maria17',\n",
       "  'https://www.kaggle.com/danielwolffram',\n",
       "  'https://www.kaggle.com/albertoferrari',\n",
       "  'https://www.kaggle.com/ajrwhite',\n",
       "  'https://www.kaggle.com/cedna198',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/dirktheeng',\n",
       "  'https://www.kaggle.com/yuanso',\n",
       "  'https://www.kaggle.com/rocket95',\n",
       "  'https://www.kaggle.com/dgunning',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/fschilder',\n",
       "  'https://www.kaggle.com/anuraagsaini',\n",
       "  'https://www.kaggle.com/raymondjia',\n",
       "  'https://www.kaggle.com/salikhussaini49',\n",
       "  'https://www.kaggle.com/dannellyz',\n",
       "  'https://www.kaggle.com/eb0x143839',\n",
       "  'https://www.kaggle.com/ajayago',\n",
       "  'https://www.kaggle.com/cstefanache',\n",
       "  'https://www.kaggle.com/joeptummers',\n",
       "  'https://www.kaggle.com/nofoosports',\n",
       "  'https://www.kaggle.com/arpitrathi',\n",
       "  'https://www.kaggle.com/sunzihao',\n",
       "  'https://www.kaggle.com/maksimeren',\n",
       "  'https://www.kaggle.com/isaacmg',\n",
       "  'https://www.kaggle.com/xhlulu',\n",
       "  'https://www.kaggle.com/sapal6',\n",
       "  'https://www.kaggle.com/jpmiller',\n",
       "  'https://www.kaggle.com/tarunpaparaju',\n",
       "  'https://www.kaggle.com/jiripodivin',\n",
       "  'https://www.kaggle.com/donkeys',\n",
       "  'https://www.kaggle.com/etonydev',\n",
       "  'https://www.kaggle.com/mobassir',\n",
       "  'https://www.kaggle.com/gpreda',\n",
       "  'https://www.kaggle.com/shahules',\n",
       "  'https://www.kaggle.com/leonwolber',\n",
       "  'https://www.kaggle.com/luisblanche',\n",
       "  'https://www.kaggle.com/duttadebadri',\n",
       "  'https://www.kaggle.com/sixteenpython',\n",
       "  'https://www.kaggle.com/csierraf',\n",
       "  'https://www.kaggle.com/chirag9073',\n",
       "  'https://www.kaggle.com/d4v1d3',\n",
       "  'https://www.kaggle.com/ratan123',\n",
       "  'https://www.kaggle.com/ivandebono',\n",
       "  'https://www.kaggle.com/chuntolee',\n",
       "  'https://www.kaggle.com/saga21',\n",
       "  'https://www.kaggle.com/ajrwhite',\n",
       "  'https://www.kaggle.com/tanulsingh077',\n",
       "  'https://www.kaggle.com/paultimothymooney',\n",
       "  'https://www.kaggle.com/mikehoney',\n",
       "  'https://www.kaggle.com/krups5',\n",
       "  'https://www.kaggle.com/ztsincom',\n",
       "  'https://www.kaggle.com/erikinwest',\n",
       "  'https://www.kaggle.com/danielwolffram',\n",
       "  'https://www.kaggle.com/dabrom55',\n",
       "  'https://www.kaggle.com/skylord',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/beatrizyumi',\n",
       "  'https://www.kaggle.com/joeptummers',\n",
       "  'https://www.kaggle.com/adelfdelvalleperez',\n",
       "  'https://www.kaggle.com/fmitchell259',\n",
       "  'https://www.kaggle.com/theamrzaki',\n",
       "  'https://www.kaggle.com/acmiyaguchi',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/ahmedewida',\n",
       "  'https://www.kaggle.com/michtyson',\n",
       "  'https://www.kaggle.com/salmanhiro',\n",
       "  'https://www.kaggle.com/ivanegapratama',\n",
       "  'https://www.kaggle.com/moazmohammed',\n",
       "  'https://www.kaggle.com/khoongweihao',\n",
       "  'https://www.kaggle.com/group16',\n",
       "  'https://www.kaggle.com/panosc',\n",
       "  'https://www.kaggle.com/docxian',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/andreamorgar',\n",
       "  'https://www.kaggle.com/albertoferrari',\n",
       "  'https://www.kaggle.com/umar47',\n",
       "  'https://www.kaggle.com/jdparsons',\n",
       "  'https://www.kaggle.com/janthiemen',\n",
       "  'https://www.kaggle.com/mmoeller',\n",
       "  'https://www.kaggle.com/yatinece',\n",
       "  'https://www.kaggle.com/dannellyz',\n",
       "  'https://www.kaggle.com/rohailsyed',\n",
       "  'https://www.kaggle.com/guymitch2007',\n",
       "  'https://www.kaggle.com/houssemayed',\n",
       "  'https://www.kaggle.com/crprpr',\n",
       "  'https://www.kaggle.com/charlieharper',\n",
       "  'https://www.kaggle.com/mpwolke',\n",
       "  'https://www.kaggle.com/hamid3731',\n",
       "  'https://www.kaggle.com/dmlombar',\n",
       "  'https://www.kaggle.com/karthikmohan27',\n",
       "  'https://www.kaggle.com/takercena',\n",
       "  'https://www.kaggle.com/rishav123',\n",
       "  'https://www.kaggle.com/hamditarek',\n",
       "  'https://www.kaggle.com/nanar69m',\n",
       "  'https://www.kaggle.com/dattaraj',\n",
       "  'https://www.kaggle.com/salmanhiro',\n",
       "  'https://www.kaggle.com/karankrishna',\n",
       "  'https://www.kaggle.com/yatinece',\n",
       "  'https://www.kaggle.com/alizahidraja',\n",
       "  'https://www.kaggle.com/sunmoon',\n",
       "  'https://www.kaggle.com/danielwolffram',\n",
       "  'https://www.kaggle.com/vasuji',\n",
       "  'https://www.kaggle.com/mimisun',\n",
       "  'https://www.kaggle.com/ekaakurniawan',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/jbofill',\n",
       "  'https://www.kaggle.com/aruncps',\n",
       "  'https://www.kaggle.com/andyh47',\n",
       "  'https://www.kaggle.com/jazivxt',\n",
       "  'https://www.kaggle.com/fmitchell259',\n",
       "  'https://www.kaggle.com/onyonixch',\n",
       "  'https://www.kaggle.com/vasuji',\n",
       "  'https://www.kaggle.com/psrajput',\n",
       "  'https://www.kaggle.com/ahmednassour',\n",
       "  'https://www.kaggle.com/group16',\n",
       "  'https://www.kaggle.com/stormliucong',\n",
       "  'https://www.kaggle.com/romangaev',\n",
       "  'https://www.kaggle.com/shiromiyuki',\n",
       "  'https://www.kaggle.com/panosc',\n",
       "  'https://www.kaggle.com/raheelsyed',\n",
       "  'https://www.kaggle.com/tourist800',\n",
       "  'https://www.kaggle.com/dattaraj',\n",
       "  'https://www.kaggle.com/jonathanbesomi',\n",
       "  'https://www.kaggle.com/khotijahs1',\n",
       "  'https://www.kaggle.com/shanmukha99',\n",
       "  'https://www.kaggle.com/mpwolke',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/otayeby',\n",
       "  'https://www.kaggle.com/franciswolinski',\n",
       "  'https://www.kaggle.com/nabeelsajid917',\n",
       "  'https://www.kaggle.com/mpwolke',\n",
       "  'https://www.kaggle.com/jonathancarvalho',\n",
       "  'https://www.kaggle.com/elsonidoq',\n",
       "  'https://www.kaggle.com/alizahidraja',\n",
       "  'https://www.kaggle.com/gkaraman',\n",
       "  'https://www.kaggle.com/midnitekoder',\n",
       "  'https://www.kaggle.com/edopredo',\n",
       "  'https://www.kaggle.com/daking',\n",
       "  'https://www.kaggle.com/uplytics',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/tintedblast',\n",
       "  'https://www.kaggle.com/mohamedramzi',\n",
       "  'https://www.kaggle.com/zoupet',\n",
       "  'https://www.kaggle.com/youhanlee',\n",
       "  'https://www.kaggle.com/nishimoto',\n",
       "  'https://www.kaggle.com/hongzhix',\n",
       "  'https://www.kaggle.com/tchainzzz',\n",
       "  'https://www.kaggle.com/mxfeinberg',\n",
       "  'https://www.kaggle.com/nexussoftware',\n",
       "  'https://www.kaggle.com/cogitae',\n",
       "  'https://www.kaggle.com/trilabs',\n",
       "  'https://www.kaggle.com/mpwolke',\n",
       "  'https://www.kaggle.com/aestheteaman01',\n",
       "  'https://www.kaggle.com/maonanwang',\n",
       "  'https://www.kaggle.com/thedocs',\n",
       "  'https://www.kaggle.com/railit',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/puneetkochar',\n",
       "  'https://www.kaggle.com/mayukhdutta',\n",
       "  'https://www.kaggle.com/qiurui96',\n",
       "  'https://www.kaggle.com/jitu38',\n",
       "  'https://www.kaggle.com/acmiyaguchi',\n",
       "  'https://www.kaggle.com/cristianfat',\n",
       "  'https://www.kaggle.com/bs2537',\n",
       "  'https://www.kaggle.com/bgoss541',\n",
       "  'https://www.kaggle.com/kicksomeasphalt',\n",
       "  'https://www.kaggle.com/kranzfafka',\n",
       "  'https://www.kaggle.com/finalepoch',\n",
       "  'https://www.kaggle.com/doggydev',\n",
       "  'https://www.kaggle.com/imbano',\n",
       "  'https://www.kaggle.com/tylersuard',\n",
       "  'https://www.kaggle.com/sklasfeld',\n",
       "  'https://www.kaggle.com/highflyingbird',\n",
       "  'https://www.kaggle.com/vasuji',\n",
       "  'https://www.kaggle.com/styluseater',\n",
       "  'https://www.kaggle.com/goooodday',\n",
       "  'https://www.kaggle.com/andretc83',\n",
       "  'https://www.kaggle.com/giuliac',\n",
       "  'https://www.kaggle.com/priteshraj10',\n",
       "  'https://www.kaggle.com/thiscuriousquest',\n",
       "  'https://www.kaggle.com/tchanda',\n",
       "  'https://www.kaggle.com/pegger',\n",
       "  'https://www.kaggle.com/adrianegli',\n",
       "  'https://www.kaggle.com/ranlevy',\n",
       "  'https://www.kaggle.com/mohamedboussakssou',\n",
       "  'https://www.kaggle.com/psrajput',\n",
       "  'https://www.kaggle.com/abashareter',\n",
       "  'https://www.kaggle.com/yatinece',\n",
       "  'https://www.kaggle.com/modoucair',\n",
       "  'https://www.kaggle.com/fireballbyedimyrnmom',\n",
       "  'https://www.kaggle.com/gtteixeira',\n",
       "  'https://www.kaggle.com/eslambaset',\n",
       "  'https://www.kaggle.com/adwivedi',\n",
       "  'https://www.kaggle.com/tschango',\n",
       "  'https://www.kaggle.com/docxian',\n",
       "  'https://www.kaggle.com/davidbetancur8',\n",
       "  'https://www.kaggle.com/shayanfl',\n",
       "  'https://www.kaggle.com/charlieharper',\n",
       "  'https://www.kaggle.com/anandsinha2031',\n",
       "  'https://www.kaggle.com/anthony358',\n",
       "  'https://www.kaggle.com/samusram',\n",
       "  'https://www.kaggle.com/acmiyaguchi',\n",
       "  'https://www.kaggle.com/e0032186',\n",
       "  'https://www.kaggle.com/fmitchell259',\n",
       "  'https://www.kaggle.com/jdparsons',\n",
       "  'https://www.kaggle.com/andrewyue',\n",
       "  'https://www.kaggle.com/midnitekoder',\n",
       "  'https://www.kaggle.com/radenkovic',\n",
       "  'https://www.kaggle.com/mpwolke',\n",
       "  'https://www.kaggle.com/jeremiahharmsen',\n",
       "  'https://www.kaggle.com/raymondjia',\n",
       "  'https://www.kaggle.com/sklasfeld',\n",
       "  'https://www.kaggle.com/nageshsomayajula',\n",
       "  'https://www.kaggle.com/anuraglahon',\n",
       "  'https://www.kaggle.com/dulangaheshan',\n",
       "  'https://www.kaggle.com/jonathanbesomi',\n",
       "  'https://www.kaggle.com/morrisb',\n",
       "  'https://www.kaggle.com/edwardnyameri',\n",
       "  'https://www.kaggle.com/elsonidoq',\n",
       "  'https://www.kaggle.com/julienbarthelat',\n",
       "  'https://www.kaggle.com/mpwolke',\n",
       "  'https://www.kaggle.com/yjunwoo14',\n",
       "  'https://www.kaggle.com/eliasgreen',\n",
       "  'https://www.kaggle.com/danielcruz97',\n",
       "  'https://www.kaggle.com/sidharthkumar',\n",
       "  'https://www.kaggle.com/eladwar',\n",
       "  'https://www.kaggle.com/pierregoutorbe',\n",
       "  'https://www.kaggle.com/latimerb',\n",
       "  'https://www.kaggle.com/mandeep419',\n",
       "  'https://www.kaggle.com/volody',\n",
       "  'https://www.kaggle.com/slander',\n",
       "  'https://www.kaggle.com/aaleksei',\n",
       "  'https://www.kaggle.com/anbu3003',\n",
       "  'https://www.kaggle.com/kapral42',\n",
       "  'https://www.kaggle.com/gyimre',\n",
       "  'https://www.kaggle.com/edrushton',\n",
       "  'https://www.kaggle.com/chahinezounoughi',\n",
       "  'https://www.kaggle.com/imdeepmind',\n",
       "  'https://www.kaggle.com/pranjalya',\n",
       "  'https://www.kaggle.com/davidbetancur8',\n",
       "  'https://www.kaggle.com/iamabdulrazak',\n",
       "  'https://www.kaggle.com/jonathanbesomi',\n",
       "  'https://www.kaggle.com/tombresee',\n",
       "  'https://www.kaggle.com/ronetswaminathan',\n",
       "  'https://www.kaggle.com/chrismattmann',\n",
       "  'https://www.kaggle.com/manojkumarvk',\n",
       "  'https://www.kaggle.com/latong',\n",
       "  'https://www.kaggle.com/vikassingh1996',\n",
       "  'https://www.kaggle.com/beatrizyumi',\n",
       "  'https://www.kaggle.com/lalitapatel',\n",
       "  'https://www.kaggle.com/jamespatten719',\n",
       "  'https://www.kaggle.com/ideanlabib',\n",
       "  'https://www.kaggle.com/subhamrath',\n",
       "  'https://www.kaggle.com/gpiyama2119',\n",
       "  'https://www.kaggle.com/leoncz',\n",
       "  'https://www.kaggle.com/longnguyen2306',\n",
       "  'https://www.kaggle.com/murthycvln',\n",
       "  'https://www.kaggle.com/andyh47',\n",
       "  'https://www.kaggle.com/tajalagawani',\n",
       "  'https://www.kaggle.com/adhok93',\n",
       "  'https://www.kaggle.com/cuongnguyen2k',\n",
       "  'https://www.kaggle.com/aftabuw',\n",
       "  'https://www.kaggle.com/charlieharper',\n",
       "  'https://www.kaggle.com/mlutz153',\n",
       "  'https://www.kaggle.com/noalubin',\n",
       "  'https://www.kaggle.com/thomasadorfer',\n",
       "  'https://www.kaggle.com/kezhenchen',\n",
       "  'https://www.kaggle.com/evasnow',\n",
       "  'https://www.kaggle.com/highflyingbird',\n",
       "  'https://www.kaggle.com/osciiart',\n",
       "  'https://www.kaggle.com/induraj2020',\n",
       "  'https://www.kaggle.com/roadblock',\n",
       "  'https://www.kaggle.com/highflyingbird',\n",
       "  'https://www.kaggle.com/morrisb',\n",
       "  'https://www.kaggle.com/mrclnndrd',\n",
       "  'https://www.kaggle.com/muhammetfaik',\n",
       "  'https://www.kaggle.com/imbano',\n",
       "  'https://www.kaggle.com/kaceywan',\n",
       "  'https://www.kaggle.com/kaggleperson1',\n",
       "  'https://www.kaggle.com/beatrandom',\n",
       "  'https://www.kaggle.com/elfaruq',\n",
       "  'https://www.kaggle.com/yuelong',\n",
       "  'https://www.kaggle.com/clmentbisaillon',\n",
       "  'https://www.kaggle.com/brarajit18',\n",
       "  'https://www.kaggle.com/jamespatten719',\n",
       "  'https://www.kaggle.com/zengrun',\n",
       "  'https://www.kaggle.com/ashish244co',\n",
       "  'https://www.kaggle.com/henrifroese',\n",
       "  'https://www.kaggle.com/jaydeepsb',\n",
       "  'https://www.kaggle.com/vishalsiram50',\n",
       "  'https://www.kaggle.com/nsteenv',\n",
       "  'https://www.kaggle.com/kiransubramaniams',\n",
       "  'https://www.kaggle.com/saisandeepkantareddy',\n",
       "  'https://www.kaggle.com/eliasgreen',\n",
       "  'https://www.kaggle.com/amanagr',\n",
       "  'https://www.kaggle.com/jdj8af',\n",
       "  'https://www.kaggle.com/hugokce',\n",
       "  'https://www.kaggle.com/elsonidoq',\n",
       "  'https://www.kaggle.com/jagannathrk',\n",
       "  'https://www.kaggle.com/adriensas',\n",
       "  'https://www.kaggle.com/kamalch',\n",
       "  'https://www.kaggle.com/garland3',\n",
       "  'https://www.kaggle.com/dangizzi',\n",
       "  'https://www.kaggle.com/dextorkaushik',\n",
       "  'https://www.kaggle.com/acordova',\n",
       "  'https://www.kaggle.com/leonardosavasta',\n",
       "  'https://www.kaggle.com/reyesaldasoro',\n",
       "  'https://www.kaggle.com/msmelguizo',\n",
       "  'https://www.kaggle.com/koneill1994',\n",
       "  'https://www.kaggle.com/bono1020',\n",
       "  'https://www.kaggle.com/mahtabkamali',\n",
       "  'https://www.kaggle.com/kdu4108',\n",
       "  'https://www.kaggle.com/mnaylor5',\n",
       "  'https://www.kaggle.com/aadharsh0428',\n",
       "  'https://www.kaggle.com/mathijs02',\n",
       "  'https://www.kaggle.com/adityakaushal98',\n",
       "  'https://www.kaggle.com/ekaterinamihaylova',\n",
       "  'https://www.kaggle.com/slander',\n",
       "  'https://www.kaggle.com/acmiyaguchi',\n",
       "  'https://www.kaggle.com/kiyoshin',\n",
       "  'https://www.kaggle.com/menglu',\n",
       "  'https://www.kaggle.com/nanar69m',\n",
       "  'https://www.kaggle.com/chahinezounoughi',\n",
       "  'https://www.kaggle.com/chahinezounoughi',\n",
       "  'https://www.kaggle.com/chahinezounoughi',\n",
       "  'https://www.kaggle.com/chahinezounoughi',\n",
       "  'https://www.kaggle.com/chahinezounoughi',\n",
       "  'https://www.kaggle.com/chahinezounoughi',\n",
       "  'https://www.kaggle.com/wasb143',\n",
       "  'https://www.kaggle.com/bhagirathl',\n",
       "  'https://www.kaggle.com/revs96',\n",
       "  'https://www.kaggle.com/diyoyo',\n",
       "  'https://www.kaggle.com/thiagodma',\n",
       "  'https://www.kaggle.com/ducale',\n",
       "  'https://www.kaggle.com/mtmeanmachine',\n",
       "  'https://www.kaggle.com/mnaylor5',\n",
       "  'https://www.kaggle.com/nahdazeez',\n",
       "  'https://www.kaggle.com/nanar69m',\n",
       "  'https://www.kaggle.com/rcd1693',\n",
       "  'https://www.kaggle.com/allen1985',\n",
       "  'https://www.kaggle.com/willem99',\n",
       "  'https://www.kaggle.com/lalitapatel',\n",
       "  'https://www.kaggle.com/lalitapatel',\n",
       "  'https://www.kaggle.com/lalitapatel',\n",
       "  'https://www.kaggle.com/zjwa127',\n",
       "  'https://www.kaggle.com/lalitapatel',\n",
       "  'https://www.kaggle.com/ashimak01',\n",
       "  'https://www.kaggle.com/deepshekhar',\n",
       "  'https://www.kaggle.com/zhcf1ess',\n",
       "  'https://www.kaggle.com/ajayago',\n",
       "  'https://www.kaggle.com/anandsrinivasan',\n",
       "  'https://www.kaggle.com/alexmulo',\n",
       "  'https://www.kaggle.com/pgromano',\n",
       "  'https://www.kaggle.com/siddheshkadam',\n",
       "  'https://www.kaggle.com/ramprakasism',\n",
       "  'https://www.kaggle.com/enygmasciences',\n",
       "  'https://www.kaggle.com/aadityaura',\n",
       "  'https://www.kaggle.com/gabrielmv',\n",
       "  'https://www.kaggle.com/unzule',\n",
       "  'https://www.kaggle.com/cotega',\n",
       "  'https://www.kaggle.com/himanshisingh',\n",
       "  'https://www.kaggle.com/hiagoaraujo',\n",
       "  'https://www.kaggle.com/koalabearski',\n",
       "  'https://www.kaggle.com/harshilkothari',\n",
       "  'https://www.kaggle.com/sumirp',\n",
       "  'https://www.kaggle.com/morrisb',\n",
       "  'https://www.kaggle.com/pathtoai',\n",
       "  'https://www.kaggle.com/billyzhaoyh',\n",
       "  'https://www.kaggle.com/brarajit18',\n",
       "  'https://www.kaggle.com/amogh05',\n",
       "  'https://www.kaggle.com/acmiyaguchi',\n",
       "  'https://www.kaggle.com/philipalexanderlees',\n",
       "  'https://www.kaggle.com/rashaddism',\n",
       "  'https://www.kaggle.com/stanhamster',\n",
       "  'https://www.kaggle.com/daxman',\n",
       "  'https://www.kaggle.com/shivampanchal',\n",
       "  'https://www.kaggle.com/edrushton',\n",
       "  'https://www.kaggle.com/mmerino',\n",
       "  'https://www.kaggle.com/dskswu',\n",
       "  'https://www.kaggle.com/furqanrustam118',\n",
       "  'https://www.kaggle.com/lalitapatel',\n",
       "  'https://www.kaggle.com/lalitapatel',\n",
       "  'https://www.kaggle.com/teju4405',\n",
       "  'https://www.kaggle.com/yazeenyuvvh',\n",
       "  'https://www.kaggle.com/tfolkman',\n",
       "  'https://www.kaggle.com/rahulsarkar906',\n",
       "  'https://www.kaggle.com/pranjalya',\n",
       "  'https://www.kaggle.com/thebooort',\n",
       "  'https://www.kaggle.com/manishajain',\n",
       "  'https://www.kaggle.com/deeshantk',\n",
       "  'https://www.kaggle.com/ashwininadupuri',\n",
       "  'https://www.kaggle.com/davidbetancur8',\n",
       "  'https://www.kaggle.com/vaccine24',\n",
       "  'https://www.kaggle.com/umar47',\n",
       "  'https://www.kaggle.com/nerdyaditya',\n",
       "  'https://www.kaggle.com/verasativa',\n",
       "  'https://www.kaggle.com/lalitapatel',\n",
       "  'https://www.kaggle.com/lalitapatel',\n",
       "  'https://www.kaggle.com/suchivijay',\n",
       "  'https://www.kaggle.com/joseantoniomanuel',\n",
       "  'https://www.kaggle.com/manasindia',\n",
       "  'https://www.kaggle.com/lauraeannielytics',\n",
       "  'https://www.kaggle.com/washingtongold',\n",
       "  'https://www.kaggle.com/aurelepo',\n",
       "  'https://www.kaggle.com/adriensas',\n",
       "  'https://www.kaggle.com/shacharosn',\n",
       "  'https://www.kaggle.com/joseantoniomanuel',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/dangelov',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/mlconsult',\n",
       "  'https://www.kaggle.com/zeeshankeerio',\n",
       "  'https://www.kaggle.com/something4kag',\n",
       "  'https://www.kaggle.com/cheenguyen',\n",
       "  'https://www.kaggle.com/slander',\n",
       "  'https://www.kaggle.com/chahinezounoughi',\n",
       "  'https://www.kaggle.com/chahinezounoughi',\n",
       "  'https://www.kaggle.com/processor',\n",
       "  'https://www.kaggle.com/selfflow',\n",
       "  'https://www.kaggle.com/pranjalya',\n",
       "  'https://www.kaggle.com/tchainzzz',\n",
       "  'https://www.kaggle.com/ramonrw',\n",
       "  'https://www.kaggle.com/kendelsignore',\n",
       "  'https://www.kaggle.com/sudhendu',\n",
       "  'https://www.kaggle.com/anand795',\n",
       "  'https://www.kaggle.com/srulikbd',\n",
       "  'https://www.kaggle.com/sudhendu',\n",
       "  'https://www.kaggle.com/skblaz',\n",
       "  'https://www.kaggle.com/jajsmith'],\n",
       " 'tier': ['novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'grandmaster',\n",
       "  'novice',\n",
       "  'master',\n",
       "  'master',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'master',\n",
       "  'grandmaster',\n",
       "  'master',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'master',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'staff',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'master',\n",
       "  'expert',\n",
       "  'master',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'master',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'master',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'master',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'master',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'expert',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice',\n",
       "  'contributor',\n",
       "  'novice',\n",
       "  'novice'],\n",
       " 'notebook_name': ['COVID-19 Case Study - Analysis, Viz & Comparisons',\n",
       "  'CoronaWhy.org - Global Collaboration (join slack)',\n",
       "  'Browsing research papers with a BM25 search engine',\n",
       "  'CORD-19: Explore Drugs Being Developed',\n",
       "  'Topic Modeling: Finding Related Articles',\n",
       "  '\"Learning\" Medicine with Word Embeddings ‚öïÔ∏èüíäüíâ',\n",
       "  'COVID-19 Transmission and incubation',\n",
       "  'Visualization of Virus Origin & Genetic Evolution',\n",
       "  'Air Temperature and COVID-19',\n",
       "  'Anserini+BERT-SQuAD for context corpus search',\n",
       "  'COVID-19 Four different epidemic situations',\n",
       "  'covid-19-incubation-time',\n",
       "  'A CORD19 Research Paper Search Engine',\n",
       "  'Age Dependent Incubation Period',\n",
       "  'Asking questions with a BM25/BERT',\n",
       "  'Corona Virus Data Visualization',\n",
       "  '3D World Heat Map of Cumulative Confirmed Case',\n",
       "  'Exploratory Data Analysis covid-19 from eCDC',\n",
       "  'CORD-19 Metadata Enrich [2/x]: Altmetric API',\n",
       "  'Convert COVID-19 papers to Entity Vectors',\n",
       "  'CORD-19 Topic Modelling',\n",
       "  'NLP Text Mining - Disease behavior',\n",
       "  'COVID-2019-ID Paper version',\n",
       "  'CORD-19 Analysis with Sentence Embeddings',\n",
       "  'Utilizing BioBERT for K-means Topic Clustering',\n",
       "  'A Brief Talk on COVID-19',\n",
       "  'COVID-19 Literature Clustering',\n",
       "  'SciBERT Embeddings',\n",
       "  'CORD-19: EDA, parse JSON and generate clean CSV\\U0001f9f9',\n",
       "  'covid-19 research paper language model',\n",
       "  'Creating a Good Analytics Report',\n",
       "  'COVID-19 Dataset : Gaining actionable insights üìä',\n",
       "  'covsum',\n",
       "  'Languages...',\n",
       "  'Abstract Summarization with Transformers & BART',\n",
       "  'üò∑Mining COVID-19 scientific papers\\U0001f9a0',\n",
       "  'CORD-19 Solution Toolbox',\n",
       "  'CORD : Tools and Knowledge graphs',\n",
       "  'COVID-19 text mining',\n",
       "  'CORD-19 Match articles to tasks w/ Doc2Vec',\n",
       "  'COVID-19 Analysing Growth Factor & Inflection',\n",
       "  'COVID-19 - Temperature, Air Travel & Transmission',\n",
       "  'A few peek',\n",
       "  'CoronaVirus (COVID-19) Outbreak Data Analysis',\n",
       "  'CORD-19-LDA-Topic-modeling-reccomendation-system',\n",
       "  'CORD-19:Understanding papers with TextAnalyticsüî¨',\n",
       "  'COVID19_Italy_PatientZeros',\n",
       "  'CORD-19 Challenge: Titles topic modelling',\n",
       "  'CORD-19 - Data extraction functions',\n",
       "  'COVID-19 Thematic tagging with Regular Expressions',\n",
       "  'A Comprehensive Resource Notebook For Beginners',\n",
       "  'Most Common Words in the CORD-19 Dataset',\n",
       "  'Hyperion',\n",
       "  'kernel4a6616c22b',\n",
       "  'Country-Based Study on COVID-19',\n",
       "  'incubation_pediatric',\n",
       "  'CORD-19: Create Dataframe',\n",
       "  'abstracts clustering, LDA, NMF, SciBERT embeddings',\n",
       "  'Clean Metadata file',\n",
       "  'summary page COVID-19 risk factors',\n",
       "  'COVID-19 - AutoComplete Search Bar',\n",
       "  'COVID-2019-ID',\n",
       "  'CORD-19 : FastText words clustering',\n",
       "  'Create Corona .csv File',\n",
       "  'COVID-19-BERT-ResearchPapers-Semantic-Search',\n",
       "  'PySpark DataFrame Preprocessing for CORD-19',\n",
       "  'COVID-19 Genome Variations',\n",
       "  'COVID 19- TASKS FILTERING',\n",
       "  'COVID-19-xray-DL',\n",
       "  'World Covid-19 EDA',\n",
       "  'COVID EDA: Initial Exploration Tool',\n",
       "  'incubation_times_mean',\n",
       "  'COVID-19 CT-Scan & Xray CNN Detector',\n",
       "  'COVID-19: Knowledge Graph (Starter)',\n",
       "  'Epidemiological curves using ECDC data',\n",
       "  'CORD-19 Metadata Evaluation',\n",
       "  'fatality and cure rate',\n",
       "  'COVID19',\n",
       "  'Most mentioned antivirals',\n",
       "  'Covid-19 Mentioned Drugs Analysis Vol 2.0',\n",
       "  'BioBERT+CorEx Topic Search',\n",
       "  'ElasticSearch/SciBERT ensemble',\n",
       "  'A references-based atlas of COVID-19 research',\n",
       "  'Combine_Final_Graph',\n",
       "  'CORD-19 Metadata Enrichment [1/x]',\n",
       "  'Consolidating Effects of Risk Factors on COVID-19',\n",
       "  'COVID-19 - Top Scholarly Journals',\n",
       "  'LDA & Information Visualization from CORD-19',\n",
       "  'Vaccine data filter',\n",
       "  'Map Search of Places in CORD-19 Full Text',\n",
       "  'Non-pharmaceutical interventions Covid-19',\n",
       "  'COVID-19 Full Text Article KeyPhrase Extraction',\n",
       "  'Getting_Started_with_Cosine_Similarity',\n",
       "  'CORD-19 : LDA Topic Model - Abstracts',\n",
       "  'COVID19 Temporal Summarization Tool Version 1',\n",
       "  'Covid-Literature-Survey',\n",
       "  'Topic Modelling: Journals Content About COVID-19üìÑ',\n",
       "  'Question answering using Semantic roles',\n",
       "  'Risks of COVID-19 - AI driven Q&A',\n",
       "  'Covids Incubation & Transmission Related Articles',\n",
       "  'Corona virus latest analysis',\n",
       "  'Combine Embedding Data and Citations Article',\n",
       "  'COVID-19 Search Engine for all Queries, USE',\n",
       "  'corona_text_mining_spacy',\n",
       "  'User-Friendly: Finding Related Articles',\n",
       "  'I-COVID19-NLP Data Parsing',\n",
       "  'Covid-19 subset of articles',\n",
       "  'CORD-19: Abstract and Conclusion Word Embedding',\n",
       "  'summary page transmission incubation environment',\n",
       "  'COVID-19 EDA including NLP with Spacy',\n",
       "  'Basic Setup to import the JSON files',\n",
       "  'Match Papers To Tasks',\n",
       "  'Task Question Search',\n",
       "  'Creating A Doc2Vec Model',\n",
       "  'CORD-19-research-challenge: Relevant doc search',\n",
       "  'II-COVID19-Citation Network',\n",
       "  'CORD-19',\n",
       "  'COVID-19 - Temperature and Transmission Rates',\n",
       "  'COVID-19: Knowledge Graph Embeddings',\n",
       "  'covid-19-mortality',\n",
       "  'COVID-19 Ultimate: Chronology + Patients analysis',\n",
       "  'COVID-19 using TF-IDF',\n",
       "  'Covid-19 epidemiological curves at regional level',\n",
       "  'COVID-19 Pandemic EDA üìä',\n",
       "  'Extract Entities from Abstracts',\n",
       "  'Demo of using Custom NER model on COVID-19 dataset',\n",
       "  'CORD-19 Sources unification with pyspark SQL',\n",
       "  'CORD-19 Metadata',\n",
       "  'BIO-NER on COVID 19 data',\n",
       "  'Viral agents. S100A12 marker.',\n",
       "  'summary page virus genetics, origin, and evolution',\n",
       "  'CORD-19-parse-docs-R',\n",
       "  'CORD-19 Human Genes Insights',\n",
       "  'COVID-19 Detection from X Ray Images of Lungs',\n",
       "  'Diagnosing Covid-19',\n",
       "  'Keywords on the subject - Ethical and social',\n",
       "  'Train a Word2Vec',\n",
       "  'COVID-19, Find the Right Research Paper, with tags',\n",
       "  'Topic Modeling (LDA) on CORD-19 Paper Abstracts',\n",
       "  'Covid-19 citation graph - embedding using DeepWalk',\n",
       "  'Covid-19 literature query tool',\n",
       "  'Extracting entities linked to UMLS with scispaCy',\n",
       "  'Evidence Gap Map for Risk Areas',\n",
       "  'summary page vaccines and therapeutics',\n",
       "  'COVID-19 Open Research Dataset (CORD-19)-Analysis',\n",
       "  'Improve quiries using W2V algorithms',\n",
       "  'COVID-19 - Search Engine with Bert',\n",
       "  'Comfirmed bar chart race depending on country',\n",
       "  'COVID-19 what is risk?',\n",
       "  'COVID-19 : Searching for the papers about vaccines',\n",
       "  'Agglomerative Document Clustering on CORD-19',\n",
       "  'Using Whoosh for Indexing and Querying',\n",
       "  'Search COVID-19 papers for particular information',\n",
       "  'Create Corona .csv File',\n",
       "  'COVID2020',\n",
       "  'Weather and Covid 19 Outbreak',\n",
       "  'Covid(RAN) - Research & Analytics Notebook',\n",
       "  'Data analysis on Coronavirus',\n",
       "  'Train Fasttext on COVID papers',\n",
       "  'Covid19 Ascending Phase Growth Model',\n",
       "  'COVID-19 Recent Questions',\n",
       "  'Beat Corona',\n",
       "  'Insights - focus and experimental findings',\n",
       "  'DoxCompass-Visualization and EDA',\n",
       "  'COVID-19 : Biomedical Semantic Search - Q&A System',\n",
       "  'CORD-19 Citation Network with Deduping',\n",
       "  'CORD-19 Articles Clustering',\n",
       "  'Searching data using KNN neighbors, topic modeling',\n",
       "  'Training Set Labeling Jump-start (UMLS Linking)',\n",
       "  'CORD-19: Disease-Chemical Co-occurrence Matrix',\n",
       "  'COVID-19 Papers Text Summarization',\n",
       "  'Medical NER : Using Spacy',\n",
       "  'BioBERT Embeddings + Demo',\n",
       "  '[CORD-19] Parse Data to Flat Format',\n",
       "  'Mat2Vec/COVID papers: Unexpected word asociations',\n",
       "  'Exploring_corona_abstracts',\n",
       "  'Analyzing the COVID-19 corpus with LDA and PCoA',\n",
       "  'III-COVID19-Collecting Virus Proteins from Uniprot',\n",
       "  'get_data_from_all_papers',\n",
       "  'COVID-19 Reference public data',\n",
       "  'covid-19_create_dataset',\n",
       "  'ACE2_protein_receptor_information',\n",
       "  'cord_19',\n",
       "  'COVID-19 in OH: measuring the response 2020_03_16',\n",
       "  'COVID-19 Retrieval via Sentence Similarity',\n",
       "  'Exploratory data analysis via NLP',\n",
       "  'Most mentioned antivirals 622022',\n",
       "  'How Good is a Drug Against The Corona Virus',\n",
       "  'COVID-19 Data Preprocessing',\n",
       "  'CORD19 - Input Data Exploration',\n",
       "  'Hybrid Search Model - Annoy bio-w2v + BM25 EDA',\n",
       "  'Search system for top article using wikipedia DB',\n",
       "  'Sentence similarity',\n",
       "  'COVID-related v4',\n",
       "  'CORD-19 ngrams insights origin evolution',\n",
       "  'Visualise and Calculate word frequencies COVID-19',\n",
       "  'COVID19_ABSG_AD',\n",
       "  'CORONA Challenge - Analysing Incubation Time in R',\n",
       "  'CORD-19 Keyword Search in Abstracts',\n",
       "  'Participations by country',\n",
       "  'Unsupervised Text Segment Group Discovery',\n",
       "  'Build CSV of Reference Entries',\n",
       "  'Worldwide_Data_and_Graphs',\n",
       "  'CORD-19 Simple Parsing to Dataframes',\n",
       "  'CORD-19:EDA,duplicated papers discovery,resolution',\n",
       "  'Parquet and BigQuery dataset for CORD-19',\n",
       "  'COVID-19 clustering (Infersent-UMAP-HDBScan)',\n",
       "  'Naive Lookup / Save Documents',\n",
       "  'Interactive Abstract and Expert Finder',\n",
       "  'CORD-19: Search Papers Referring to Antivirals',\n",
       "  'coronavirus_jargon_vocabulary',\n",
       "  'COVID19 Challenge Notebook',\n",
       "  'Pandemic Ethics - Covid19',\n",
       "  'CORD-19 Duplicate body_text.text',\n",
       "  'Quick summary and integrated task detail',\n",
       "  'Exploring_corona_competition',\n",
       "  'CORD-19-research-challenge - Using NLP Search',\n",
       "  'COVID Papers',\n",
       "  'bag of words apply for abstract and text fields',\n",
       "  'CORD-19: EDA, LDA and BERT (unsupervised)',\n",
       "  '01 Exploring The Folder-Structure',\n",
       "  'CORVID-19 TRACKING THE KENYA SPREAD',\n",
       "  'Checkout the COVID 19 Word2Vec model',\n",
       "  'CORD-19 : publication analysis',\n",
       "  'War on Covid-19',\n",
       "  'COVID-19: Journal Analysis and Wordcloud',\n",
       "  'COVID-19 - Russia',\n",
       "  'pd.read_csv',\n",
       "  'SpaCy: Aspect Based and Compound Nouns Key Words',\n",
       "  'CoronaVirus',\n",
       "  'First-Notebook-CORD-19-Research',\n",
       "  'CORD-19 beginner EDA',\n",
       "  'Covid-19 - MetaData Overview',\n",
       "  'start with covid-19 data',\n",
       "  'add_pub_types_to_metadata_df',\n",
       "  'COVID-19: data_qa',\n",
       "  'COVID-19',\n",
       "  'COVID-19 Russia details',\n",
       "  'Covid-19 NLP',\n",
       "  'CORD-19: interactive word2vec paragraph search',\n",
       "  'COVID-19 (Task 01)',\n",
       "  'COVID-19 Word Embedding Approach',\n",
       "  '[CORD-19] Embeddings üìô from abstracts with SpaCy',\n",
       "  'symptoms word cloud',\n",
       "  'Detecting and Visualizing covid-19',\n",
       "  '[CORD-19] Embeddings üìô from abstracts with SpaCy',\n",
       "  'NG-EDA-COVID-19-v2',\n",
       "  'COVID-19 World Statistics',\n",
       "  'Extract Tika cTAKES Features',\n",
       "  'Covid-19 Analysis',\n",
       "  'Extractive text summarization',\n",
       "  'COVID-19: Extracting the Hidden Topics With Gensim',\n",
       "  'COVID-19 - Interactive Cluster Graph',\n",
       "  'Papers on Virus Genetics',\n",
       "  'Enigma Covid-19',\n",
       "  'BM25 Search + Query Similarity Ranking',\n",
       "  'COVID parameter study - India & others',\n",
       "  'naive LSTM model test for covid19',\n",
       "  'Search functions for cord19-challenge',\n",
       "  'Browsing research papers with a BM25 search engine',\n",
       "  'COVID-19 Dataset : Gaining actionable insights üìä',\n",
       "  'What Are The Treatments?',\n",
       "  'Tracking the spread of the Coronavirus',\n",
       "  'Clustering Papers using K-Means and t-SNE',\n",
       "  'Find similar COVID-19 Research Articles',\n",
       "  'COVID-19 Classify articles-Doc2vec PCA',\n",
       "  'Build CSV of Body Text',\n",
       "  'betweenness_centrality_of_the_bibliography',\n",
       "  'COVID-19-Word2Vec',\n",
       "  'Protein Sequence Analysis with ProtLearn',\n",
       "  'Extract Related Documents using Bert',\n",
       "  'Metadata_basic_statistics',\n",
       "  'COVID-19 - Find mentions of mortality rates',\n",
       "  'Trying to extract table data from the paper',\n",
       "  'clustering abstracts using fasttext',\n",
       "  'Covid-19 1st transmission',\n",
       "  'COVID-19 - Find keywords using Word2Vec',\n",
       "  '02 Exploring The Article-Metadata-CSV',\n",
       "  'CORD-19: Match SJR Rank journals',\n",
       "  'Corona(nCOVID-19 ) Detection inspect_nucleus_model',\n",
       "  '[CORD-19] Cleaning and EDA',\n",
       "  'Fixing the metadata',\n",
       "  'COVID-19_Genetics_Origin_Evolution',\n",
       "  'All papers sorted by their citation count',\n",
       "  'COVID-19 paper exploration',\n",
       "  'Covid Research',\n",
       "  'Using NLP with answer extraction',\n",
       "  'ResearchPaperAPI (Data Exploitation API)',\n",
       "  'Enigma_Covid19',\n",
       "  'coronavirus factors research',\n",
       "  'COVID-19: Analysing Research Papers (NLP)',\n",
       "  'Covid - Analyzing the Symptoms',\n",
       "  'Classification of articles by Matrix Factorization',\n",
       "  'COVID_19_NER extraction',\n",
       "  'CORD-19 - Data extraction functions',\n",
       "  'High level articles grouping: Topic Modeling & EDA',\n",
       "  'CORD-19_research_challenge',\n",
       "  'COVID-19 simple spread research',\n",
       "  'CoronaVirus EDA',\n",
       "  'Data manipulation with cotools',\n",
       "  'COVID19_EDA_Study1',\n",
       "  'Super hacky regex search engine',\n",
       "  'COVID-19 Research-Clustering',\n",
       "  'Word-embedding',\n",
       "  'Screening for most relevant articles',\n",
       "  '01_data_explore_get_abstracts',\n",
       "  'üò∑ COVID-19 Social Sciences, Vaccines, and Origins',\n",
       "  'Covid-19 EDA in detail',\n",
       "  'COVID-19 Cases Acceleration by Country',\n",
       "  'COVID-19 research NPI',\n",
       "  'QualityOfCovidData',\n",
       "  'Fastai Language Model only COVID-19 papers',\n",
       "  'cord19 data exploration',\n",
       "  'Novel Corona Virus',\n",
       "  'Extractive summary',\n",
       "  'EDA + Preprocessing/Cleaning CORD-19 metadata',\n",
       "  'Export Cleaned Dataset',\n",
       "  'CORD19-EDA extended to all available datasets',\n",
       "  'Recommend a paper by using word embeddings',\n",
       "  'Range of incubation periods for the disease',\n",
       "  'COVID-19 Incubation period',\n",
       "  'count_pmids_per_journal_no_full_text',\n",
       "  'Citation Analysis - Environmental Factors',\n",
       "  'COVID-19-Visualization by co-occurrence network.',\n",
       "  'draft',\n",
       "  'Preprocessing NER, SRL, BERT',\n",
       "  'COVID-19 (Task 09)',\n",
       "  'COVID-19 (Task 08)',\n",
       "  'COVID-19 (Task 06)',\n",
       "  'COVID-19 (Task 07)',\n",
       "  'COVID-19 (Task 04)',\n",
       "  'COVID-19 (Task 03)',\n",
       "  'nCOVID-19 Therapeutics',\n",
       "  'COVID19-Alpha to Omega',\n",
       "  'revs1_covid19_notebook',\n",
       "  'First Exploration of the Weather articles',\n",
       "  'Simple Search by Keywords Using TF-IDF',\n",
       "  'Covid-19 research',\n",
       "  'COV Literature Word Cloud',\n",
       "  'develop-lsi-search',\n",
       "  'Generating Topics using LDA',\n",
       "  'Predict NER and SRL on abstracts',\n",
       "  'CORD-19 Solution',\n",
       "  'COVID-EDA',\n",
       "  'Comparison of COVID-19 virus growth per country',\n",
       "  'Papers on Medical Care',\n",
       "  'Papers on Information Sharing and Collaboration',\n",
       "  'Papers on Ethical and Social Considerations',\n",
       "  'Covid-19 @Zhijie',\n",
       "  'Papers on vaccines and therapeutics',\n",
       "  'Get_file_details',\n",
       "  \"CORD-19 EDA on Literature(Kaggle's Dataset)\",\n",
       "  'Covid-19 Paper Analysis Part I',\n",
       "  'CORD-19 Clustering documents using Abstract',\n",
       "  'COVID - Task 1 - Analysis - Submission',\n",
       "  'Transmission Filtering v1',\n",
       "  'EDA: Cleaning the CORD-19 Dataset',\n",
       "  'Covid19',\n",
       "  'covid-19-analysis',\n",
       "  'Kaggle COVID Roppsters',\n",
       "  'Question Generation + tune bert + telegrambot',\n",
       "  'An√°lise Explorat√≥ria - Coronavirus',\n",
       "  'Cord-19ResearchC-Analysis',\n",
       "  'Semantic Search of Covid Content',\n",
       "  'Top 10 antiretroviral C19',\n",
       "  'Leitura de dados e clustering -medxiv',\n",
       "  'Could citations be used to link papers?',\n",
       "  'COVID-19 Data Visualisation',\n",
       "  'CORD-19-Topic Modelling',\n",
       "  '03 Create A Collaboration Network Of Scientists',\n",
       "  'CORONA Data Analysis',\n",
       "  'Initial start',\n",
       "  'Critical Epidemic Term Visualization w/ WordCloud',\n",
       "  'CORD-19 EDA + Question & Topic Modeling',\n",
       "  'Citation embeddings with visualization',\n",
       "  'kernela990a37deb',\n",
       "  'Outbreak Data Analysis',\n",
       "  'kernel7457cf1f41',\n",
       "  'A Simple, Direct COVID-19 QA engine',\n",
       "  'Coronavirus (CoVid19) - Exploratory Analysis',\n",
       "  'CORD-19: interactive search tool',\n",
       "  'COVID19Frame',\n",
       "  'Topic Modeling BERT+LDA',\n",
       "  'Topic Modeling with LDA and NMF',\n",
       "  'Papers on Non-pharmaceutical Interventions',\n",
       "  'Papers on Diagnostics and Surveillance',\n",
       "  'kernel154a79be15',\n",
       "  'Corona_19_Clustering_and_TopicWise_Search',\n",
       "  'Abstract Similarity for COVID-19',\n",
       "  'kernel2400a64d5a',\n",
       "  '[CORD-19] Embeddings üìô from abstracts (Notebook)',\n",
       "  'COVID19 exploration and paper recommendation',\n",
       "  'wordcloud',\n",
       "  'kernel6aeadef153',\n",
       "  'kernel666a075559',\n",
       "  'risk factors word cloud',\n",
       "  'kernel162450d46d',\n",
       "  'COVID-19: Clustering',\n",
       "  '[CORD-19] Parse Data to Flat Format',\n",
       "  'kernel6f28923430',\n",
       "  'Papers on Transmission and Incubation',\n",
       "  'Papers on Risk Factors',\n",
       "  'kernel35d406586c',\n",
       "  'COVID-19 Graph Clustering',\n",
       "  'COVID-19 Drug and chemical mentions',\n",
       "  'Laura Edell Walk Through of COVID19',\n",
       "  'BM25 Index Search',\n",
       "  'CORD-19 Solution Toolbox',\n",
       "  'TFIDF sklearn model',\n",
       "  'I - COVID19-NLP-Data-Parsing_Animals',\n",
       "  'Covid19_JAM',\n",
       "  'chloroquine COVID-19',\n",
       "  'Incubation Question (query) design',\n",
       "  'COVID-19: Topic Modelling and Search with Top2Vec',\n",
       "  'Virus Variations',\n",
       "  'Testing Positive After Recovery',\n",
       "  'surface persistence',\n",
       "  'COVID-19 Pandemic in Pakistan and Other',\n",
       "  'To Put a LAMP on COVID-19',\n",
       "  'AaaAaa',\n",
       "  'covid_add_sjr_if_to_metadata',\n",
       "  'COVID-19 (Task 10)',\n",
       "  'Task 02: CORD-19 Challenge (COVID-19)',\n",
       "  'COVID-19 Unsupervised Literature Understanding',\n",
       "  'COVID-19 Dataset : Insights',\n",
       "  'Similarity between docs (20/3 update)',\n",
       "  'Query2Vec: Creating Query-Context Embeddings',\n",
       "  'CORD-19 Competition - Final Submission',\n",
       "  'kernel41a29f6692',\n",
       "  'COVID-19 Literature Clustering',\n",
       "  'COVID-19 Challenge Notebook',\n",
       "  'SciBERT+sentence similarity',\n",
       "  'CORD-19 Search articles with Doc2Vec',\n",
       "  'CORVID interactive',\n",
       "  'cord-19-LDA'],\n",
       " 'num_visualizations': [42,\n",
       "  0,\n",
       "  2,\n",
       "  4,\n",
       "  26,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  19,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  25,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  3,\n",
       "  10,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  66,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  13,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  7,\n",
       "  0,\n",
       "  6,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  110,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  8,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  18,\n",
       "  5,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  4,\n",
       "  1,\n",
       "  7,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  13,\n",
       "  7,\n",
       "  2,\n",
       "  15,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  23,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  10,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  10,\n",
       "  0,\n",
       "  0,\n",
       "  12,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  8,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  48,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  24,\n",
       "  3,\n",
       "  11,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  13,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  18,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  6,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  33,\n",
       "  0,\n",
       "  0,\n",
       "  22,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  10,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  10,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'num_datafiles': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  13,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  36,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  33206,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  14,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2],\n",
       " 'time_published': ['Sat Mar 28 2020 16:27:39 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 16:11:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 16:51:49 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:23:37 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 05:21:16 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 12:43:01 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:50:24 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 15:26:54 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 09:56:28 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:51:08 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 09:23:10 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 12:31:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 16:33:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 11:12:37 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 16:03:51 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 12:14:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 14:47:28 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 12:59:24 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 17:23:16 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:23:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 12:40:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 11:59:16 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 10:37:22 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 11:17:10 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 06:18:24 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 08:27:52 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 02:43:44 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 16:23:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 18:09:52 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 09:16:47 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 23:12:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 22:08:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 04:26:48 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 19:12:03 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 12:27:56 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 02:50:08 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 07:18:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 07:29:24 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 16:37:21 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 11:27:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 07:50:47 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 15:07:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 12:22:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 02:48:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 08:35:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 01:56:35 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 21:07:37 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 21:07:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 19:32:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 22:11:52 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 04:33:38 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 20:04:04 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 22:04:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 16:10:07 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 14:45:15 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 17:58:31 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 15:19:33 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 12:53:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 03:00:48 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:01:54 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 13:10:22 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 16:26:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 20:51:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 02:40:39 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 18:07:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 23:09:15 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:22:01 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 13:46:30 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 15:56:01 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 10:58:58 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 16 2020 22:50:33 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 15:01:12 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 12:15:22 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 07:22:37 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 08:40:17 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 17:42:52 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:18:30 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 12:55:24 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 06:47:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 18:19:23 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 15:37:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 05:29:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 09:33:17 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 11:15:33 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 20:40:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 18:50:24 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 16:22:32 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 13:08:36 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 22:42:23 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 18:03:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 12:53:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 08:59:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 12:40:00 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 09:54:48 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 07:38:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 14:34:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 07:39:15 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 06:27:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 06:53:46 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 01:36:17 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 00:17:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 06:10:09 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 20:57:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 15:33:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 08:51:45 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 17:33:54 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 02:26:35 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 05:37:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:27:29 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 02:16:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 23:57:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 23:28:10 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 05:51:54 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 18:52:14 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 09:30:00 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 13:29:12 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 04:09:08 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 18:04:45 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 08:19:34 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 13:53:16 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 07:49:10 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 09:34:51 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 09:19:09 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 19:51:16 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 15:43:39 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 03:45:54 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 08:47:21 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 04:21:31 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 14:20:07 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 00:10:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:29:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 21:47:00 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 05:27:29 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 14:19:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 15:07:19 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 10:40:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 19:21:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 17:19:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 16 2020 23:45:21 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 06:03:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 05:27:18 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 22:34:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 19:04:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:37:08 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 14:44:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 16:59:58 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 04:37:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 13:54:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 09:30:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 22:47:46 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 14:59:56 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 19:30:08 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 17:28:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 12:33:40 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 07:25:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 16 2020 18:03:49 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 01:04:50 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 20:31:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 15:40:22 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 19:44:18 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:30:44 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 13:56:12 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 09:20:17 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 10:58:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 17:20:30 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 15:18:31 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 15:10:19 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 11:51:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 23:53:44 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 21:06:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 11:24:30 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 09:02:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 15:10:30 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 05:34:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 01:22:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 14:01:36 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 14:31:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 00:47:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 22:52:40 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 21:09:39 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 18:34:09 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 13:22:31 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 02:29:44 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 16 2020 23:08:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 19:02:49 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 09:49:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 09:47:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 14:45:07 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 08:13:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 04:51:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 10:47:37 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 07:02:03 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 20:58:45 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 09:53:30 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 16:41:52 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 17:55:00 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 15:08:33 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 06:24:54 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 12:14:31 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 18:39:12 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 16:16:12 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 16:13:35 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 16:50:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 10:13:17 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 09:59:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 00:31:01 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 05:07:40 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 03:15:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 00:41:49 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 00:51:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 14:10:33 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 08:13:28 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 07:41:29 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 07:18:28 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 06:48:01 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 16:21:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 18:32:40 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 16:59:24 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 13:40:56 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 10:42:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 09:41:48 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 06:19:46 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 12:32:22 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 14:02:05 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 19:11:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 14:04:39 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 16:37:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 04:04:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 02:40:34 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 16 2020 23:09:07 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 16 2020 20:15:23 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 16 2020 20:03:10 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 12:48:35 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 01:45:03 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 05:40:44 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 18:24:58 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 14:56:16 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 14:05:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 20:16:39 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 06:34:22 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 16:01:14 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 07:45:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 02:59:29 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 22:10:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 17:21:05 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 18:11:01 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 21:36:22 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 15:09:35 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 12:10:17 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 11:19:59 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 18:33:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 02:11:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 09:48:05 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 20:01:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 17:15:33 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 15:38:33 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 15:09:51 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 08:13:19 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 19:01:44 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 17:22:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 13:21:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 13:15:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 11:32:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 09:39:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 04:59:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 21:59:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 16:13:40 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 16:21:01 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 08:58:59 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 05:45:05 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 13:14:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 16:21:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 14:13:35 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 12:59:32 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 15:50:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 10:46:22 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 11:19:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 09:37:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 08:41:38 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 08:37:30 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 12:48:24 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 03:29:04 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 02:49:37 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 01:51:14 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 00:29:50 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 23:26:16 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 21:42:49 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 18:43:48 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 18:21:36 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 13:34:59 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 06:09:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 12:27:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 12:13:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 11:49:45 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 11:16:00 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 06:39:09 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 07:33:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 06:17:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 04:55:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 03:00:58 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 02:20:14 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 16:29:44 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 01:04:51 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 13:10:28 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 06:25:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 16 2020 22:19:01 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 22:35:51 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 22:08:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 21:20:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 18:29:09 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 18:10:47 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 19:55:09 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 17:10:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 17:09:21 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 13:36:46 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 11:52:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 11:46:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 10:31:37 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 06:44:30 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 08:20:19 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 07:03:08 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 05:39:03 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 20:57:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 21:36:48 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 21:24:24 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 18:55:23 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 16:15:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 15:18:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 15:00:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 14:37:58 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 13:35:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 13:23:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 13:23:46 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 11:55:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 08:36:37 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 11:13:54 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 23:30:19 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 20:39:40 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 19:37:35 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 17:31:12 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 15:51:13 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 14:13:04 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 09:52:38 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 03:21:18 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 02:48:01 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 19:23:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 18:53:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 18:46:36 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 18:15:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 16:27:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 10:34:09 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 10:25:19 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 10:07:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 09:34:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 23:31:34 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 17:10:16 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 08:19:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 06:02:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 00:52:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 19:26:05 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 03:19:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 11:47:44 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 11:41:39 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 11:08:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 09:08:31 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 05:57:55 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 23:00:59 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 22:36:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 14:53:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 11:48:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 08:35:33 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 06:36:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 13:26:08 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 06:22:14 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 01:43:00 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 00:02:17 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 10:57:29 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 08:06:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 07:01:03 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 06:07:35 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 04:57:48 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 18:04:43 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 12:22:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 19:22:23 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 19:59:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 17:36:32 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 04:45:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 05:47:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 10:46:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 17 2020 12:06:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 26 2020 03:10:31 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 18:11:33 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 07:47:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 07:07:49 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 25 2020 00:04:25 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 15:22:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 07:30:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 05:32:35 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 03:17:47 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 20:28:03 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 20:00:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 20:00:07 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 18:19:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 07:03:57 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 07:14:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 06:41:27 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 17:18:52 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 12:38:23 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 12:32:38 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 09:28:37 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 16:39:26 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:35:45 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 10:58:53 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 18:09:34 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:06:10 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:19:52 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 13:21:15 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 16:17:22 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 27 2020 02:15:48 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 28 2020 06:09:20 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 18:58:17 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 16:38:50 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Tue Mar 24 2020 12:37:06 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Mon Mar 23 2020 05:20:04 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 11:19:44 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 10:34:47 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 20:03:04 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sun Mar 22 2020 11:36:41 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 11:45:11 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Fri Mar 20 2020 03:05:45 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 04:39:02 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 04:48:42 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Wed Mar 18 2020 13:34:21 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Thu Mar 19 2020 09:44:08 GMT-0400 (Eastern Daylight Time)',\n",
       "  'Sat Mar 21 2020 00:12:44 GMT-0400 (Eastern Daylight Time)'],\n",
       " 'relative_time_published': ['2h ago',\n",
       "  '2h ago',\n",
       "  '1h ago',\n",
       "  '5h ago',\n",
       "  '13h ago',\n",
       "  '5h ago',\n",
       "  '4h ago',\n",
       "  '3h ago',\n",
       "  '8h ago',\n",
       "  '4h ago',\n",
       "  '9h ago',\n",
       "  '6h ago',\n",
       "  '1h ago',\n",
       "  '7h ago',\n",
       "  '2h ago',\n",
       "  '6h ago',\n",
       "  '3h ago',\n",
       "  '5h ago',\n",
       "  '39m ago',\n",
       "  '5h ago',\n",
       "  '5h ago',\n",
       "  '6h ago',\n",
       "  '7h ago',\n",
       "  '1d ago',\n",
       "  '12h ago',\n",
       "  '10h ago',\n",
       "  '8d ago',\n",
       "  '1d ago',\n",
       "  '7d ago',\n",
       "  '9h ago',\n",
       "  '7d ago',\n",
       "  '5d ago',\n",
       "  '14h ago',\n",
       "  '1d ago',\n",
       "  '1d ago',\n",
       "  '4d ago',\n",
       "  '5d ago',\n",
       "  '3d ago',\n",
       "  '1d ago',\n",
       "  '1d ago',\n",
       "  '1d ago',\n",
       "  '4d ago',\n",
       "  '6h ago',\n",
       "  '2d ago',\n",
       "  '10d ago',\n",
       "  '7d ago',\n",
       "  '1d ago',\n",
       "  '1d ago',\n",
       "  '7d ago',\n",
       "  '4d ago',\n",
       "  '5d ago',\n",
       "  '1d ago',\n",
       "  '21h ago',\n",
       "  '3h ago',\n",
       "  '3d ago',\n",
       "  '1d ago',\n",
       "  '3h ago',\n",
       "  '1d ago',\n",
       "  '16h ago',\n",
       "  '6h ago',\n",
       "  '7d ago',\n",
       "  '1d ago',\n",
       "  '7d ago',\n",
       "  '9d ago',\n",
       "  '7d ago',\n",
       "  '10d ago',\n",
       "  '5h ago',\n",
       "  '1d ago',\n",
       "  '2d ago',\n",
       "  '10d ago',\n",
       "  '12d ago',\n",
       "  '1d ago',\n",
       "  '2d ago',\n",
       "  '1d ago',\n",
       "  '4d ago',\n",
       "  '6d ago',\n",
       "  '5h ago',\n",
       "  '1d ago',\n",
       "  '3d ago',\n",
       "  '27m ago',\n",
       "  '5d ago',\n",
       "  '3d ago',\n",
       "  '1d ago',\n",
       "  '1d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '9d ago',\n",
       "  '10d ago',\n",
       "  '11d ago',\n",
       "  '4d ago',\n",
       "  '10d ago',\n",
       "  '2d ago',\n",
       "  '2d ago',\n",
       "  '1d ago',\n",
       "  '1d ago',\n",
       "  '4d ago',\n",
       "  '11d ago',\n",
       "  '12h ago',\n",
       "  '7d ago',\n",
       "  '12d ago',\n",
       "  '18h ago',\n",
       "  '2d ago',\n",
       "  '8d ago',\n",
       "  '3d ago',\n",
       "  '6d ago',\n",
       "  '11d ago',\n",
       "  '7d ago',\n",
       "  '2d ago',\n",
       "  '5h ago',\n",
       "  '2d ago',\n",
       "  '9d ago',\n",
       "  '10d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '1d ago',\n",
       "  '2d ago',\n",
       "  '5d ago',\n",
       "  '1d ago',\n",
       "  '10d ago',\n",
       "  '3d ago',\n",
       "  '5d ago',\n",
       "  '4d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '8d ago',\n",
       "  '10d ago',\n",
       "  '12d ago',\n",
       "  '11d ago',\n",
       "  '12d ago',\n",
       "  '5h ago',\n",
       "  '4d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '8d ago',\n",
       "  '10d ago',\n",
       "  '9d ago',\n",
       "  '11d ago',\n",
       "  '12d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '5h ago',\n",
       "  '4d ago',\n",
       "  '2d ago',\n",
       "  '2d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '8d ago',\n",
       "  '9d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '12d ago',\n",
       "  '3d ago',\n",
       "  '2d ago',\n",
       "  '2d ago',\n",
       "  '2d ago',\n",
       "  '5h ago',\n",
       "  '2d ago',\n",
       "  '3d ago',\n",
       "  '2d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '10h ago',\n",
       "  '8d ago',\n",
       "  '10d ago',\n",
       "  '4d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '12d ago',\n",
       "  '12d ago',\n",
       "  '1d ago',\n",
       "  '2d ago',\n",
       "  '2d ago',\n",
       "  '3d ago',\n",
       "  '2d ago',\n",
       "  '14h ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '6d ago',\n",
       "  '1h ago',\n",
       "  '5d ago',\n",
       "  '4d ago',\n",
       "  '2d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '4d ago',\n",
       "  '7d ago',\n",
       "  '8d ago',\n",
       "  '7d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '11d ago',\n",
       "  '10d ago',\n",
       "  '7d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '1d ago',\n",
       "  '12d ago',\n",
       "  '12d ago',\n",
       "  '12d ago',\n",
       "  '12d ago',\n",
       "  '12d ago',\n",
       "  '2d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '2d ago',\n",
       "  '2d ago',\n",
       "  '4d ago',\n",
       "  '3d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '13m ago',\n",
       "  '6d ago',\n",
       "  '5d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '8d ago',\n",
       "  '7d ago',\n",
       "  '8d ago',\n",
       "  '6d ago',\n",
       "  '9d ago',\n",
       "  '8d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '8d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '10d ago',\n",
       "  '11d ago',\n",
       "  '11d ago',\n",
       "  '12d ago',\n",
       "  '12d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '2d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '4d ago',\n",
       "  '3d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '3d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '6d ago',\n",
       "  '3d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '8d ago',\n",
       "  '8d ago',\n",
       "  '8d ago',\n",
       "  '8d ago',\n",
       "  '8d ago',\n",
       "  '8d ago',\n",
       "  '8d ago',\n",
       "  '8d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '10d ago',\n",
       "  '9d ago',\n",
       "  '12d ago',\n",
       "  '17h ago',\n",
       "  '19h ago',\n",
       "  '1d ago',\n",
       "  '1d ago',\n",
       "  '1d ago',\n",
       "  '2d ago',\n",
       "  '2d ago',\n",
       "  '10d ago',\n",
       "  '2d ago',\n",
       "  '5d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '9d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '11d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '3d ago',\n",
       "  '4d ago',\n",
       "  '5d ago',\n",
       "  '5d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '6d ago',\n",
       "  '7d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '9d ago',\n",
       "  '10d ago',\n",
       "  '5h ago',\n",
       "  '8h ago',\n",
       "  '37m ago',\n",
       "  '6h ago',\n",
       "  '5h ago',\n",
       "  '5h ago',\n",
       "  '1d ago',\n",
       "  '2d ago',\n",
       "  '13h ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '4d ago',\n",
       "  '6d ago',\n",
       "  '7d ago',\n",
       "  '7d ago',\n",
       "  '8d ago',\n",
       "  '6d ago',\n",
       "  '8d ago',\n",
       "  '9d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '10d ago',\n",
       "  '9d ago',\n",
       "  '8d ago'],\n",
       " 'tags': [['epidemiology', 'health'],\n",
       "  [],\n",
       "  ['beginner', 'eda', 'starter code'],\n",
       "  ['clinical research'],\n",
       "  ['epidemiology', 'text mining'],\n",
       "  [],\n",
       "  ['covid19'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['nlp', 'data visualization'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['data cleaning', 'data visualization'],\n",
       "  ['data visualization'],\n",
       "  ['beginner', 'eda', 'data visualization'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['nlp', 'spaCy'],\n",
       "  [],\n",
       "  ['eda', 'nlp', 'covid19'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['tutorial', 'data visualization'],\n",
       "  ['beginner', 'eda', 'data cleaning'],\n",
       "  [],\n",
       "  ['data journalism'],\n",
       "  ['medicine', 'eda', 'nlp'],\n",
       "  [],\n",
       "  ['eda', 'nlp'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['research', 'nlp', 'covid19'],\n",
       "  [],\n",
       "  ['beginner', 'nlp', 'clustering'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['health', 'beginner', 'data visualization'],\n",
       "  ['covid19'],\n",
       "  [],\n",
       "  ['data cleaning', 'nlp', 'text mining'],\n",
       "  ['eda', 'nlp', 'feature engineering'],\n",
       "  ['beginner', 'eda', 'nlp'],\n",
       "  ['healthcare', 'biology'],\n",
       "  ['data visualization'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['medicine', 'beginner'],\n",
       "  [],\n",
       "  ['research', 'tutorial', 'nlp'],\n",
       "  ['data cleaning', 'preprocessing'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['healthcare', 'epidemiology'],\n",
       "  ['eda', 'starter code'],\n",
       "  [],\n",
       "  [],\n",
       "  ['knowledge', 'literature'],\n",
       "  ['epidemiology', 'data visualization'],\n",
       "  ['epidemiology', 'medicine'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['data cleaning', 'data management'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['data cleaning', 'nlp'],\n",
       "  ['geospatial analysis'],\n",
       "  [],\n",
       "  ['text mining', 'data visualization'],\n",
       "  ['eda', 'starter code', 'covid19'],\n",
       "  [],\n",
       "  [],\n",
       "  ['eda', 'nlp'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['medicine', 'beginner'],\n",
       "  ['healthcare', 'geospatial analysis'],\n",
       "  [],\n",
       "  ['beginner', 'classification'],\n",
       "  [],\n",
       "  [],\n",
       "  ['beginner', 'data cleaning'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['eda', 'nlp'],\n",
       "  ['beginner', 'starter code'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['epidemiology', 'beginner'],\n",
       "  ['beginner', 'network analysis'],\n",
       "  ['health', 'beginner', 'nlp'],\n",
       "  [],\n",
       "  ['literature', 'covid19'],\n",
       "  [],\n",
       "  ['epidemiology', 'health'],\n",
       "  [],\n",
       "  ['epidemiology', 'statistical analysis'],\n",
       "  ['time series', 'eda', 'data visualization'],\n",
       "  ['healthcare', 'biology'],\n",
       "  [],\n",
       "  ['preprocessing', 'covid19'],\n",
       "  [],\n",
       "  ['beginner', 'eda', 'data visualization'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['human genetics'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['nlp', 'starter code'],\n",
       "  ['data cleaning', 'data visualization'],\n",
       "  [],\n",
       "  [],\n",
       "  ['text mining', 'text data'],\n",
       "  ['nlp', 'preprocessing'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['search engines', 'starter code'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['medicine', 'covid19'],\n",
       "  ['data cleaning', 'data visualization'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['eda', 'data visualization'],\n",
       "  ['pharmaceutical industry'],\n",
       "  ['data cleaning', 'network analysis'],\n",
       "  [],\n",
       "  ['research tools and topics'],\n",
       "  ['nlp', 'text data', 'covid19'],\n",
       "  [],\n",
       "  ['text mining', 'data visualization'],\n",
       "  [],\n",
       "  ['research', 'deep learning'],\n",
       "  ['data cleaning'],\n",
       "  [],\n",
       "  [],\n",
       "  ['eda', 'text mining'],\n",
       "  ['databases', 'data cleaning'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['eda', 'nlp', 'data visualization'],\n",
       "  [],\n",
       "  [],\n",
       "  ['nlp'],\n",
       "  ['health', 'beginner', 'eda'],\n",
       "  ['biology', 'medicine'],\n",
       "  ['data visualization', 'feature engineering'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['data cleaning', 'nlp'],\n",
       "  ['epidemiology', 'text data'],\n",
       "  [],\n",
       "  [],\n",
       "  ['beginner', 'text data'],\n",
       "  [],\n",
       "  ['feature engineering'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['tutorial', 'data cleaning'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['beginner'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['russia', 'diseases', 'epidemiology'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['beginner', 'eda', 'data cleaning'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['research', 'tutorial', 'beginner'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['eda', 'clustering'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['beginner', 'text data'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['beginner', 'text mining'],\n",
       "  [],\n",
       "  ['clustering', 'covid19'],\n",
       "  [],\n",
       "  ['text mining', 'starter code'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['beginner', 'eda', 'data cleaning'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['eda', 'nlp'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['starter code'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['beginner', 'eda', 'data cleaning'],\n",
       "  [],\n",
       "  [],\n",
       "  ['nlp', 'clustering', 'recommender systems'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  ['data cleaning', 'preprocessing'],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []],\n",
       " 'language': ['Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'markdown',\n",
       "  'R',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'Python'],\n",
       " 'num_comments': ['42',\n",
       "  '14',\n",
       "  '31',\n",
       "  '7',\n",
       "  '20',\n",
       "  '0',\n",
       "  '4',\n",
       "  '0',\n",
       "  '1',\n",
       "  '9',\n",
       "  '7',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '3',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '10',\n",
       "  '0',\n",
       "  '32',\n",
       "  '0',\n",
       "  '0',\n",
       "  '92',\n",
       "  '8',\n",
       "  '31',\n",
       "  '0',\n",
       "  '22',\n",
       "  '64',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '24',\n",
       "  '10',\n",
       "  '21',\n",
       "  '0',\n",
       "  '8',\n",
       "  '6',\n",
       "  '26',\n",
       "  '1',\n",
       "  '20',\n",
       "  '3',\n",
       "  '21',\n",
       "  '0',\n",
       "  '0',\n",
       "  '7',\n",
       "  '15',\n",
       "  '4',\n",
       "  '6',\n",
       "  '0',\n",
       "  '0',\n",
       "  '4',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '8',\n",
       "  '0',\n",
       "  '6',\n",
       "  '9',\n",
       "  '1',\n",
       "  '6',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '3',\n",
       "  '4',\n",
       "  '0',\n",
       "  '4',\n",
       "  '2',\n",
       "  '2',\n",
       "  '2',\n",
       "  '0',\n",
       "  '0',\n",
       "  '12',\n",
       "  '0',\n",
       "  '5',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '3',\n",
       "  '5',\n",
       "  '2',\n",
       "  '4',\n",
       "  '8',\n",
       "  '1',\n",
       "  '6',\n",
       "  '5',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '6',\n",
       "  '1',\n",
       "  '4',\n",
       "  '3',\n",
       "  '8',\n",
       "  '2',\n",
       "  '4',\n",
       "  '3',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '3',\n",
       "  '0',\n",
       "  '6',\n",
       "  '1',\n",
       "  '1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '0',\n",
       "  '7',\n",
       "  '6',\n",
       "  '2',\n",
       "  '0',\n",
       "  '3',\n",
       "  '1',\n",
       "  '0',\n",
       "  '2',\n",
       "  '2',\n",
       "  '3',\n",
       "  '2',\n",
       "  '4',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '2',\n",
       "  '2',\n",
       "  '6',\n",
       "  '3',\n",
       "  '8',\n",
       "  '2',\n",
       "  '1',\n",
       "  '6',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '3',\n",
       "  '3',\n",
       "  '0',\n",
       "  '2',\n",
       "  '0',\n",
       "  '1',\n",
       "  '2',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '3',\n",
       "  '6',\n",
       "  '3',\n",
       "  '2',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '2',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '2',\n",
       "  '2',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '3',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '3',\n",
       "  '1',\n",
       "  '3',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '2',\n",
       "  '1',\n",
       "  '1',\n",
       "  '2',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '8',\n",
       "  '0',\n",
       "  '0',\n",
       "  '2',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '3',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '2',\n",
       "  '0',\n",
       "  '0',\n",
       "  '2',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '2',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '2',\n",
       "  '0',\n",
       "  '2',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '1',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '2',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '2',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0'],\n",
       " 'notebook_link': ['https://www.kaggle.com/tarunkr/covid-19-case-study-analysis-viz-comparisons',\n",
       "  'https://www.kaggle.com/arturkiulian/coronawhy-org-global-collaboration-join-slack',\n",
       "  'https://www.kaggle.com/dgunning/browsing-research-papers-with-a-bm25-search-engine',\n",
       "  'https://www.kaggle.com/maria17/cord-19-explore-drugs-being-developed',\n",
       "  'https://www.kaggle.com/danielwolffram/topic-modeling-finding-related-articles',\n",
       "  'https://www.kaggle.com/albertoferrari/learning-medicine-with-word-embeddings',\n",
       "  'https://www.kaggle.com/ajrwhite/covid-19-transmission-and-incubation',\n",
       "  'https://www.kaggle.com/cedna198/visualization-of-virus-origin-genetic-evolution',\n",
       "  'https://www.kaggle.com/mlconsult/air-temperature-and-covid-19',\n",
       "  'https://www.kaggle.com/dirktheeng/anserini-bert-squad-for-context-corpus-search',\n",
       "  'https://www.kaggle.com/yuanso/covid-19-four-different-epidemic-situations',\n",
       "  'https://www.kaggle.com/rocket95/covid-19-incubation-time',\n",
       "  'https://www.kaggle.com/dgunning/a-cord19-research-paper-search-engine',\n",
       "  'https://www.kaggle.com/mlconsult/age-dependent-incubation-period',\n",
       "  'https://www.kaggle.com/fschilder/asking-questions-with-a-bm25-bert',\n",
       "  'https://www.kaggle.com/anuraagsaini/corona-virus-data-visualization',\n",
       "  'https://www.kaggle.com/raymondjia/3d-world-heat-map-of-cumulative-confirmed-case',\n",
       "  'https://www.kaggle.com/salikhussaini49/exploratory-data-analysis-covid-19-from-ecdc',\n",
       "  'https://www.kaggle.com/dannellyz/cord-19-metadata-enrich-2-x-altmetric-api',\n",
       "  'https://www.kaggle.com/eb0x143839/convert-covid-19-papers-to-entity-vectors',\n",
       "  'https://www.kaggle.com/ajayago/cord-19-topic-modelling',\n",
       "  'https://www.kaggle.com/cstefanache/nlp-text-mining-disease-behavior',\n",
       "  'https://www.kaggle.com/joeptummers/covid-2019-id-paper-version',\n",
       "  'https://www.kaggle.com/nofoosports/cord-19-analysis-with-sentence-embeddings',\n",
       "  'https://www.kaggle.com/arpitrathi/utilizing-biobert-for-k-means-topic-clustering',\n",
       "  'https://www.kaggle.com/sunzihao/a-brief-talk-on-covid-19',\n",
       "  'https://www.kaggle.com/maksimeren/covid-19-literature-clustering',\n",
       "  'https://www.kaggle.com/isaacmg/scibert-embeddings',\n",
       "  'https://www.kaggle.com/xhlulu/cord-19-eda-parse-json-and-generate-clean-csv',\n",
       "  'https://www.kaggle.com/sapal6/covid-19-research-paper-language-model',\n",
       "  'https://www.kaggle.com/jpmiller/creating-a-good-analytics-report',\n",
       "  'https://www.kaggle.com/tarunpaparaju/covid-19-dataset-gaining-actionable-insights',\n",
       "  'https://www.kaggle.com/jiripodivin/covsum',\n",
       "  'https://www.kaggle.com/donkeys/languages',\n",
       "  'https://www.kaggle.com/etonydev/abstract-summarization-with-transformers-bart',\n",
       "  'https://www.kaggle.com/mobassir/mining-covid-19-scientific-papers',\n",
       "  'https://www.kaggle.com/gpreda/cord-19-solution-toolbox',\n",
       "  'https://www.kaggle.com/shahules/cord-tools-and-knowledge-graphs',\n",
       "  'https://www.kaggle.com/leonwolber/covid-19-text-mining',\n",
       "  'https://www.kaggle.com/luisblanche/cord-19-match-articles-to-tasks-w-doc2vec',\n",
       "  'https://www.kaggle.com/duttadebadri/covid-19-analysing-growth-factor-inflection',\n",
       "  'https://www.kaggle.com/sixteenpython/covid-19-temperature-air-travel-transmission',\n",
       "  'https://www.kaggle.com/csierraf/a-few-peek',\n",
       "  'https://www.kaggle.com/chirag9073/coronavirus-covid-19-outbreak-data-analysis',\n",
       "  'https://www.kaggle.com/d4v1d3/cord-19-lda-topic-modeling-reccomendation-system',\n",
       "  'https://www.kaggle.com/ratan123/cord-19-understanding-papers-with-textanalytics',\n",
       "  'https://www.kaggle.com/ivandebono/covid19-italy-patientzeros',\n",
       "  'https://www.kaggle.com/chuntolee/cord-19-challenge-titles-topic-modelling',\n",
       "  'https://www.kaggle.com/saga21/cord-19-data-extraction-functions',\n",
       "  'https://www.kaggle.com/ajrwhite/covid-19-thematic-tagging-with-regular-expressions',\n",
       "  'https://www.kaggle.com/tanulsingh077/a-comprehensive-resource-notebook-for-beginners',\n",
       "  'https://www.kaggle.com/paultimothymooney/most-common-words-in-the-cord-19-dataset',\n",
       "  'https://www.kaggle.com/mikehoney/hyperion',\n",
       "  'https://www.kaggle.com/krups5/kernel4a6616c22b',\n",
       "  'https://www.kaggle.com/ztsincom/country-based-study-on-covid-19',\n",
       "  'https://www.kaggle.com/erikinwest/incubation-pediatric',\n",
       "  'https://www.kaggle.com/danielwolffram/cord-19-create-dataframe',\n",
       "  'https://www.kaggle.com/dabrom55/abstracts-clustering-lda-nmf-scibert-embeddings',\n",
       "  'https://www.kaggle.com/skylord/clean-metadata-file',\n",
       "  'https://www.kaggle.com/mlconsult/summary-page-covid-19-risk-factors',\n",
       "  'https://www.kaggle.com/beatrizyumi/covid-19-autocomplete-search-bar',\n",
       "  'https://www.kaggle.com/joeptummers/covid-2019-id',\n",
       "  'https://www.kaggle.com/adelfdelvalleperez/cord-19-fasttext-words-clustering',\n",
       "  'https://www.kaggle.com/fmitchell259/create-corona-csv-file',\n",
       "  'https://www.kaggle.com/theamrzaki/covid-19-bert-researchpapers-semantic-search',\n",
       "  'https://www.kaggle.com/acmiyaguchi/pyspark-dataframe-preprocessing-for-cord-19',\n",
       "  'https://www.kaggle.com/mlconsult/covid-19-genome-variations',\n",
       "  'https://www.kaggle.com/ahmedewida/covid-19-tasks-filtering',\n",
       "  'https://www.kaggle.com/michtyson/covid-19-xray-dl',\n",
       "  'https://www.kaggle.com/salmanhiro/world-covid-19-eda',\n",
       "  'https://www.kaggle.com/ivanegapratama/covid-eda-initial-exploration-tool',\n",
       "  'https://www.kaggle.com/moazmohammed/incubation-times-mean',\n",
       "  'https://www.kaggle.com/khoongweihao/covid-19-ct-scan-xray-cnn-detector',\n",
       "  'https://www.kaggle.com/group16/covid-19-knowledge-graph-starter',\n",
       "  'https://www.kaggle.com/panosc/epidemiological-curves-using-ecdc-data',\n",
       "  'https://www.kaggle.com/docxian/cord-19-metadata-evaluation',\n",
       "  'https://www.kaggle.com/mlconsult/fatality-and-cure-rate',\n",
       "  'https://www.kaggle.com/andreamorgar/covid19',\n",
       "  'https://www.kaggle.com/albertoferrari/most-mentioned-antivirals',\n",
       "  'https://www.kaggle.com/umar47/covid-19-mentioned-drugs-analysis-vol-2-0',\n",
       "  'https://www.kaggle.com/jdparsons/biobert-corex-topic-search',\n",
       "  'https://www.kaggle.com/janthiemen/elasticsearch-scibert-ensemble',\n",
       "  'https://www.kaggle.com/mmoeller/a-references-based-atlas-of-covid-19-research',\n",
       "  'https://www.kaggle.com/yatinece/combine-final-graph',\n",
       "  'https://www.kaggle.com/dannellyz/cord-19-metadata-enrichment-1-x',\n",
       "  'https://www.kaggle.com/rohailsyed/consolidating-effects-of-risk-factors-on-covid-19',\n",
       "  'https://www.kaggle.com/guymitch2007/covid-19-top-scholarly-journals',\n",
       "  'https://www.kaggle.com/houssemayed/lda-information-visualization-from-cord-19',\n",
       "  'https://www.kaggle.com/crprpr/vaccine-data-filter',\n",
       "  'https://www.kaggle.com/charlieharper/map-search-of-places-in-cord-19-full-text',\n",
       "  'https://www.kaggle.com/mpwolke/non-pharmaceutical-interventions-covid-19',\n",
       "  'https://www.kaggle.com/hamid3731/covid-19-full-text-article-keyphrase-extraction',\n",
       "  'https://www.kaggle.com/dmlombar/getting-started-with-cosine-similarity',\n",
       "  'https://www.kaggle.com/karthikmohan27/cord-19-lda-topic-model-abstracts',\n",
       "  'https://www.kaggle.com/takercena/covid19-temporal-summarization-tool-version-1',\n",
       "  'https://www.kaggle.com/rishav123/covid-literature-survey',\n",
       "  'https://www.kaggle.com/hamditarek/topic-modelling-journals-content-about-covid-19',\n",
       "  'https://www.kaggle.com/nanar69m/question-answering-using-semantic-roles',\n",
       "  'https://www.kaggle.com/dattaraj/risks-of-covid-19-ai-driven-q-a',\n",
       "  'https://www.kaggle.com/salmanhiro/covids-incubation-transmission-related-articles',\n",
       "  'https://www.kaggle.com/karankrishna/corona-virus-latest-analysis',\n",
       "  'https://www.kaggle.com/yatinece/combine-embedding-data-and-citations-article',\n",
       "  'https://www.kaggle.com/alizahidraja/covid-19-search-engine-for-all-queries-use',\n",
       "  'https://www.kaggle.com/sunmoon/corona-text-mining-spacy',\n",
       "  'https://www.kaggle.com/danielwolffram/user-friendly-finding-related-articles',\n",
       "  'https://www.kaggle.com/vasuji/i-covid19-nlp-data-parsing',\n",
       "  'https://www.kaggle.com/mimisun/covid-19-subset-of-articles',\n",
       "  'https://www.kaggle.com/ekaakurniawan/cord-19-abstract-and-conclusion-word-embedding',\n",
       "  'https://www.kaggle.com/mlconsult/summary-page-transmission-incubation-environment',\n",
       "  'https://www.kaggle.com/jbofill/covid-19-eda-including-nlp-with-spacy',\n",
       "  'https://www.kaggle.com/aruncps/basic-setup-to-import-the-json-files',\n",
       "  'https://www.kaggle.com/andyh47/match-papers-to-tasks',\n",
       "  'https://www.kaggle.com/jazivxt/task-question-search',\n",
       "  'https://www.kaggle.com/fmitchell259/creating-a-doc2vec-model',\n",
       "  'https://www.kaggle.com/onyonixch/cord-19-research-challenge-relevant-doc-search',\n",
       "  'https://www.kaggle.com/vasuji/ii-covid19-citation-network',\n",
       "  'https://www.kaggle.com/psrajput/cord-19',\n",
       "  'https://www.kaggle.com/ahmednassour/covid-19-temperature-and-transmission-rates',\n",
       "  'https://www.kaggle.com/group16/covid-19-knowledge-graph-embeddings',\n",
       "  'https://www.kaggle.com/stormliucong/covid-19-mortality',\n",
       "  'https://www.kaggle.com/romangaev/covid-19-ultimate-chronology-patients-analysis',\n",
       "  'https://www.kaggle.com/shiromiyuki/covid-19-using-tf-idf',\n",
       "  'https://www.kaggle.com/panosc/covid-19-epidemiological-curves-at-regional-level',\n",
       "  'https://www.kaggle.com/raheelsyed/covid-19-pandemic-eda',\n",
       "  'https://www.kaggle.com/tourist800/extract-entities-from-abstracts',\n",
       "  'https://www.kaggle.com/dattaraj/demo-of-using-custom-ner-model-on-covid-19-dataset',\n",
       "  'https://www.kaggle.com/jonathanbesomi/cord-19-sources-unification-with-pyspark-sql',\n",
       "  'https://www.kaggle.com/khotijahs1/cord-19-metadata',\n",
       "  'https://www.kaggle.com/shanmukha99/bio-ner-on-covid-19-data',\n",
       "  'https://www.kaggle.com/mpwolke/viral-agents-s100a12-marker',\n",
       "  'https://www.kaggle.com/mlconsult/summary-page-virus-genetics-origin-and-evolution',\n",
       "  'https://www.kaggle.com/otayeby/cord-19-parse-docs-r',\n",
       "  'https://www.kaggle.com/franciswolinski/cord-19-human-genes-insights',\n",
       "  'https://www.kaggle.com/nabeelsajid917/covid-19-detection-from-x-ray-images-of-lungs',\n",
       "  'https://www.kaggle.com/mpwolke/diagnosing-covid-19',\n",
       "  'https://www.kaggle.com/jonathancarvalho/keywords-on-the-subject-ethical-and-social',\n",
       "  'https://www.kaggle.com/elsonidoq/train-a-word2vec',\n",
       "  'https://www.kaggle.com/alizahidraja/covid-19-find-the-right-research-paper-with-tags',\n",
       "  'https://www.kaggle.com/gkaraman/topic-modeling-lda-on-cord-19-paper-abstracts',\n",
       "  'https://www.kaggle.com/midnitekoder/covid-19-citation-graph-embedding-using-deepwalk',\n",
       "  'https://www.kaggle.com/edopredo/covid-19-literature-query-tool',\n",
       "  'https://www.kaggle.com/daking/extracting-entities-linked-to-umls-with-scispacy',\n",
       "  'https://www.kaggle.com/uplytics/evidence-gap-map-for-risk-areas',\n",
       "  'https://www.kaggle.com/mlconsult/summary-page-vaccines-and-therapeutics',\n",
       "  'https://www.kaggle.com/tintedblast/covid-19-open-research-dataset-cord-19-analysis',\n",
       "  'https://www.kaggle.com/mohamedramzi/improve-quiries-using-w2v-algorithms',\n",
       "  'https://www.kaggle.com/zoupet/covid-19-search-engine-with-bert',\n",
       "  'https://www.kaggle.com/youhanlee/comfirmed-bar-chart-race-depending-on-country',\n",
       "  'https://www.kaggle.com/nishimoto/covid-19-what-is-risk',\n",
       "  'https://www.kaggle.com/hongzhix/covid-19-searching-for-the-papers-about-vaccines',\n",
       "  'https://www.kaggle.com/tchainzzz/agglomerative-document-clustering-on-cord-19',\n",
       "  'https://www.kaggle.com/mxfeinberg/using-whoosh-for-indexing-and-querying',\n",
       "  'https://www.kaggle.com/nexussoftware/search-covid-19-papers-for-particular-information',\n",
       "  'https://www.kaggle.com/cogitae/create-corona-csv-file',\n",
       "  'https://www.kaggle.com/trilabs/covid2020',\n",
       "  'https://www.kaggle.com/mpwolke/weather-and-covid-19-outbreak',\n",
       "  'https://www.kaggle.com/aestheteaman01/covid-ran-research-analytics-notebook',\n",
       "  'https://www.kaggle.com/maonanwang/data-analysis-on-coronavirus',\n",
       "  'https://www.kaggle.com/thedocs/train-fasttext-on-covid-papers',\n",
       "  'https://www.kaggle.com/railit/covid19-ascending-phase-growth-model',\n",
       "  'https://www.kaggle.com/mlconsult/covid-19-recent-questions',\n",
       "  'https://www.kaggle.com/puneetkochar/beat-corona',\n",
       "  'https://www.kaggle.com/mayukhdutta/insights-focus-and-experimental-findings',\n",
       "  'https://www.kaggle.com/qiurui96/doxcompass-visualization-and-eda',\n",
       "  'https://www.kaggle.com/jitu38/covid-19-biomedical-semantic-search-q-a-system',\n",
       "  'https://www.kaggle.com/acmiyaguchi/cord-19-citation-network-with-deduping',\n",
       "  'https://www.kaggle.com/cristianfat/cord-19-articles-clustering',\n",
       "  'https://www.kaggle.com/bs2537/searching-data-using-knn-neighbors-topic-modeling',\n",
       "  'https://www.kaggle.com/bgoss541/training-set-labeling-jump-start-umls-linking',\n",
       "  'https://www.kaggle.com/kicksomeasphalt/cord-19-disease-chemical-co-occurrence-matrix',\n",
       "  'https://www.kaggle.com/kranzfafka/covid-19-papers-text-summarization',\n",
       "  'https://www.kaggle.com/finalepoch/medical-ner-using-spacy',\n",
       "  'https://www.kaggle.com/doggydev/biobert-embeddings-demo',\n",
       "  'https://www.kaggle.com/imbano/cord-19-parse-data-to-flat-format',\n",
       "  'https://www.kaggle.com/tylersuard/mat2vec-covid-papers-unexpected-word-asociations',\n",
       "  'https://www.kaggle.com/sklasfeld/exploring-corona-abstracts',\n",
       "  'https://www.kaggle.com/highflyingbird/analyzing-the-covid-19-corpus-with-lda-and-pcoa',\n",
       "  'https://www.kaggle.com/vasuji/iii-covid19-collecting-virus-proteins-from-uniprot',\n",
       "  'https://www.kaggle.com/styluseater/get-data-from-all-papers',\n",
       "  'https://www.kaggle.com/goooodday/covid-19-reference-public-data',\n",
       "  'https://www.kaggle.com/andretc83/covid-19-create-dataset',\n",
       "  'https://www.kaggle.com/giuliac/ace2-protein-receptor-information',\n",
       "  'https://www.kaggle.com/priteshraj10/cord-19',\n",
       "  'https://www.kaggle.com/thiscuriousquest/covid-19-in-oh-measuring-the-response-2020-03-16',\n",
       "  'https://www.kaggle.com/tchanda/covid-19-retrieval-via-sentence-similarity',\n",
       "  'https://www.kaggle.com/pegger/exploratory-data-analysis-via-nlp',\n",
       "  'https://www.kaggle.com/adrianegli/most-mentioned-antivirals-622022',\n",
       "  'https://www.kaggle.com/ranlevy/how-good-is-a-drug-against-the-corona-virus',\n",
       "  'https://www.kaggle.com/mohamedboussakssou/covid-19-data-preprocessing',\n",
       "  'https://www.kaggle.com/psrajput/cord19-input-data-exploration',\n",
       "  'https://www.kaggle.com/abashareter/hybrid-search-model-annoy-bio-w2v-bm25-eda',\n",
       "  'https://www.kaggle.com/yatinece/search-system-for-top-article-using-wikipedia-db',\n",
       "  'https://www.kaggle.com/modoucair/sentence-similarity',\n",
       "  'https://www.kaggle.com/fireballbyedimyrnmom/covid-related-v4',\n",
       "  'https://www.kaggle.com/gtteixeira/cord-19-ngrams-insights-origin-evolution',\n",
       "  'https://www.kaggle.com/eslambaset/visualise-and-calculate-word-frequencies-covid-19',\n",
       "  'https://www.kaggle.com/adwivedi/covid19-absg-ad',\n",
       "  'https://www.kaggle.com/tschango/corona-challenge-analysing-incubation-time-in-r',\n",
       "  'https://www.kaggle.com/docxian/cord-19-keyword-search-in-abstracts',\n",
       "  'https://www.kaggle.com/davidbetancur8/participations-by-country',\n",
       "  'https://www.kaggle.com/shayanfl/unsupervised-text-segment-group-discovery',\n",
       "  'https://www.kaggle.com/charlieharper/build-csv-of-reference-entries',\n",
       "  'https://www.kaggle.com/anandsinha2031/worldwide-data-and-graphs',\n",
       "  'https://www.kaggle.com/anthony358/cord-19-simple-parsing-to-dataframes',\n",
       "  'https://www.kaggle.com/samusram/cord-19-eda-duplicated-papers-discovery-resolution',\n",
       "  'https://www.kaggle.com/acmiyaguchi/parquet-and-bigquery-dataset-for-cord-19',\n",
       "  'https://www.kaggle.com/e0032186/covid-19-clustering-infersent-umap-hdbscan',\n",
       "  'https://www.kaggle.com/fmitchell259/naive-lookup-save-documents',\n",
       "  'https://www.kaggle.com/jdparsons/interactive-abstract-and-expert-finder',\n",
       "  'https://www.kaggle.com/andrewyue/cord-19-search-papers-referring-to-antivirals',\n",
       "  'https://www.kaggle.com/midnitekoder/coronavirus-jargon-vocabulary',\n",
       "  'https://www.kaggle.com/radenkovic/covid19-challenge-notebook',\n",
       "  'https://www.kaggle.com/mpwolke/pandemic-ethics-covid19',\n",
       "  'https://www.kaggle.com/jeremiahharmsen/cord-19-duplicate-body-text-text',\n",
       "  'https://www.kaggle.com/raymondjia/quick-summary-and-integrated-task-detail',\n",
       "  'https://www.kaggle.com/sklasfeld/exploring-corona-competition',\n",
       "  'https://www.kaggle.com/nageshsomayajula/cord-19-research-challenge-using-nlp-search',\n",
       "  'https://www.kaggle.com/anuraglahon/covid-papers',\n",
       "  'https://www.kaggle.com/dulangaheshan/bag-of-words-apply-for-abstract-and-text-fields',\n",
       "  'https://www.kaggle.com/jonathanbesomi/cord-19-eda-lda-and-bert-unsupervised',\n",
       "  'https://www.kaggle.com/morrisb/01-exploring-the-folder-structure',\n",
       "  'https://www.kaggle.com/edwardnyameri/corvid-19-tracking-the-kenya-spread',\n",
       "  'https://www.kaggle.com/elsonidoq/checkout-the-covid-19-word2vec-model',\n",
       "  'https://www.kaggle.com/julienbarthelat/cord-19-publication-analysis',\n",
       "  'https://www.kaggle.com/mpwolke/war-on-covid-19',\n",
       "  'https://www.kaggle.com/yjunwoo14/covid-19-journal-analysis-and-wordcloud',\n",
       "  'https://www.kaggle.com/eliasgreen/covid-19-russia',\n",
       "  'https://www.kaggle.com/danielcruz97/pd-read-csv',\n",
       "  'https://www.kaggle.com/sidharthkumar/spacy-aspect-based-and-compound-nouns-key-words',\n",
       "  'https://www.kaggle.com/eladwar/coronavirus',\n",
       "  'https://www.kaggle.com/pierregoutorbe/first-notebook-cord-19-research',\n",
       "  'https://www.kaggle.com/latimerb/cord-19-beginner-eda',\n",
       "  'https://www.kaggle.com/mandeep419/covid-19-metadata-overview',\n",
       "  'https://www.kaggle.com/volody/start-with-covid-19-data',\n",
       "  'https://www.kaggle.com/slander/add-pub-types-to-metadata-df',\n",
       "  'https://www.kaggle.com/aaleksei/covid-19-data-qa',\n",
       "  'https://www.kaggle.com/anbu3003/covid-19',\n",
       "  'https://www.kaggle.com/kapral42/covid-19-russia-details',\n",
       "  'https://www.kaggle.com/gyimre/covid-19-nlp',\n",
       "  'https://www.kaggle.com/edrushton/cord-19-interactive-word2vec-paragraph-search',\n",
       "  'https://www.kaggle.com/chahinezounoughi/covid-19-task-01',\n",
       "  'https://www.kaggle.com/imdeepmind/covid-19-word-embedding-approach',\n",
       "  'https://www.kaggle.com/pranjalya/cord-19-embeddings-from-abstracts-with-spacy',\n",
       "  'https://www.kaggle.com/davidbetancur8/symptoms-word-cloud',\n",
       "  'https://www.kaggle.com/iamabdulrazak/detecting-and-visualizing-covid-19',\n",
       "  'https://www.kaggle.com/jonathanbesomi/cord-19-embeddings-from-abstracts-with-spacy',\n",
       "  'https://www.kaggle.com/tombresee/ng-eda-covid-19-v2',\n",
       "  'https://www.kaggle.com/ronetswaminathan/covid-19-world-statistics',\n",
       "  'https://www.kaggle.com/chrismattmann/extract-tika-ctakes-features',\n",
       "  'https://www.kaggle.com/manojkumarvk/covid-19-analysis',\n",
       "  'https://www.kaggle.com/latong/extractive-text-summarization',\n",
       "  'https://www.kaggle.com/vikassingh1996/covid-19-extracting-the-hidden-topics-with-gensim',\n",
       "  'https://www.kaggle.com/beatrizyumi/covid-19-interactive-cluster-graph',\n",
       "  'https://www.kaggle.com/lalitapatel/papers-on-virus-genetics',\n",
       "  'https://www.kaggle.com/jamespatten719/enigma-covid-19',\n",
       "  'https://www.kaggle.com/ideanlabib/bm25-search-query-similarity-ranking',\n",
       "  'https://www.kaggle.com/subhamrath/covid-parameter-study-india-others',\n",
       "  'https://www.kaggle.com/gpiyama2119/naive-lstm-model-test-for-covid19',\n",
       "  'https://www.kaggle.com/leoncz/search-functions-for-cord19-challenge',\n",
       "  'https://www.kaggle.com/longnguyen2306/browsing-research-papers-with-a-bm25-search-engine',\n",
       "  'https://www.kaggle.com/murthycvln/covid-19-dataset-gaining-actionable-insights',\n",
       "  'https://www.kaggle.com/andyh47/what-are-the-treatments',\n",
       "  'https://www.kaggle.com/tajalagawani/tracking-the-spread-of-the-coronavirus',\n",
       "  'https://www.kaggle.com/adhok93/clustering-papers-using-k-means-and-t-sne',\n",
       "  'https://www.kaggle.com/cuongnguyen2k/find-similar-covid-19-research-articles',\n",
       "  'https://www.kaggle.com/aftabuw/covid-19-classify-articles-doc2vec-pca',\n",
       "  'https://www.kaggle.com/charlieharper/build-csv-of-body-text',\n",
       "  'https://www.kaggle.com/mlutz153/betweenness-centrality-of-the-bibliography',\n",
       "  'https://www.kaggle.com/noalubin/covid-19-word2vec',\n",
       "  'https://www.kaggle.com/thomasadorfer/protein-sequence-analysis-with-protlearn',\n",
       "  'https://www.kaggle.com/kezhenchen/extract-related-documents-using-bert',\n",
       "  'https://www.kaggle.com/evasnow/metadata-basic-statistics',\n",
       "  'https://www.kaggle.com/highflyingbird/covid-19-find-mentions-of-mortality-rates',\n",
       "  'https://www.kaggle.com/osciiart/trying-to-extract-table-data-from-the-paper',\n",
       "  'https://www.kaggle.com/induraj2020/clustering-abstracts-using-fasttext',\n",
       "  'https://www.kaggle.com/roadblock/covid-19-1st-transmission',\n",
       "  'https://www.kaggle.com/highflyingbird/covid-19-find-keywords-using-word2vec',\n",
       "  'https://www.kaggle.com/morrisb/02-exploring-the-article-metadata-csv',\n",
       "  'https://www.kaggle.com/mrclnndrd/cord-19-match-sjr-rank-journals',\n",
       "  'https://www.kaggle.com/muhammetfaik/corona-ncovid-19-detection-inspect-nucleus-model',\n",
       "  'https://www.kaggle.com/imbano/cord-19-cleaning-and-eda',\n",
       "  'https://www.kaggle.com/kaceywan/fixing-the-metadata',\n",
       "  'https://www.kaggle.com/kaggleperson1/covid-19-genetics-origin-evolution',\n",
       "  'https://www.kaggle.com/beatrandom/all-papers-sorted-by-their-citation-count',\n",
       "  'https://www.kaggle.com/elfaruq/covid-19-paper-exploration',\n",
       "  'https://www.kaggle.com/yuelong/covid-research',\n",
       "  'https://www.kaggle.com/clmentbisaillon/using-nlp-with-answer-extraction',\n",
       "  'https://www.kaggle.com/brarajit18/researchpaperapi-data-exploitation-api',\n",
       "  'https://www.kaggle.com/jamespatten719/enigma-covid19',\n",
       "  'https://www.kaggle.com/zengrun/coronavirus-factors-research',\n",
       "  'https://www.kaggle.com/ashish244co/covid-19-analysing-research-papers-nlp',\n",
       "  'https://www.kaggle.com/henrifroese/covid-analyzing-the-symptoms',\n",
       "  'https://www.kaggle.com/jaydeepsb/classification-of-articles-by-matrix-factorization',\n",
       "  'https://www.kaggle.com/vishalsiram50/covid-19-ner-extraction',\n",
       "  'https://www.kaggle.com/nsteenv/cord-19-data-extraction-functions',\n",
       "  'https://www.kaggle.com/kiransubramaniams/high-level-articles-grouping-topic-modeling-eda',\n",
       "  'https://www.kaggle.com/saisandeepkantareddy/cord-19-research-challenge',\n",
       "  'https://www.kaggle.com/eliasgreen/covid-19-simple-spread-research',\n",
       "  'https://www.kaggle.com/amanagr/coronavirus-eda',\n",
       "  'https://www.kaggle.com/jdj8af/data-manipulation-with-cotools',\n",
       "  'https://www.kaggle.com/hugokce/covid19-eda-study1',\n",
       "  'https://www.kaggle.com/elsonidoq/super-hacky-regex-search-engine',\n",
       "  'https://www.kaggle.com/jagannathrk/covid-19-research-clustering',\n",
       "  'https://www.kaggle.com/adriensas/word-embedding',\n",
       "  'https://www.kaggle.com/kamalch/screening-for-most-relevant-articles',\n",
       "  'https://www.kaggle.com/garland3/01-data-explore-get-abstracts',\n",
       "  'https://www.kaggle.com/dangizzi/covid-19-social-sciences-vaccines-and-origins',\n",
       "  'https://www.kaggle.com/dextorkaushik/covid-19-eda-in-detail',\n",
       "  'https://www.kaggle.com/acordova/covid-19-cases-acceleration-by-country',\n",
       "  'https://www.kaggle.com/leonardosavasta/covid-19-research-npi',\n",
       "  'https://www.kaggle.com/reyesaldasoro/qualityofcoviddata',\n",
       "  'https://www.kaggle.com/msmelguizo/fastai-language-model-only-covid-19-papers',\n",
       "  'https://www.kaggle.com/koneill1994/cord19-data-exploration',\n",
       "  'https://www.kaggle.com/bono1020/novel-corona-virus',\n",
       "  'https://www.kaggle.com/mahtabkamali/extractive-summary',\n",
       "  'https://www.kaggle.com/kdu4108/eda-preprocessing-cleaning-cord-19-metadata',\n",
       "  'https://www.kaggle.com/mnaylor5/export-cleaned-dataset',\n",
       "  'https://www.kaggle.com/aadharsh0428/cord19-eda-extended-to-all-available-datasets',\n",
       "  'https://www.kaggle.com/mathijs02/recommend-a-paper-by-using-word-embeddings',\n",
       "  'https://www.kaggle.com/adityakaushal98/range-of-incubation-periods-for-the-disease',\n",
       "  'https://www.kaggle.com/ekaterinamihaylova/covid-19-incubation-period',\n",
       "  'https://www.kaggle.com/slander/count-pmids-per-journal-no-full-text',\n",
       "  'https://www.kaggle.com/acmiyaguchi/citation-analysis-environmental-factors',\n",
       "  'https://www.kaggle.com/kiyoshin/covid-19-visualization-by-co-occurrence-network',\n",
       "  'https://www.kaggle.com/menglu/draft',\n",
       "  'https://www.kaggle.com/nanar69m/preprocessing-ner-srl-bert',\n",
       "  'https://www.kaggle.com/chahinezounoughi/covid-19-task-09',\n",
       "  'https://www.kaggle.com/chahinezounoughi/covid-19-task-08',\n",
       "  'https://www.kaggle.com/chahinezounoughi/covid-19-task-06',\n",
       "  'https://www.kaggle.com/chahinezounoughi/covid-19-task-07',\n",
       "  'https://www.kaggle.com/chahinezounoughi/covid-19-task-04',\n",
       "  'https://www.kaggle.com/chahinezounoughi/covid-19-task-03',\n",
       "  'https://www.kaggle.com/wasb143/ncovid-19-therapeutics',\n",
       "  'https://www.kaggle.com/bhagirathl/covid19-alpha-to-omega',\n",
       "  'https://www.kaggle.com/revs96/revs1-covid19-notebook',\n",
       "  'https://www.kaggle.com/diyoyo/first-exploration-of-the-weather-articles',\n",
       "  'https://www.kaggle.com/thiagodma/simple-search-by-keywords-using-tf-idf',\n",
       "  'https://www.kaggle.com/ducale/covid-19-research',\n",
       "  'https://www.kaggle.com/mtmeanmachine/cov-literature-word-cloud',\n",
       "  'https://www.kaggle.com/mnaylor5/develop-lsi-search',\n",
       "  'https://www.kaggle.com/nahdazeez/generating-topics-using-lda',\n",
       "  'https://www.kaggle.com/nanar69m/predict-ner-and-srl-on-abstracts',\n",
       "  'https://www.kaggle.com/rcd1693/cord-19-solution',\n",
       "  'https://www.kaggle.com/allen1985/covid-eda',\n",
       "  'https://www.kaggle.com/willem99/comparison-of-covid-19-virus-growth-per-country',\n",
       "  'https://www.kaggle.com/lalitapatel/papers-on-medical-care',\n",
       "  'https://www.kaggle.com/lalitapatel/papers-on-information-sharing-and-collaboration',\n",
       "  'https://www.kaggle.com/lalitapatel/papers-on-ethical-and-social-considerations',\n",
       "  'https://www.kaggle.com/zjwa127/covid-19-zhijie',\n",
       "  'https://www.kaggle.com/lalitapatel/papers-on-vaccines-and-therapeutics',\n",
       "  'https://www.kaggle.com/ashimak01/get-file-details',\n",
       "  'https://www.kaggle.com/deepshekhar/cord-19-eda-on-literature-kaggle-s-dataset',\n",
       "  'https://www.kaggle.com/zhcf1ess/covid-19-paper-analysis-part-i',\n",
       "  'https://www.kaggle.com/ajayago/cord-19-clustering-documents-using-abstract',\n",
       "  'https://www.kaggle.com/anandsrinivasan/covid-task-1-analysis-submission',\n",
       "  'https://www.kaggle.com/alexmulo/transmission-filtering-v1',\n",
       "  'https://www.kaggle.com/pgromano/eda-cleaning-the-cord-19-dataset',\n",
       "  'https://www.kaggle.com/siddheshkadam/covid19',\n",
       "  'https://www.kaggle.com/ramprakasism/covid-19-analysis',\n",
       "  'https://www.kaggle.com/enygmasciences/kaggle-covid-roppsters',\n",
       "  'https://www.kaggle.com/aadityaura/question-generation-tune-bert-telegrambot',\n",
       "  'https://www.kaggle.com/gabrielmv/an-lise-explorat-ria-coronavirus',\n",
       "  'https://www.kaggle.com/unzule/cord-19researchc-analysis',\n",
       "  'https://www.kaggle.com/cotega/semantic-search-of-covid-content',\n",
       "  'https://www.kaggle.com/himanshisingh/top-10-antiretroviral-c19',\n",
       "  'https://www.kaggle.com/hiagoaraujo/leitura-de-dados-e-clustering-medxiv',\n",
       "  'https://www.kaggle.com/koalabearski/could-citations-be-used-to-link-papers',\n",
       "  'https://www.kaggle.com/harshilkothari/covid-19-data-visualisation',\n",
       "  'https://www.kaggle.com/sumirp/cord-19-topic-modelling',\n",
       "  'https://www.kaggle.com/morrisb/03-create-a-collaboration-network-of-scientists',\n",
       "  'https://www.kaggle.com/pathtoai/corona-data-analysis',\n",
       "  'https://www.kaggle.com/billyzhaoyh/initial-start',\n",
       "  'https://www.kaggle.com/brarajit18/critical-epidemic-term-visualization-w-wordcloud',\n",
       "  'https://www.kaggle.com/amogh05/cord-19-eda-question-topic-modeling',\n",
       "  'https://www.kaggle.com/acmiyaguchi/citation-embeddings-with-visualization',\n",
       "  'https://www.kaggle.com/philipalexanderlees/kernela990a37deb',\n",
       "  'https://www.kaggle.com/rashaddism/outbreak-data-analysis',\n",
       "  'https://www.kaggle.com/stanhamster/kernel7457cf1f41',\n",
       "  'https://www.kaggle.com/daxman/a-simple-direct-covid-19-qa-engine',\n",
       "  'https://www.kaggle.com/shivampanchal/coronavirus-covid19-exploratory-analysis',\n",
       "  'https://www.kaggle.com/edrushton/cord-19-interactive-search-tool',\n",
       "  'https://www.kaggle.com/mmerino/covid19frame',\n",
       "  'https://www.kaggle.com/dskswu/topic-modeling-bert-lda',\n",
       "  'https://www.kaggle.com/furqanrustam118/topic-modeling-with-lda-and-nmf',\n",
       "  'https://www.kaggle.com/lalitapatel/papers-on-non-pharmaceutical-interventions',\n",
       "  'https://www.kaggle.com/lalitapatel/papers-on-diagnostics-and-surveillance',\n",
       "  'https://www.kaggle.com/teju4405/kernel154a79be15',\n",
       "  'https://www.kaggle.com/yazeenyuvvh/corona-19-clustering-and-topicwise-search',\n",
       "  'https://www.kaggle.com/tfolkman/abstract-similarity-for-covid-19',\n",
       "  'https://www.kaggle.com/rahulsarkar906/kernel2400a64d5a',\n",
       "  'https://www.kaggle.com/pranjalya/cord-19-embeddings-from-abstracts-notebook',\n",
       "  'https://www.kaggle.com/thebooort/covid19-exploration-and-paper-recommendation',\n",
       "  'https://www.kaggle.com/manishajain/wordcloud',\n",
       "  'https://www.kaggle.com/deeshantk/kernel6aeadef153',\n",
       "  'https://www.kaggle.com/ashwininadupuri/kernel666a075559',\n",
       "  'https://www.kaggle.com/davidbetancur8/risk-factors-word-cloud',\n",
       "  'https://www.kaggle.com/vaccine24/kernel162450d46d',\n",
       "  'https://www.kaggle.com/umar47/covid-19-clustering',\n",
       "  'https://www.kaggle.com/nerdyaditya/cord-19-parse-data-to-flat-format',\n",
       "  'https://www.kaggle.com/verasativa/kernel6f28923430',\n",
       "  'https://www.kaggle.com/lalitapatel/papers-on-transmission-and-incubation',\n",
       "  'https://www.kaggle.com/lalitapatel/papers-on-risk-factors',\n",
       "  'https://www.kaggle.com/suchivijay/kernel35d406586c',\n",
       "  'https://www.kaggle.com/joseantoniomanuel/covid-19-graph-clustering',\n",
       "  'https://www.kaggle.com/manasindia/covid-19-drug-and-chemical-mentions',\n",
       "  'https://www.kaggle.com/lauraeannielytics/laura-edell-walk-through-of-covid19',\n",
       "  'https://www.kaggle.com/washingtongold/bm25-index-search',\n",
       "  'https://www.kaggle.com/aurelepo/cord-19-solution-toolbox',\n",
       "  'https://www.kaggle.com/adriensas/tfidf-sklearn-model',\n",
       "  'https://www.kaggle.com/shacharosn/i-covid19-nlp-data-parsing-animals',\n",
       "  'https://www.kaggle.com/joseantoniomanuel/covid19-jam',\n",
       "  'https://www.kaggle.com/mlconsult/chloroquine-covid-19',\n",
       "  'https://www.kaggle.com/mlconsult/incubation-question-query-design',\n",
       "  'https://www.kaggle.com/dangelov/covid-19-topic-modelling-and-search-with-top2vec',\n",
       "  'https://www.kaggle.com/mlconsult/virus-variations',\n",
       "  'https://www.kaggle.com/mlconsult/testing-positive-after-recovery',\n",
       "  'https://www.kaggle.com/mlconsult/surface-persistence',\n",
       "  'https://www.kaggle.com/zeeshankeerio/covid-19-pandemic-in-pakistan-and-other',\n",
       "  'https://www.kaggle.com/something4kag/to-put-a-lamp-on-covid-19',\n",
       "  'https://www.kaggle.com/cheenguyen/aaaaaa',\n",
       "  'https://www.kaggle.com/slander/covid-add-sjr-if-to-metadata',\n",
       "  'https://www.kaggle.com/chahinezounoughi/covid-19-task-10',\n",
       "  'https://www.kaggle.com/chahinezounoughi/task-02-cord-19-challenge-covid-19',\n",
       "  'https://www.kaggle.com/processor/covid-19-unsupervised-literature-understanding',\n",
       "  'https://www.kaggle.com/selfflow/covid-19-dataset-insights',\n",
       "  'https://www.kaggle.com/pranjalya/similarity-between-docs-20-3-update',\n",
       "  'https://www.kaggle.com/tchainzzz/query2vec-creating-query-context-embeddings',\n",
       "  'https://www.kaggle.com/ramonrw/cord-19-competition-final-submission',\n",
       "  'https://www.kaggle.com/kendelsignore/kernel41a29f6692',\n",
       "  'https://www.kaggle.com/sudhendu/covid-19-literature-clustering',\n",
       "  'https://www.kaggle.com/anand795/covid-19-challenge-notebook',\n",
       "  'https://www.kaggle.com/srulikbd/scibert-sentence-similarity',\n",
       "  'https://www.kaggle.com/sudhendu/cord-19-search-articles-with-doc2vec',\n",
       "  'https://www.kaggle.com/skblaz/corvid-interactive',\n",
       "  'https://www.kaggle.com/jajsmith/cord-19-lda']}"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.DataFrame.from_dict(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes</th>\n",
       "      <th>user_link</th>\n",
       "      <th>tier</th>\n",
       "      <th>notebook_name</th>\n",
       "      <th>num_visualizations</th>\n",
       "      <th>num_datafiles</th>\n",
       "      <th>time_published</th>\n",
       "      <th>relative_time_published</th>\n",
       "      <th>tags</th>\n",
       "      <th>language</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>notebook_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165</td>\n",
       "      <td>https://kaggle.com/tarunkr</td>\n",
       "      <td>novice</td>\n",
       "      <td>COVID-19 Case Study - Analysis, Viz &amp; Comparisons</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Mar 30 2020 16:05:26 GMT-0400 (Eastern Day...</td>\n",
       "      <td>2h ago</td>\n",
       "      <td>[epidemiology, health, data visualization, sta...</td>\n",
       "      <td>Python</td>\n",
       "      <td>68</td>\n",
       "      <td>https://kaggle.com/tarunkr/covid-19-case-study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287</td>\n",
       "      <td>https://kaggle.com/dgunning</td>\n",
       "      <td>novice</td>\n",
       "      <td>Browsing research papers with a BM25 search en...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Mar 30 2020 09:00:51 GMT-0400 (Eastern Day...</td>\n",
       "      <td>9h ago</td>\n",
       "      <td>[beginner, eda, starter code]</td>\n",
       "      <td>Python</td>\n",
       "      <td>32</td>\n",
       "      <td>https://kaggle.com/dgunning/browsing-research-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107</td>\n",
       "      <td>https://kaggle.com/mobassir</td>\n",
       "      <td>master</td>\n",
       "      <td>üò∑Mining COVID-19 scientific papersü¶†</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon Mar 30 2020 10:58:23 GMT-0400 (Eastern Day...</td>\n",
       "      <td>7h ago</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>25</td>\n",
       "      <td>https://kaggle.com/mobassir/mining-covid-19-sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>https://kaggle.com/dirktheeng</td>\n",
       "      <td>novice</td>\n",
       "      <td>Anserini+BERT-SQuAD for context corpus search</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Mar 30 2020 17:00:31 GMT-0400 (Eastern Day...</td>\n",
       "      <td>1h ago</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>17</td>\n",
       "      <td>https://kaggle.com/dirktheeng/anserini-bert-sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>https://kaggle.com/duttadebadri</td>\n",
       "      <td>expert</td>\n",
       "      <td>COVID-19 Analysing Growth Factor &amp; Inflection</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Mar 30 2020 16:40:10 GMT-0400 (Eastern Day...</td>\n",
       "      <td>1h ago</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>6</td>\n",
       "      <td>https://kaggle.com/duttadebadri/covid-19-analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/srulikbd</td>\n",
       "      <td>novice</td>\n",
       "      <td>SciBERT+sentence similarity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Mar 19 2020 04:48:42 GMT-0400 (Eastern Day...</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/srulikbd/scibert-sentence-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/sudhendu</td>\n",
       "      <td>contributor</td>\n",
       "      <td>CORD-19 Search articles with Doc2Vec</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wed Mar 18 2020 13:34:21 GMT-0400 (Eastern Day...</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/sudhendu/cord-19-search-art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/mobasshir</td>\n",
       "      <td>contributor</td>\n",
       "      <td>Creating a Good Analytics Report</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Mar 30 2020 08:59:56 GMT-0400 (Eastern Day...</td>\n",
       "      <td>9h ago</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/mobasshir/creating-a-good-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/skblaz</td>\n",
       "      <td>novice</td>\n",
       "      <td>CORVID interactive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu Mar 19 2020 09:44:08 GMT-0400 (Eastern Day...</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/skblaz/corvid-interactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/jajsmith</td>\n",
       "      <td>novice</td>\n",
       "      <td>cord-19-LDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Mar 21 2020 00:12:44 GMT-0400 (Eastern Day...</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>[]</td>\n",
       "      <td>Python</td>\n",
       "      <td>0</td>\n",
       "      <td>https://kaggle.com/jajsmith/cord-19-lda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    votes                        user_link         tier  \\\n",
       "0     165       https://kaggle.com/tarunkr       novice   \n",
       "1     287      https://kaggle.com/dgunning       novice   \n",
       "2     107      https://kaggle.com/mobassir       master   \n",
       "3      25    https://kaggle.com/dirktheeng       novice   \n",
       "4      16  https://kaggle.com/duttadebadri       expert   \n",
       "..    ...                              ...          ...   \n",
       "488     0      https://kaggle.com/srulikbd       novice   \n",
       "489     0      https://kaggle.com/sudhendu  contributor   \n",
       "490     0     https://kaggle.com/mobasshir  contributor   \n",
       "491     0        https://kaggle.com/skblaz       novice   \n",
       "492     0      https://kaggle.com/jajsmith       novice   \n",
       "\n",
       "                                         notebook_name  num_visualizations  \\\n",
       "0    COVID-19 Case Study - Analysis, Viz & Comparisons                  53   \n",
       "1    Browsing research papers with a BM25 search en...                   0   \n",
       "2                  üò∑Mining COVID-19 scientific papersü¶†                   7   \n",
       "3        Anserini+BERT-SQuAD for context corpus search                   0   \n",
       "4      COVID-19 Analysing Growth Factor & Inflection                     2   \n",
       "..                                                 ...                 ...   \n",
       "488                        SciBERT+sentence similarity                   0   \n",
       "489               CORD-19 Search articles with Doc2Vec                   0   \n",
       "490                   Creating a Good Analytics Report                   0   \n",
       "491                                 CORVID interactive                   0   \n",
       "492                                        cord-19-LDA                   0   \n",
       "\n",
       "     num_datafiles                                     time_published  \\\n",
       "0                0  Mon Mar 30 2020 16:05:26 GMT-0400 (Eastern Day...   \n",
       "1                0  Mon Mar 30 2020 09:00:51 GMT-0400 (Eastern Day...   \n",
       "2                5  Mon Mar 30 2020 10:58:23 GMT-0400 (Eastern Day...   \n",
       "3                0  Mon Mar 30 2020 17:00:31 GMT-0400 (Eastern Day...   \n",
       "4                0  Mon Mar 30 2020 16:40:10 GMT-0400 (Eastern Day...   \n",
       "..             ...                                                ...   \n",
       "488              0  Thu Mar 19 2020 04:48:42 GMT-0400 (Eastern Day...   \n",
       "489              0  Wed Mar 18 2020 13:34:21 GMT-0400 (Eastern Day...   \n",
       "490              0  Mon Mar 30 2020 08:59:56 GMT-0400 (Eastern Day...   \n",
       "491              0  Thu Mar 19 2020 09:44:08 GMT-0400 (Eastern Day...   \n",
       "492              1  Sat Mar 21 2020 00:12:44 GMT-0400 (Eastern Day...   \n",
       "\n",
       "    relative_time_published  \\\n",
       "0                    2h ago   \n",
       "1                    9h ago   \n",
       "2                    7h ago   \n",
       "3                    1h ago   \n",
       "4                    1h ago   \n",
       "..                      ...   \n",
       "488                 12d ago   \n",
       "489                 12d ago   \n",
       "490                  9h ago   \n",
       "491                 11d ago   \n",
       "492                 10d ago   \n",
       "\n",
       "                                                  tags language num_comments  \\\n",
       "0    [epidemiology, health, data visualization, sta...   Python           68   \n",
       "1                        [beginner, eda, starter code]   Python           32   \n",
       "2                                                   []   Python           25   \n",
       "3                                                   []   Python           17   \n",
       "4                                                   []   Python            6   \n",
       "..                                                 ...      ...          ...   \n",
       "488                                                 []   Python            0   \n",
       "489                                                 []   Python            0   \n",
       "490                                                 []   Python            0   \n",
       "491                                                 []   Python            0   \n",
       "492                                                 []   Python            0   \n",
       "\n",
       "                                         notebook_link  \n",
       "0    https://kaggle.com/tarunkr/covid-19-case-study...  \n",
       "1    https://kaggle.com/dgunning/browsing-research-...  \n",
       "2    https://kaggle.com/mobassir/mining-covid-19-sc...  \n",
       "3    https://kaggle.com/dirktheeng/anserini-bert-sq...  \n",
       "4    https://kaggle.com/duttadebadri/covid-19-analy...  \n",
       "..                                                 ...  \n",
       "488  https://kaggle.com/srulikbd/scibert-sentence-s...  \n",
       "489  https://kaggle.com/sudhendu/cord-19-search-art...  \n",
       "490  https://kaggle.com/mobasshir/creating-a-good-a...  \n",
       "491       https://kaggle.com/skblaz/corvid-interactive  \n",
       "492            https://kaggle.com/jajsmith/cord-19-lda  \n",
       "\n",
       "[493 rows x 12 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-89a722731891>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmeta_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"covid-kernels.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'meta_df' is not defined"
     ]
    }
   ],
   "source": [
    "meta_df.to_csv(\"covid-kernels.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(\"covid-kernels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Chrome(webdriver)#, options=chrome_options)\n",
    "url = meta_df['notebook_link'][0]\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.frame(driver.find_element_by_xpath('//*[@id=\"rendered-kernel-content\"]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = [each.text for each in driver.find_elements_by_tag_name('h1')]\n",
    "h2 = [each.text for each in driver.find_elements_by_tag_name('h2')]\n",
    "h3 = [each.text for each in driver.find_elements_by_tag_name('h3')]\n",
    "h4 = [each.text for each in driver.find_elements_by_tag_name('h4')]\n",
    "h5 = [each.text for each in driver.find_elements_by_tag_name('h5')]\n",
    "h6 = [each.text for each in driver.find_elements_by_tag_name('h6')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = ['trend', 'map', 'curve', 'visualization', 'visualisation',\n",
    "              'prediction', 'tabulation', 'table', 'histogram', 'bar', 'figure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Intorduction to COVID-19',\n",
       " 'Downloding and Installing Prerequisite',\n",
       " 'Imports and Datasets',\n",
       " 'Preprocessing',\n",
       " 'Defining Functions',\n",
       " 'General Analysis of Data',\n",
       " 'Correlation Analysis',\n",
       " 'Visualization on Map\\nGlobal Confirmed Cases Heat Map\\nGlobal Deaths Heat Map',\n",
       " 'Global Confirmed Cases Heat Map',\n",
       " 'Global Deaths Heat Map',\n",
       " 'COVID-19 Spread Analysis\\nSpread Comparison with India New\\nCOVID-19 Spread Comparison of in different continents New',\n",
       " 'Spread Comparison with India New',\n",
       " 'COVID-19 Spread Comparison of in different continents New',\n",
       " 'COVID-19 Case (Confirmed, Deaths, Recovered and Active) Percent Split in Different countries (Pie Viz)',\n",
       " 'Global Prediction\\nTabulation of prediction and actual figure after 24th March (Global) New',\n",
       " 'Tabulation of prediction and actual figure after 24th March (Global) New',\n",
       " 'COVID-19 Mortality Rate Variation Over Period of Time',\n",
       " 'Comparision of Mortality and Recovery Rate',\n",
       " 'Cumulative Confirmed Cases and Cumulative Recovery Vs Cumulative Deaths Analysis',\n",
       " 'China Vs Outside China New',\n",
       " 'COVID-19 : INDIA New',\n",
       " 'Valuable Feedback']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[each.text for each in driver.find_element_by_id(\"Content-:\").find_element_by_xpath(\"..\").find_elements_by_tag_name('li')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we should probably just scrape all the imports then graph them lmfao\n",
    "\n",
    "A notebook with an unfamiliar import can lead to you getting more information about different data science technniques\n",
    "A notebook with low level imports can signal that this person is making their own model, etc.\n",
    "A notebook with cosmetic imports can help you add to your toolkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60436"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(driver.find_element_by_xpath('//*[@id=\"notebook\"]').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load lxml tree\n",
    "tree = html.fromstring(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12981"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str([each.text for each in tree.body.xpath('//*[self::p or self::strong or self::h1 or self::h2 or self::h3 or self::h4]')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16,735'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get views\n",
    "tree.xpath('//*[@id=\"kernel-header-wrapper\"]/div[1]/span[1]/span[2]/span/span[2]/span')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[None]'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str([each.text for each in tree.xpath('//*[@id=\"rendered-kernel-content\"]')])#[self::h1 or self::h2 or self::h3 or self::p]')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "    code = [each.text for each in driver.find_elements_by_class_name(\"input_area\") if 'import' in each.text]\n",
    "    modules = []\n",
    "    for block in code:\n",
    "        for each in block.split('\\n'):\n",
    "            tokens = each.split(' ')\n",
    "            if tokens[0] == 'import':\n",
    "                for package in re.sub(' ', '', each.split(' as ')[0].split('import')[1]).split(','):\n",
    "                    modules.append(package)\n",
    "            elif tokens[0] == 'from':\n",
    "                submodules = each.split('import')[1]\n",
    "                for sub in re.sub(' ', '', submodules).split(','):\n",
    "                    modules.append(tokens[1]+'.'+sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ipywidgets.Image',\n",
       " 'cord.ResearchPapers',\n",
       " 'multiprocessing',\n",
       " 'concurrent.futures.ThreadPoolExecutor',\n",
       " 'concurrent.futures.as_completed',\n",
       " 'typing.Collection',\n",
       " 'typing.Any',\n",
       " 'ipywidgets.Image']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.xpath(\"//*[@class='input_area']\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = bsoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11599"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str(bs.body.findAll(['h1', 'h2', 'h3', 'p'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' views']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.findAll( = \" views\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = html.fromstring(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10059"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = tree.cssselect('strong')+tree.cssselect('p')+tree.cssselect('h1')+tree.cssselect('h2')+tree.cssselect('h3')\n",
    "len(str([each.text for each in text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://kaggle.com/tarunkr/covid-19-case-study-analysis-viz-comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.frame(driver.find_element_by_xpath('//*[@id=\"rendered-kernel-content\"]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = html.fromstring(driver.page_source)\n",
    "#//*[@id=\"kernel-header-wrapper\"]/div[1]/span[1]/span[2]/span/span[2]/span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-ab919d0f8c56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"KernelViewerContext_KernelSubtitle-sc-rltxca jxVKtW\"]/span[2]/span'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tree.xpath('//*[@id=\"KernelViewerContext_KernelSubtitle-sc-rltxca jxVKtW\"]/span[2]/span')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11,204'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.xpath('//*[@id=\"kernel-header-wrapper\"]/div[1]/span[1]/span[2]/span/span[2]/span')[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# requests/ lxml rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.kaggleusercontent.com/kf/30719380/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..8bzKldvxCkXAaypbyImZTg.s9-xLIUZe8uV6U3re40aWvYORBBUfVkjJWhGuD6SiG1g7hORbv7F1d9_UGjYFh26tgUlb5veTSY0E2zuRpsVf_Jo6kPGq9T20ezNJ7s6phV8z3s0e5kloj7cW1ms6ElD3YHgHm9bEgZqhgRU5OG7tpS-e6SajA6Um2RdcPTZr7yPujY5KsK_dYQg0f15xlnO1GXoo3f6rut9A47t7Neox2NaArx1SnDRcKM7mm_Gv8z2huQ5PkPCFEE5NoA8rB_AkhqZKeF9x8ClSIDl02xEgu6gbp_nGAF9mIiop4V4DkmCLA9hyVuzFITEYxEHFtC3zzptP0U5h3sdEMY20AVhPsR64rdsS95-7ut2Jrw_N0qctWs1cZqjQ_FhipUNx5j2SW9sSXVRS2wjCKZwmVut4wPiXgYi0CgVEG1gybEqkYdqghkdfFSXMh_07OquPyhaFqGwVjCTseZynIQxSZwjnNH8xMRgcryDNrAycKwREvdF69jxv4UtqRSbgquXWdWhIFCXjEaYr6TTXFIJYiNt8_QYgwJwPraIL71aWC0J0HtXvquaxDOrSPzoxeU3HkwPx8UuDk1Fwf-ExFC9XlNWZ8gzCapKjS_n1jY-ph99iy0MS3OTryZQN2Hv6n2hc--ajUP67H2J0VAG-hP4jMnWz_uMu48g4tom3xj5c3KYwcqOkFAT17ZCDrLdFKkwq7_g.2VCKvbXlYIwnWYPyLzv8Cg/__results__.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = html.fromstring(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.xpath('//*[@class=\"_kg_hide-input-true\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = html.fromstring(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<iframe id=\"rendered-kernel-content\" src=\"https://www.kaggleusercontent.com/kf/30719380/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..LJKthxuWaLqdSnSerftX3Q.jUAwCpIn5a4AcPc6b4Ds7G0WKFnvT_FDupjOuf9kr15EsP1wxnBEspVLmCK606tMWDVNTfciOmiPSN3hs4njXZdqdroSItBNupQunj9NBIUw6T6MLIT6EzZ3tmO9biEiPqlvZhHf6enTdl3iK_KJ67Qt1uUlwT8r7Wh6RU9PkZYAmBAMzaIQdO41nfomO0MrlP6BDrpr-JGT3Z-cQN7CL_v3sU8LMys0ZdWEhUiU-3G5XiU2x6tBlE3wQEIdupUjRJqiLhH4ZYoCnMuyPqBF91Bzu5DSG29SVvLmIEKeOEy7QUlMr_0C38tHrXZ1Jv-KLxmRTdqfSXiHtaViP1mdwmwHK3DHj_m7XjxAYLukPVLpFxPdwxcWeKzp_3TaeyfkplM79Sc_bzw4JJl8QnXij2i9v6hbF1TqJS8ER4jShS-MC93mR2FHhxXMDBBeGp7sVxEyHRql0OEp0u4-RlWNqXUaHkdTH-6kNkEk9icKIRLmEt9WxQ0LZG0J0y4BhgPNSQEL5i8XCn4zcecqHNWDUk9eP3nDc0WUoUE7cIpWkPIIi9VuVyNdWqUHeYdAxbcui76KG3aIg0Z42yRbsVx_5cBFL1QLjejLBA-qgUOK2mwrNf809Jca9Z8eEjjqb1oKCJSMlDM-rOanLhX1THAAvA27NWgRrLYZtFkEVKwXYebbrWv-lyIn5YADyKY2PdVD.y0yzInQarTfOB-G47hKqDg/__results__.html\" scrolling=\"no\" title=\"Main Kernel Content\" class=\"sc-erNlkL hpVXSS\" style=\"height: 46865px; display: block;\"></iframe>'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.tostring(tree.xpath('//*[self::iframe]')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.xpath('//*[@id=\"kernel-header-wrapper\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://kaggle.com/tarunkr/covid-19-case-study-analysis-viz-comparisons\n",
      "11,207 views\n",
      "22 module(s)\n",
      "5537 characters\n",
      "https://kaggle.com/dgunning/browsing-research-papers-with-a-bm25-search-engine\n",
      "16,897 views\n",
      "7 module(s)\n",
      "3005 characters\n",
      "https://kaggle.com/mobassir/mining-covid-19-scientific-papers\n",
      "5,154 views\n",
      "66 module(s)\n",
      "7784 characters\n",
      "https://kaggle.com/dirktheeng/anserini-bert-squad-for-context-corpus-search\n",
      "1,139 views\n",
      "14 module(s)\n",
      "7925 characters\n",
      "https://kaggle.com/duttadebadri/covid-19-analysing-growth-factor-inflection\n",
      "2,173 views\n",
      "13 module(s)\n",
      "4069 characters\n",
      "https://kaggle.com/mlconsult/transmission-incubation-and-environment-2-0\n",
      "71 views\n",
      "6 module(s)\n",
      "2942 characters\n",
      "https://kaggle.com/phyothuhtet/document-clustering-kmeans-som\n",
      "357 views\n",
      "17 module(s)\n",
      "6570 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-analysis-with-sentence-embeddings\n",
      "5,794 views\n",
      "16 module(s)\n",
      "6998 characters\n",
      "https://kaggle.com/gatunnopvp/covid-19-in-brazil-predicting-cases-and-deaths\n",
      "835 views\n",
      "19 module(s)\n",
      "2378 characters\n",
      "https://kaggle.com/yuanso/covid-19-four-different-epidemic-situations\n",
      "1,124 views\n",
      "0 module(s)\n",
      "2580 characters\n",
      "https://kaggle.com/marcusgawronsky/cord-19-simple-scikit-topic-models-doc2vec\n",
      "56 views\n",
      "24 module(s)\n",
      "5269 characters\n",
      "https://kaggle.com/dannellyz/cord19-metadata-enrich-microsoft-academic-api\n",
      "25 views\n",
      "6 module(s)\n",
      "847 characters\n",
      "https://kaggle.com/corochann/covid-19-eda-with-recent-update-on-march\n",
      "661 views\n",
      "25 module(s)\n",
      "5910 characters\n",
      "https://kaggle.com/jkb123/semantic-search-using-vespa-ai-s-cord19-index\n",
      "21 views\n",
      "6 module(s)\n",
      "272 characters\n",
      "https://kaggle.com/chaker1/document-embeddings-to-find-tasks-related-papers\n",
      "23 views\n",
      "15 module(s)\n",
      "1693 characters\n",
      "https://kaggle.com/maria17/cord-19-explore-drugs-being-developed\n",
      "2,006 views\n",
      "34 module(s)\n",
      "6443 characters\n",
      "https://kaggle.com/jiripodivin/covsum\n",
      "41 views\n",
      "11 module(s)\n",
      "3279 characters\n",
      "https://kaggle.com/psrajput/cord-19\n",
      "86 views\n",
      "4 module(s)\n",
      "74 characters\n",
      "https://kaggle.com/arturkiulian/coronawhy-org-global-collaboration-join-slack\n",
      "5,458 views\n",
      "1 module(s)\n",
      "12850 characters\n",
      "https://kaggle.com/donkeys/my-little-preprocessing\n",
      "6 views\n",
      "28 module(s)\n",
      "4669 characters\n",
      "https://kaggle.com/raymondjia/3d-world-heat-map-of-cumulative-confirmed-case\n",
      "110 views\n",
      "0 module(s)\n",
      "505 characters\n",
      "https://kaggle.com/maonanwang/data-analysis-on-coronavirus\n",
      "177 views\n",
      "17 module(s)\n",
      "2104 characters\n",
      "https://kaggle.com/ajrwhite/covid-19-risk-factors\n",
      "87 views\n",
      "6 module(s)\n",
      "315 characters\n",
      "https://kaggle.com/maksimeren/covid-19-literature-clustering\n",
      "40,048 views\n",
      "41 module(s)\n",
      "7140 characters\n",
      "https://kaggle.com/ritam3144/covid19-challanges\n",
      "8 views\n",
      "9 module(s)\n",
      "187 characters\n",
      "https://kaggle.com/isaacmg/scibert-embeddings\n",
      "1,135 views\n",
      "22 module(s)\n",
      "4855 characters\n",
      "https://kaggle.com/danielwolffram/topic-modeling-finding-related-articles\n",
      "17,457 views\n",
      "25 module(s)\n",
      "2640 characters\n",
      "https://kaggle.com/mlconsult/virus-strains\n",
      "23 views\n",
      "3 module(s)\n",
      "180 characters\n",
      "https://kaggle.com/jpmiller/creating-a-good-analytics-report\n",
      "23,511 views\n",
      "0 module(s)\n",
      "3799 characters\n",
      "https://kaggle.com/xhlulu/cord-19-eda-parse-json-and-generate-clean-csv\n",
      "13,210 views\n",
      "7 module(s)\n",
      "1753 characters\n",
      "https://kaggle.com/chuntolee/cord-19-challenge-titles-topic-modelling\n",
      "36 views\n",
      "20 module(s)\n",
      "5888 characters\n",
      "https://kaggle.com/darensin01/sentence-embeddings-with-spacy-and-scispacy\n",
      "26 views\n",
      "15 module(s)\n",
      "630 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-transmission-incubation-environment\n",
      "310 views\n",
      "2 module(s)\n",
      "1583 characters\n",
      "https://kaggle.com/tarunpaparaju/covid-19-dataset-gaining-actionable-insights\n",
      "16,354 views\n",
      "37 module(s)\n",
      "10059 characters\n",
      "https://kaggle.com/ajrwhite/covid-19-thematic-tagging-with-regular-expressions\n",
      "2,301 views\n",
      "5 module(s)\n",
      "3073 characters\n",
      "https://kaggle.com/mikehatchi/covid-19-risk-factors-sci-nlp-compiler\n",
      "90 views\n",
      "11 module(s)\n",
      "2199 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-diagnostics-and-surveillance\n",
      "61 views\n",
      "2 module(s)\n",
      "3804 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-ethical-and-social-science-considerations\n",
      "57 views\n",
      "2 module(s)\n",
      "1531 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-medical-care\n",
      "55 views\n",
      "2 module(s)\n",
      "2179 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-non-pharmaceutical-interventions\n",
      "56 views\n",
      "2 module(s)\n",
      "1922 characters\n",
      "https://kaggle.com/narasimha1997/faster-semantic-search-using-faiss\n",
      "121 views\n",
      "8 module(s)\n",
      "3419 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-vaccines-and-therapeutics\n",
      "71 views\n",
      "2 module(s)\n",
      "1524 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-virus-genetics-origin-and-evolution\n",
      "83 views\n",
      "2 module(s)\n",
      "1300 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-risk-factors\n",
      "112 views\n",
      "2 module(s)\n",
      "870 characters\n",
      "https://kaggle.com/dannellyz/cord19-metadata-enrich-nih-api\n",
      "142 views\n",
      "5 module(s)\n",
      "2647 characters\n",
      "https://kaggle.com/daxman/covid-19-corpus-pickle-factory\n",
      "6 views\n",
      "13 module(s)\n",
      "87 characters\n",
      "https://kaggle.com/ahmedewida/covid-19-tasks-filtering\n",
      "204 views\n",
      "32 module(s)\n",
      "8827 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-sharing-and-collaboration\n",
      "39 views\n",
      "2 module(s)\n",
      "1765 characters\n",
      "https://kaggle.com/gpreda/cord-19-solution-toolbox\n",
      "7,521 views\n",
      "10 module(s)\n",
      "1492 characters\n",
      "https://kaggle.com/izzatalsmadi/extract-covid-19-treatments-related-articles\n",
      "36 views\n",
      "6 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/shahules/cord-tools-and-knowledge-graphs\n",
      "6,215 views\n",
      "31 module(s)\n",
      "683 characters\n",
      "https://kaggle.com/uplytics/evidence-gap-map-for-risk-areas\n",
      "175 views\n",
      "13 module(s)\n",
      "1214 characters\n",
      "https://kaggle.com/sixteenpython/covid-19-temperature-air-travel-transmission\n",
      "6,817 views\n",
      "14 module(s)\n",
      "2739 characters\n",
      "https://kaggle.com/ravitatakc/covid19-1-visualization\n",
      "26 views\n",
      "9 module(s)\n",
      "284 characters\n",
      "https://kaggle.com/lalitapatel/correlation-of-covid-19-to-white-nose-syndrome\n",
      "89 views\n",
      "6 module(s)\n",
      "3258 characters\n",
      "https://kaggle.com/cstefanache/nlp-text-mining-disease-behavior\n",
      "3,586 views\n",
      "12 module(s)\n",
      "2543 characters\n",
      "https://kaggle.com/davidmezzetti/cord-19-report-builder\n",
      "86 views\n",
      "5 module(s)\n",
      "123 characters\n",
      "https://kaggle.com/latong/extractive-text-summarization-ner-exploration\n",
      "357 views\n",
      "18 module(s)\n",
      "1666 characters\n",
      "https://kaggle.com/something4kag/covid-19-utility-script\n",
      "4 views\n",
      "12 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/ratan123/cord-19-understanding-papers-with-textanalytics\n",
      "3,201 views\n",
      "43 module(s)\n",
      "3038 characters\n",
      "https://kaggle.com/saga21/cord-19-data-extraction-functions\n",
      "5,874 views\n",
      "14 module(s)\n",
      "8465 characters\n",
      "https://kaggle.com/group16/covid-19-knowledge-graph-embeddings\n",
      "637 views\n",
      "35 module(s)\n",
      "1577 characters\n",
      "https://kaggle.com/d4v1d3/cord-19-lda-topic-modeling-reccomendation-system\n",
      "4,676 views\n",
      "8 module(s)\n",
      "81 characters\n",
      "https://kaggle.com/ztsincom/country-based-study-on-covid-19\n",
      "1,291 views\n",
      "10 module(s)\n",
      "2264 characters\n",
      "https://kaggle.com/tanulsingh077/a-comprehensive-resource-notebook-for-beginners\n",
      "2,055 views\n",
      "7 module(s)\n",
      "2635 characters\n",
      "https://kaggle.com/paultimothymooney/most-common-words-in-the-cord-19-dataset\n",
      "4,970 views\n",
      "12 module(s)\n",
      "219 characters\n",
      "https://kaggle.com/fmitchell259/create-corona-csv-file\n",
      "2,490 views\n",
      "6 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/dangelov/covid-19-top2vec-interactive-search\n",
      "47 views\n",
      "8 module(s)\n",
      "1172 characters\n",
      "https://kaggle.com/ivanegapratama/covid-eda-initial-exploration-tool\n",
      "1,604 views\n",
      "5 module(s)\n",
      "331 characters\n",
      "https://kaggle.com/dattaraj/risks-of-covid-19-ai-driven-q-a\n",
      "1,210 views\n",
      "8 module(s)\n",
      "2371 characters\n",
      "https://kaggle.com/ezekielyovel/kernel5e2466e43e\n",
      "9 views\n",
      "3 module(s)\n",
      "52 characters\n",
      "https://kaggle.com/anuraagsaini/corona-virus-data-visualization\n",
      "1,369 views\n",
      "0 module(s)\n",
      "1206 characters\n",
      "https://kaggle.com/onyonixch/covid-19-deep-embedded-literature-clustering\n",
      "15 views\n",
      "26 module(s)\n",
      "2592 characters\n",
      "https://kaggle.com/danich329/exploring-corona-competition\n",
      "0 views\n",
      "6 module(s)\n",
      "457 characters\n",
      "https://kaggle.com/zoupet/covid-19-search-engine-with-bert\n",
      "530 views\n",
      "9 module(s)\n",
      "1710 characters\n",
      "https://kaggle.com/chirag9073/coronavirus-covid-19-outbreak-data-analysis\n",
      "1,559 views\n",
      "12 module(s)\n",
      "3869 characters\n",
      "https://kaggle.com/mlconsult/summary-page-vaccines-and-therapeutics\n",
      "251 views\n",
      "6 module(s)\n",
      "5177 characters\n",
      "https://kaggle.com/hamid3731/keyphrase-extraction-and-graph-analysis\n",
      "574 views\n",
      "20 module(s)\n",
      "3473 characters\n",
      "https://kaggle.com/mlconsult/summary-page-covid-19-risk-factors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 views\n",
      "6 module(s)\n",
      "2755 characters\n",
      "https://kaggle.com/robbieedwards/covid-19-lda-notebook\n",
      "42 views\n",
      "15 module(s)\n",
      "302 characters\n",
      "https://kaggle.com/cedna198/visualization-of-virus-origin-genetic-evolution\n",
      "93 views\n",
      "32 module(s)\n",
      "2341 characters\n",
      "https://kaggle.com/albertoferrari/most-mentioned-antivirals\n",
      "1,141 views\n",
      "10 module(s)\n",
      "2276 characters\n",
      "https://kaggle.com/panosc/epidemiological-curves-using-ecdc-data\n",
      "1,625 views\n",
      "0 module(s)\n",
      "2118 characters\n",
      "https://kaggle.com/docxian/cord-19-metadata-evaluation\n",
      "2,026 views\n",
      "12 module(s)\n",
      "257 characters\n",
      "https://kaggle.com/luisblanche/cord-19-match-articles-to-tasks-w-doc2vec\n",
      "2,144 views\n",
      "16 module(s)\n",
      "4042 characters\n",
      "https://kaggle.com/dangelov/covid-19-topic-modeling-and-search-with-top2vec\n",
      "72 views\n",
      "5 module(s)\n",
      "1562 characters\n",
      "https://kaggle.com/arturkiulian/coronawhy-org-task-risk-factors\n",
      "63 views\n",
      "1 module(s)\n",
      "6378 characters\n",
      "https://kaggle.com/thebooort/epidemiology-math-models-used-in-research\n",
      "144 views\n",
      "9 module(s)\n",
      "3353 characters\n",
      "https://kaggle.com/mlconsult/age-dependent-incubation-period\n",
      "115 views\n",
      "3 module(s)\n",
      "81 characters\n",
      "https://kaggle.com/nabeelsajid917/covid-19-detection-from-x-ray-images-of-lungs\n",
      "1,033 views\n",
      "24 module(s)\n",
      "719 characters\n",
      "https://kaggle.com/jdparsons/biobert-corex-topic-search\n",
      "696 views\n",
      "12 module(s)\n",
      "2578 characters\n",
      "https://kaggle.com/adelfdelvalleperez/cord-19-fasttext-words-clustering\n",
      "1,161 views\n",
      "28 module(s)\n",
      "2375 characters\n",
      "https://kaggle.com/danielwolffram/cord-19-create-dataframe\n",
      "264 views\n",
      "9 module(s)\n",
      "1272 characters\n",
      "https://kaggle.com/dannellyz/cord19-metadata-enrich-altmetric-api\n",
      "35 views\n",
      "6 module(s)\n",
      "755 characters\n",
      "https://kaggle.com/acmiyaguchi/pyspark-dataframe-preprocessing-for-cord-19\n",
      "737 views\n",
      "5 module(s)\n",
      "2986 characters\n",
      "https://kaggle.com/andreamorgar/covid19\n",
      "86 views\n",
      "19 module(s)\n",
      "719 characters\n",
      "https://kaggle.com/cheenguyen/aaaaaa\n",
      "37 views\n",
      "4 module(s)\n",
      "289 characters\n",
      "https://kaggle.com/rohailsyed/consolidating-effects-of-risk-factors-on-covid-19\n",
      "1,194 views\n",
      "12 module(s)\n",
      "840 characters\n",
      "https://kaggle.com/tintedblast/covid-19-open-research-dataset-cord-19-analysis\n",
      "340 views\n",
      "10 module(s)\n",
      "3279 characters\n",
      "https://kaggle.com/crprpr/vaccine-data-filter\n",
      "3,132 views\n",
      "16 module(s)\n",
      "1848 characters\n",
      "https://kaggle.com/cogitae/create-corona-csv-file\n",
      "301 views\n",
      "6 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/salmanhiro/world-covid-19-eda\n",
      "2,105 views\n",
      "6 module(s)\n",
      "437 characters\n",
      "https://kaggle.com/trilabs/covid2020\n",
      "1,018 views\n",
      "3 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/mpwolke/non-pharmaceutical-interventions-covid-19\n",
      "1,648 views\n",
      "15 module(s)\n",
      "13479 characters\n",
      "https://kaggle.com/hamditarek/topic-modelling-journals-content-about-covid-19\n",
      "345 views\n",
      "47 module(s)\n",
      "4017 characters\n",
      "https://kaggle.com/mmoeller/a-references-based-atlas-of-covid-19-research\n",
      "130 views\n",
      "2 module(s)\n",
      "3165 characters\n",
      "https://kaggle.com/tylersuard/mat2vec-covid-papers-unexpected-word-asociations\n",
      "367 views\n",
      "0 module(s)\n",
      "1156 characters\n",
      "https://kaggle.com/puneetkochar/beat-corona\n",
      "19 views\n",
      "8 module(s)\n",
      "36 characters\n",
      "https://kaggle.com/mikehoney/hyperion\n",
      "193 views\n",
      "1 module(s)\n",
      "2271 characters\n",
      "https://kaggle.com/slander/add-pub-types-to-metadata-df\n",
      "31 views\n",
      "5 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/vikassingh1996/covid-19-extracting-the-hidden-topics-with-gensim\n",
      "73 views\n",
      "19 module(s)\n",
      "4483 characters\n",
      "https://kaggle.com/salmanhiro/covids-incubation-transmission-related-articles\n",
      "1,040 views\n",
      "3 module(s)\n",
      "1413 characters\n",
      "https://kaggle.com/karankrishna/corona-virus-latest-analysis\n",
      "592 views\n",
      "7 module(s)\n",
      "5556 characters\n",
      "https://kaggle.com/yuanso/covid-19-save-people-in-developing-countries\n",
      "27 views\n",
      "0 module(s)\n",
      "1293 characters\n",
      "https://kaggle.com/mlconsult/testing-positive-after-recovery\n",
      "40 views\n",
      "3 module(s)\n",
      "55 characters\n",
      "https://kaggle.com/karthikmohan27/cord-19-lda-topic-model-abstracts\n",
      "33 views\n",
      "12 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/psrajput/cord19-generating-corona-csv\n",
      "16 views\n",
      "2 module(s)\n",
      "169 characters\n",
      "https://kaggle.com/adityakaushal98/range-of-incubation-periods-for-the-disease\n",
      "87 views\n",
      "8 module(s)\n",
      "475 characters\n",
      "https://kaggle.com/slander/count-pmids-per-journal-no-full-text\n",
      "14 views\n",
      "1 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/willem99/comparison-of-covid-19-virus-growth-per-country\n",
      "295 views\n",
      "6 module(s)\n",
      "2551 characters\n",
      "https://kaggle.com/alizahidraja/covid-19-search-engine-for-all-queries-use\n",
      "2,285 views\n",
      "21 module(s)\n",
      "3114 characters\n",
      "https://kaggle.com/ajtamayoh/tabu2020\n",
      "22 views\n",
      "17 module(s)\n",
      "1743 characters\n",
      "https://kaggle.com/ajrwhite/covid-19-transmission-and-incubation\n",
      "937 views\n",
      "5 module(s)\n",
      "307 characters\n",
      "https://kaggle.com/sunmoon/corona-text-mining-spacy\n",
      "1,037 views\n",
      "8 module(s)\n",
      "1502 characters\n",
      "https://kaggle.com/danielwolffram/user-friendly-finding-related-articles\n",
      "958 views\n",
      "24 module(s)\n",
      "2124 characters\n",
      "https://kaggle.com/beatrizyumi/covid-19-autocomplete-search-bar\n",
      "2,331 views\n",
      "15 module(s)\n",
      "410 characters\n",
      "https://kaggle.com/vasuji/i-covid19-nlp-data-parsing\n",
      "1,114 views\n",
      "6 module(s)\n",
      "1552 characters\n",
      "https://kaggle.com/mimisun/covid-19-subset-of-articles\n",
      "408 views\n",
      "6 module(s)\n",
      "161 characters\n",
      "https://kaggle.com/theamrzaki/covid-19-bert-researchpapers-semantic-search\n",
      "910 views\n",
      "9 module(s)\n",
      "58758 characters\n",
      "https://kaggle.com/group16/covid-19-knowledge-graph-starter\n",
      "617 views\n",
      "3 module(s)\n",
      "1192 characters\n",
      "https://kaggle.com/aruncps/basic-setup-to-import-the-json-files\n",
      "354 views\n",
      "0 module(s)\n",
      "295 characters\n",
      "https://kaggle.com/fmitchell259/creating-a-doc2vec-model\n",
      "631 views\n",
      "5 module(s)\n",
      "4318 characters\n",
      "https://kaggle.com/sourojit/biobert-covid2\n",
      "25 views\n",
      "13 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/sourojit/biobert-covid4\n",
      "10 views\n",
      "13 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/khoongweihao/covid-19-ct-scan-xray-cnn-detector\n",
      "639 views\n",
      "27 module(s)\n",
      "392 characters\n",
      "https://kaggle.com/andyh47/match-papers-to-tasks\n",
      "359 views\n",
      "8 module(s)\n",
      "682 characters\n",
      "https://kaggle.com/jazivxt/task-question-search\n",
      "372 views\n",
      "9 module(s)\n",
      "41 characters\n",
      "https://kaggle.com/onyonixch/cord-19-research-challenge-relevant-doc-search\n",
      "335 views\n",
      "6 module(s)\n",
      "1604 characters\n",
      "https://kaggle.com/vasuji/ii-covid19-citation-network\n",
      "377 views\n",
      "7 module(s)\n",
      "1633 characters\n",
      "https://kaggle.com/ajayago/cord-19-topic-modelling-on-abstracts\n",
      "42 views\n",
      "18 module(s)\n",
      "127 characters\n",
      "https://kaggle.com/sandeepbhogaraju/covid-19-eda\n",
      "22 views\n",
      "0 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/ahmednassour/covid-19-temperature-and-transmission-rates\n",
      "822 views\n",
      "14 module(s)\n",
      "2586 characters\n",
      "https://kaggle.com/stormliucong/covid-19-mortality\n",
      "1,158 views\n",
      "0 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/romangaev/covid-19-ultimate-chronology-patients-analysis\n",
      "679 views\n",
      "15 module(s)\n",
      "2565 characters\n",
      "https://kaggle.com/shanmukha99/bio-ner-on-covid-19-data\n",
      "280 views\n",
      "11 module(s)\n",
      "161 characters\n",
      "https://kaggle.com/albertoferrari/learning-medicine-with-word-embeddings\n",
      "80 views\n",
      "12 module(s)\n",
      "1912 characters\n",
      "https://kaggle.com/raihan1319/kernelcb2b29c22c\n",
      "9 views\n",
      "5 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/michtyson/covid-19-xray-dl\n",
      "775 views\n",
      "5 module(s)\n",
      "5465 characters\n",
      "https://kaggle.com/salikhussaini49/exploratory-data-analysis-covid-19-from-ecdc\n",
      "395 views\n",
      "0 module(s)\n",
      "1745 characters\n",
      "https://kaggle.com/charlieharper/map-search-of-places-in-cord-19-full-text\n",
      "340 views\n",
      "1 module(s)\n",
      "973 characters\n",
      "https://kaggle.com/franciswolinski/cord-19-human-genes-insights\n",
      "238 views\n",
      "10 module(s)\n",
      "305 characters\n",
      "https://kaggle.com/shiromiyuki/covid-19-using-tf-idf\n",
      "1,756 views\n",
      "15 module(s)\n",
      "17245 characters\n",
      "https://kaggle.com/panosc/covid-19-epidemiological-curves-at-regional-level\n",
      "645 views\n",
      "0 module(s)\n",
      "2012 characters\n",
      "https://kaggle.com/raheelsyed/covid-19-pandemic-eda\n",
      "284 views\n",
      "4 module(s)\n",
      "1397 characters\n",
      "https://kaggle.com/tourist800/extract-entities-from-abstracts\n",
      "1,120 views\n",
      "8 module(s)\n",
      "300 characters\n",
      "https://kaggle.com/dattaraj/demo-of-using-custom-ner-model-on-covid-19-dataset\n",
      "627 views\n",
      "6 module(s)\n",
      "1642 characters\n",
      "https://kaggle.com/jonathanbesomi/cord-19-sources-unification-with-pyspark-sql\n",
      "244 views\n",
      "10 module(s)\n",
      "1116 characters\n",
      "https://kaggle.com/elsonidoq/train-a-word2vec\n",
      "429 views\n",
      "5 module(s)\n",
      "329 characters\n",
      "https://kaggle.com/khotijahs1/cord-19-metadata\n",
      "264 views\n",
      "16 module(s)\n",
      "89 characters\n",
      "https://kaggle.com/mpwolke/viral-agents-s100a12-marker\n",
      "115 views\n",
      "14 module(s)\n",
      "1789 characters\n",
      "https://kaggle.com/blasteraj/covid-19\n",
      "23 views\n",
      "30 module(s)\n",
      "205 characters\n",
      "https://kaggle.com/fschilder/asking-questions-with-a-bm25-bert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 views\n",
      "15 module(s)\n",
      "2842 characters\n",
      "https://kaggle.com/arpitrathi/utilizing-biobert-for-k-means-topic-clustering\n",
      "192 views\n",
      "18 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/dgunning/a-cord19-research-paper-search-engine\n",
      "227 views\n",
      "1 module(s)\n",
      "2094 characters\n",
      "https://kaggle.com/midnitekoder/covid-19-citation-graph-embedding-using-deepwalk\n",
      "337 views\n",
      "12 module(s)\n",
      "125 characters\n",
      "https://kaggle.com/otayeby/cord-19-parse-docs-r\n",
      "134 views\n",
      "0 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/mpwolke/diagnosing-covid-19\n",
      "633 views\n",
      "26 module(s)\n",
      "11790 characters\n",
      "https://kaggle.com/guymitch2007/covid-19-top-scholarly-journals\n",
      "696 views\n",
      "8 module(s)\n",
      "2120 characters\n",
      "https://kaggle.com/houssemayed/lda-information-visualization-from-cord-19\n",
      "364 views\n",
      "15 module(s)\n",
      "300 characters\n",
      "https://kaggle.com/jonathancarvalho/keywords-on-the-subject-ethical-and-social\n",
      "784 views\n",
      "14 module(s)\n",
      "447 characters\n",
      "https://kaggle.com/alizahidraja/covid-19-find-the-right-research-paper-with-tags\n",
      "373 views\n",
      "8 module(s)\n",
      "3556 characters\n",
      "https://kaggle.com/gkaraman/topic-modeling-lda-on-cord-19-paper-abstracts\n",
      "475 views\n",
      "16 module(s)\n",
      "374 characters\n",
      "https://kaggle.com/mlconsult/air-temperature-and-covid-19\n",
      "234 views\n",
      "3 module(s)\n",
      "75 characters\n",
      "https://kaggle.com/umar47/covid-19-launched-treaments-by-who-worldcloud\n",
      "34 views\n",
      "8 module(s)\n",
      "234 characters\n",
      "https://kaggle.com/rocket95/covid-19-incubation-time\n",
      "59 views\n",
      "9 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/edopredo/covid-19-literature-query-tool\n",
      "154 views\n",
      "5 module(s)\n",
      "2976 characters\n",
      "https://kaggle.com/daking/extracting-entities-linked-to-umls-with-scispacy\n",
      "162 views\n",
      "11 module(s)\n",
      "2 characters\n",
      "https://kaggle.com/bs2537/searching-data-using-knn-neighbors-topic-modeling\n",
      "339 views\n",
      "16 module(s)\n",
      "2950 characters\n",
      "https://kaggle.com/youhanlee/comfirmed-bar-chart-race-depending-on-country\n",
      "213 views\n",
      "11 module(s)\n",
      "13 characters\n",
      "https://kaggle.com/nishimoto/covid-19-what-is-risk\n",
      "204 views\n",
      "3 module(s)\n",
      "1635 characters\n",
      "https://kaggle.com/hongzhix/covid-19-searching-for-the-papers-about-vaccines\n",
      "192 views\n",
      "5 module(s)\n",
      "93 characters\n",
      "https://kaggle.com/tchainzzz/agglomerative-document-clustering-on-cord-19\n",
      "290 views\n",
      "18 module(s)\n",
      "3947 characters\n",
      "https://kaggle.com/mxfeinberg/using-whoosh-for-indexing-and-querying\n",
      "204 views\n",
      "11 module(s)\n",
      "1281 characters\n",
      "https://kaggle.com/nexussoftware/search-covid-19-papers-for-particular-information\n",
      "132 views\n",
      "11 module(s)\n",
      "16271 characters\n",
      "https://kaggle.com/mpwolke/weather-and-covid-19-outbreak\n",
      "642 views\n",
      "7 module(s)\n",
      "4106 characters\n",
      "https://kaggle.com/peronneaumoliere/keywords-extraction-and-text-clustering-covid-19\n",
      "38 views\n",
      "22 module(s)\n",
      "1376 characters\n",
      "https://kaggle.com/somertonman/covid-usa\n",
      "12 views\n",
      "22 module(s)\n",
      "3492 characters\n",
      "https://kaggle.com/dabrom55/abstracts-clustering-lda-nmf-scibert-embeddings\n",
      "302 views\n",
      "24 module(s)\n",
      "1045 characters\n",
      "https://kaggle.com/etonydev/abstract-summarization-with-transformers-bart\n",
      "143 views\n",
      "8 module(s)\n",
      "1341 characters\n",
      "https://kaggle.com/umar47/covid-19-mentioned-drugs-analysis-vol-3-0\n",
      "230 views\n",
      "20 module(s)\n",
      "1727 characters\n",
      "https://kaggle.com/nanar69m/question-answering-using-semantic-roles\n",
      "90 views\n",
      "5 module(s)\n",
      "63 characters\n",
      "https://kaggle.com/mlconsult/summary-page-virus-genetics-origin-and-evolution\n",
      "192 views\n",
      "6 module(s)\n",
      "3111 characters\n",
      "https://kaggle.com/janthiemen/elasticsearch-scibert-ensemble\n",
      "238 views\n",
      "20 module(s)\n",
      "4610 characters\n",
      "https://kaggle.com/aestheteaman01/covid-ran-research-analytics-notebook\n",
      "111 views\n",
      "27 module(s)\n",
      "6601 characters\n",
      "https://kaggle.com/mayukhdutta/insights-focus-and-experimental-findings\n",
      "87 views\n",
      "12 module(s)\n",
      "11679 characters\n",
      "https://kaggle.com/qiurui96/doxcompass-visualization-and-eda\n",
      "75 views\n",
      "60 module(s)\n",
      "639 characters\n",
      "https://kaggle.com/jitu38/covid-19-biomedical-semantic-search-q-a-system\n",
      "197 views\n",
      "60 module(s)\n",
      "557 characters\n",
      "https://kaggle.com/acmiyaguchi/cord-19-citation-network-with-deduping\n",
      "223 views\n",
      "14 module(s)\n",
      "5829 characters\n",
      "https://kaggle.com/cristianfat/cord-19-articles-clustering\n",
      "134 views\n",
      "20 module(s)\n",
      "1049 characters\n",
      "https://kaggle.com/rishav123/paper-and-lines-extractor\n",
      "91 views\n",
      "19 module(s)\n",
      "418 characters\n",
      "https://kaggle.com/bgoss541/training-set-labeling-jump-start-umls-linking\n",
      "151 views\n",
      "12 module(s)\n",
      "2531 characters\n",
      "https://kaggle.com/kicksomeasphalt/cord-19-disease-chemical-co-occurrence-matrix\n",
      "226 views\n",
      "15 module(s)\n",
      "928 characters\n",
      "https://kaggle.com/kranzfafka/covid-19-papers-text-summarization\n",
      "80 views\n",
      "0 module(s)\n",
      "1152 characters\n",
      "https://kaggle.com/finalepoch/medical-ner-using-spacy\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: timeout: Timed out receiving message from renderer: -387.502\n  (Session info: chrome=80.0.3987.149)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-0b2af7c6c827>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmeta_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'notebook_link'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: timeout: Timed out receiving message from renderer: -387.502\n  (Session info: chrome=80.0.3987.149)\n"
     ]
    }
   ],
   "source": [
    "views = []\n",
    "char_length = []\n",
    "packages = []\n",
    "for link in meta_df['notebook_link']:\n",
    "    print (link)\n",
    "    driver.get(link)\n",
    "    tree = html.fromstring(driver.page_source)\n",
    "    \n",
    "    #get views before switching to iframe\n",
    "    views_=tree.xpath('//*[@id=\"kernel-header-wrapper\"]/div[1]/span[1]/span[2]/span/span[2]/span')[0].text\n",
    "    views.append(views_)\n",
    "    print(f'{views_} views')\n",
    "    \n",
    "    #switch to iframe context\n",
    "    driver.switch_to.frame(driver.find_element_by_xpath('//*[@id=\"rendered-kernel-content\"]'))\n",
    "    tree = html.fromstring(driver.page_source)\n",
    "    \n",
    "    #unhide codeblocks\n",
    "    codeblocks = driver.find_elements_by_class_name('_kg_hide-input-true')\n",
    "    for to_unhide in codeblocks:\n",
    "        driver.execute_script(f\"arguments[0].className = '_kg_hide-input-false';\", to_unhide)\n",
    "    \n",
    "    #scrape imports\n",
    "    code = [each.text for each in driver.find_elements_by_class_name(\"input_area\") if 'import' in each.text]\n",
    "    modules = []\n",
    "    for block in code:\n",
    "        for each in block.split('\\n'):\n",
    "            tokens = each.split(' ')\n",
    "            if tokens[0] == 'import':\n",
    "                for package in re.sub(' ', '', each.split(' as ')[0].split('import')[1]).split(','):\n",
    "                    modules.append(package)\n",
    "            elif tokens[0] == 'from':\n",
    "                submodules = each.split('import')[1]\n",
    "                for sub in re.sub(' ', '', submodules).split(','):\n",
    "                    modules.append(tokens[1]+'.'+sub)\n",
    "    packages_= list(dict.fromkeys(modules))\n",
    "    packages.append(packages_)\n",
    "    print(f'{len(packages_)} module(s)')\n",
    "    text = tree.cssselect('strong')+tree.cssselect('p')+tree.cssselect('h1')+tree.cssselect('h2')+tree.cssselect('h3')\n",
    "    char_length_ = len(str([each.text for each in text]))\n",
    "    char_length.append(char_length_)\n",
    "    print(f'{char_length_} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', ' json, requests']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.split('\\n')[9].split('import')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.default_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [each for each in meta_df['notebook_link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Chrome(webdriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://kaggle.com/tarunpaparaju/covid-19-dataset-gaining-actionable-insights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://kaggle.com/dirktheeng/anserini-bert-squad-for-context-corpus-search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.kaggleusercontent.com/kf/30719380/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..7NF9JzxoE7s_r21dimn98w.Gt221Q7ef-MAFQMyIbx26MDv6G_lYzvJQgPTWF-YbNcqZQOMo3hJ6x_C6Y96DdrOSJkccIZ09mj8AFklRwAjRLj476eo3n_g-ceBJjgxPPB4ed1uby4ClV-fPz9qhPYbR5S4upIbzbNm2wngW8RFB8gjbry0e3AOLMBb3_YkZ22eTF-n8g8wDqt23PeUhxXoEyZz6ebsP39h901l-Af8NBtm4ZqJepUSNiYyiuLv7eAVZQxHCtY7tJoH_L77Yj1DAeBlV6bcfr4J6fMCNYH0mmTI9M68Cx_9DEGW1P4ytKG9eg1u1tv10to0-RhJwlilG2enpj0Jt2uVHO01jjBRrfPPSYSQG29I6gJPt9u-gNjseCigb9nAKCODcWMLNpDykttpn4839TzaxDHiDRqwjlUa0ma_Duta7AjhF3i-WzLc6WJw-7xAnThj9gQwRxzlRDJ9hOXCBQQQuhLL-H3fJ381bRuMHrZI9kFSnFiiP736m7JfKAkwF8w0fopka44iYUYyrsHwny2lxYYgBmsSRS38kmC9NCmyHv934EpQbtu-dQnw9jovXETEytFcviyNWr9VFDZlwiNBml3cNPWq2y80ZwGR9w_g5pSHQPpSSC6vlOuNeXSo-7IdpK6TdvOuMWp3nS_ZELlp5fdoKIFoRc6dksWOiYwYtYAXnWBdPoZzXLwnFtXJKYa3RD4JXtek.f2kzlMErsFSX-D5WbOqAwg/__results__.html'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_tag_name('iframe').get_attribute('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.frame(driver.find_element_by_xpath('//*[@id=\"rendered-kernel-content\"]'))\n",
    "codeblocks = driver.find_elements_by_class_name('_kg_hide-input-true')\n",
    "for to_unhide in codeblocks:\n",
    "    driver.execute_script(f\"arguments[0].className = '_kg_hide-input-false';\", to_unhide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeblocks = driver.find_elements_by_class_name('_kg_hide-input-true')\n",
    "for to_unhide in codeblocks:\n",
    "    driver.execute_script(f\"arguments[0].className = '_kg_hide-input-false';\", to_unhide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(f\"return document.getElementById('rendered-kernel-content')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict.fromkeys(['a', 'a', 'a', 'b']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Presenting the CORD19 Research Engine\\nAs the COVID-19 pandemic accelerates at frightening pace throughout the world's population, there is an urgent need for solutions or ideas on how to stop it. There are many thousands of research papers on diseases - specific to conronavirus or not; on epidemics and how to fight them; on information gathering and sharing. We hope that we can find among these research papers specific ideas, research or data that give use the ammunition to stop SARS-COV-2 as quickly as we can.\\nThis notebook presents a search engine that is built on top of the CORD-19 Research Dataset. It uses both the metadata.csv file and the research paper JSON files for its indexing source, and provides powerful yet simple tool ways to show results to users based on their queries. It is intended for any researcher - be it a nurse at a hospital in Bergamo, or a city planner in Brooklyn or casual data hunters looking for any information that can provide any help.\\nFinally, the search engine will be used as to mine the CORD Research Dataset for papers, information and data specific to each of the 10 official tasks.**\\nCode\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"notebook-container\"]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeblocks = driver.find_elements_by_class_name('_kg_hide-input-true')\n",
    "for to_unhide in codeblocks:\n",
    "    driver.execute_script(f\"arguments[0].className = '_kg_hide-input-false';\", to_unhide)\n",
    "code = [each.text for each in driver.find_elements_by_class_name(\"input_area\") if 'import' in each.text]\n",
    "modules = []\n",
    "for block in code:\n",
    "    for each in block.split('\\n'):\n",
    "        tokens = each.split(' ')\n",
    "        if tokens[0] == 'import':\n",
    "            for package in re.sub(' ', '', each.split(' as ')[0].split('import')[1]).split(','):\n",
    "                modules.append(package)\n",
    "        elif tokens[0] == 'from':\n",
    "            submodules = each.split('import')[1]\n",
    "            for sub in re.sub(' ', '', submodules).split(','):\n",
    "                modules.append(tokens[1]+'.'+sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [each.text for each in driver.find_elements_by_class_name(\"input_area\") if 'import' in each.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements_by_class_name(\"input_area\")[0].find_element_by_tag_name('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b72a504cc39f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://kaggle.com/tarunpaparaju/covid-19-dataset-gaining-actionable-insights\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             return self.request_encode_body(\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m             )\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    419\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "driver.get(\"https://kaggle.com/tarunpaparaju/covid-19-dataset-gaining-actionable-insights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pd.read_csv('notebook_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexd\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cleaned = feat[feat.packages != '[]'][feat.packages!=\"['']\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "for modules in cleaned['packages']:\n",
    "    for each in eval(modules):\n",
    "        if each not in unique:\n",
    "            unique.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_modules = {each:0 for each in unique}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modules in cleaned['packages']:\n",
    "    for each in eval(modules):\n",
    "        all_modules[each] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_values' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-fca40eaee8c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'dict_values' object does not support indexing"
     ]
    }
   ],
   "source": [
    "list(all_modules.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_modules = {k: v for k, v in sorted(all_modules.items(), key = lambda item: item[1],reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pandas': 415,\n",
       " 'numpy': 362,\n",
       " 'os': 281,\n",
       " 'json': 227,\n",
       " 'matplotlib.pyplot': 207,\n",
       " 're': 134,\n",
       " 'nltk.corpus.stopwords': 98,\n",
       " 'seaborn': 97,\n",
       " 'nltk': 86,\n",
       " 'spacy': 84,\n",
       " 'glob': 79,\n",
       " 'collections.Counter': 65,\n",
       " 'wordcloud.WordCloud': 62,\n",
       " 'tqdm.tqdm': 54,\n",
       " 'sklearn.feature_extraction.text.CountVectorizer': 52,\n",
       " 'warnings': 51,\n",
       " 'plotly.express': 49,\n",
       " 'sklearn.feature_extraction.text.TfidfVectorizer': 42,\n",
       " 'sys': 42,\n",
       " 'nltk.tokenize.word_tokenize': 42,\n",
       " 'gensim': 40,\n",
       " 'wordcloud.STOPWORDS': 39,\n",
       " 'nltk.stem.WordNetLemmatizer': 37,\n",
       " 'tqdm.notebook.tqdm': 37,\n",
       " 'IPython.core.display.HTML': 34,\n",
       " 'IPython.display.display': 34,\n",
       " 'string': 34,\n",
       " 'random': 34,\n",
       " 'sklearn.cluster.KMeans': 31,\n",
       " 'IPython.core.display.display': 31,\n",
       " 'time': 31,\n",
       " 'pprint.pprint': 26,\n",
       " 'pathlib.Path': 26,\n",
       " 'sklearn.decomposition.PCA': 25,\n",
       " 'pickle': 25,\n",
       " 'sklearn.manifold.TSNE': 24,\n",
       " 'ipywidgets.interact': 23,\n",
       " 'copy.deepcopy': 23,\n",
       " 'gensim.models.Word2Vec': 23,\n",
       " 'requests': 22,\n",
       " 'sklearn.decomposition.LatentDirichletAllocation': 22,\n",
       " 'networkx': 22,\n",
       " 'IPython.display.Image': 22,\n",
       " 'ipywidgets': 22,\n",
       " 'IPython.display.HTML': 21,\n",
       " 'sklearn.metrics.pairwise.cosine_similarity': 21,\n",
       " 'plotly.graph_objects': 21,\n",
       " 'nltk.corpus.wordnet': 21,\n",
       " 'sklearn.model_selection.train_test_split': 20,\n",
       " 'gc': 20,\n",
       " 'scispacy': 19,\n",
       " 'math': 18,\n",
       " 'folium': 16,\n",
       " 'tensorflow': 16,\n",
       " 'bokeh.plotting.figure': 16,\n",
       " 'IPython.display.Markdown': 16,\n",
       " 'collections.defaultdict': 16,\n",
       " 'matplotlib.pyplotasplt': 15,\n",
       " 'nltk.tokenize.sent_tokenize': 15,\n",
       " 'plotly.graph_objs': 15,\n",
       " 'sklearn.metrics': 14,\n",
       " 'nltk.stem.PorterStemmer': 14,\n",
       " 'gensim.corpora': 13,\n",
       " 'pyLDAvis': 13,\n",
       " 'plotly.offline': 13,\n",
       " 'datetime': 13,\n",
       " 'pyLDAvis.gensim': 12,\n",
       " 'bokeh.models.HoverTool': 12,\n",
       " 'bokeh.io.output_notebook': 12,\n",
       " 'nltk.stem.porter.PorterStemmer': 12,\n",
       " 'sklearn.cluster.MiniBatchKMeans': 12,\n",
       " 'wordcloud.ImageColorGenerator': 11,\n",
       " 'torch': 11,\n",
       " 'mpl_toolkits.mplot3d.Axes3D': 11,\n",
       " 'scipy': 11,\n",
       " 'spacy.displacy': 11,\n",
       " 'collections': 11,\n",
       " 'matplotlib': 11,\n",
       " 'bokeh.models.ColumnDataSource': 11,\n",
       " 'os.path': 11,\n",
       " 'plotly.offline.init_notebook_mode': 11,\n",
       " 'ast': 11,\n",
       " 'rank_bm25.BM25Okapi': 11,\n",
       " 'datetime.datetime': 10,\n",
       " 'multiprocessing': 10,\n",
       " 'logging': 10,\n",
       " 'functools': 10,\n",
       " 'plotly.subplots.make_subplots': 10,\n",
       " 'gensim.models': 10,\n",
       " 'search_func_py.*': 10,\n",
       " 'plotly.offline.iplot': 10,\n",
       " 'datetime.date': 9,\n",
       " 'itertools': 9,\n",
       " 'PIL.Image': 9,\n",
       " 'tqdm.auto.tqdm': 9,\n",
       " 'bokeh.io.output_file': 9,\n",
       " 'bokeh.io.show': 9,\n",
       " 'scipy.stats': 9,\n",
       " 'textblob.TextBlob': 9,\n",
       " 'matplotlib.cm': 9,\n",
       " 'operator': 9,\n",
       " 'pyLDAvis.sklearn': 9,\n",
       " 'spacy.lang.en.English': 9,\n",
       " 'matplotlib.style': 9,\n",
       " 'nltk.tokenize.RegexpTokenizer': 9,\n",
       " 'pathlib.PurePath': 9,\n",
       " 'requests.exceptions.HTTPError': 9,\n",
       " 'requests.exceptions.ConnectionError': 9,\n",
       " 'dateutil.parser': 9,\n",
       " 'pycountry': 8,\n",
       " 'plotly.figure_factory': 8,\n",
       " 'gensim.models.doc2vec.Doc2Vec': 8,\n",
       " 'gensim.models.doc2vec.TaggedDocument': 8,\n",
       " 'sklearn.feature_extraction.text': 8,\n",
       " 'glob.glob': 8,\n",
       " 'datetime.timedelta': 7,\n",
       " 'gensim.utils.simple_preprocess': 7,\n",
       " 'tqdm.tqdm_notebook': 7,\n",
       " 'bokeh.plotting.show': 7,\n",
       " 'string.punctuation': 7,\n",
       " 'sklearn.cluster.DBSCAN': 7,\n",
       " 'spacy.matcher.Matcher': 7,\n",
       " 'bokeh.models.LinearColorMapper': 7,\n",
       " 'bokeh.palettes.Category20': 7,\n",
       " 'bokeh.transform.linear_cmap': 7,\n",
       " 'bokeh.transform.transform': 7,\n",
       " 'umap': 7,\n",
       " 'scipy.sparse': 7,\n",
       " 'nltk.WordNetLemmatizer': 7,\n",
       " 'scipy.spatial.distance': 7,\n",
       " 'nltk.stem.wordnet.WordNetLemmatizer': 7,\n",
       " 'scispacy.abbreviation.AbbreviationDetector': 7,\n",
       " 'sklearn.feature_extraction.text.TfidfTransformer': 7,\n",
       " 'keras.layers.Dense': 6,\n",
       " 'tensorflow_hub': 6,\n",
       " 'sklearn.decomposition.TruncatedSVD': 6,\n",
       " 'sklearn.feature_extraction.text.HashingVectorizer': 6,\n",
       " 'nltk.PorterStemmer': 6,\n",
       " 'sklearn.linear_model.LinearRegression': 6,\n",
       " 'nltk.util.ngrams': 6,\n",
       " 'copy': 6,\n",
       " 'sklearn.ensemble.RandomForestClassifier': 6,\n",
       " 'sklearn.metrics.precision_score': 6,\n",
       " 'en_core_sci_md': 6,\n",
       " 'joblib': 6,\n",
       " 'sklearn.decomposition.NMF': 6,\n",
       " 'sklearn.preprocessing.StandardScaler': 6,\n",
       " 'pyspark.sql.SparkSession': 6,\n",
       " 'nltk.word_tokenize': 6,\n",
       " 'functools.reduce': 6,\n",
       " 'scispacy.umls_linking.UmlsEntityLinker': 6,\n",
       " 'typing.List': 6,\n",
       " 'typing.Tuple': 6,\n",
       " 'matplotlib.ticker': 5,\n",
       " 'keras.layers.Input': 5,\n",
       " 'sklearn.metrics.mean_absolute_error': 5,\n",
       " 'sklearn.preprocessing': 5,\n",
       " 'gensim.corpora.Dictionary': 5,\n",
       " 'csv': 5,\n",
       " 'cv2': 5,\n",
       " 'itertools.chain': 5,\n",
       " 'langdetect.detect': 5,\n",
       " 'multiprocessing.Pool': 5,\n",
       " 'sklearn.metrics.recall_score': 5,\n",
       " 'scipy.spatial.distance.jensenshannon': 5,\n",
       " 'ipywidgets.Layout': 5,\n",
       " 'IPython.display.clear_output': 5,\n",
       " 'plotly.offline.download_plotlyjs': 5,\n",
       " 'plotly.offline.plot': 5,\n",
       " 'collections.OrderedDict': 5,\n",
       " 'IPython.display.IFrame': 5,\n",
       " 'pprint': 5,\n",
       " 'gensim.models.CoherenceModel': 4,\n",
       " 'sklearn.pipeline.Pipeline': 4,\n",
       " 'sklearn.metrics.confusion_matrix': 4,\n",
       " 'matplotlib.colors': 4,\n",
       " 'gensim.summarization.summarizer.summarize': 4,\n",
       " 'transformers.BertTokenizer': 4,\n",
       " 'Bio.Entrez': 4,\n",
       " 'sklearn.metrics.silhouette_score': 4,\n",
       " 'sklearn.metrics.mean_squared_error': 4,\n",
       " 'plotly.tools': 4,\n",
       " 'sentence_transformers.SentenceTransformer': 4,\n",
       " 'en_ner_bc5cdr_md': 4,\n",
       " 'ipywidgets.interactive': 4,\n",
       " 'ipywidgets.fixed': 4,\n",
       " 'hashlib': 4,\n",
       " 'sklearn.model_selection.cross_val_score': 4,\n",
       " 'sklearn.model_selection.cross_val_predict': 4,\n",
       " 'bokeh.models.CustomJS': 4,\n",
       " 'bokeh.layouts.column': 4,\n",
       " 'bokeh.models.RadioButtonGroup': 4,\n",
       " 'bokeh.models.TextInput': 4,\n",
       " 'bokeh.layouts.gridplot': 4,\n",
       " 'bokeh.models.Div': 4,\n",
       " 'bokeh.models.Paragraph': 4,\n",
       " 'bokeh.layouts.widgetbox': 4,\n",
       " 'bokeh.plotting.output_notebook': 4,\n",
       " 'ipywidgets.VBox': 4,\n",
       " 'sklearn.utils.shuffle': 4,\n",
       " 'nltk.sentiment.vader.SentimentIntensityAnalyzer': 4,\n",
       " 'gensim.similarities': 4,\n",
       " 'plotly': 4,\n",
       " 'matplotlib.pyplot.figure': 4,\n",
       " 'spacy.lang.en.stop_words.STOP_WORDS': 4,\n",
       " 'en_core_sci_lg': 4,\n",
       " 'sklearn.neighbors.NearestNeighbors': 4,\n",
       " 'scipy.spatial.distance.cdist': 4,\n",
       " 'nltk.stem.LancasterStemmer': 4,\n",
       " 'stop_words.get_stop_words': 4,\n",
       " 'scipy.spatial': 4,\n",
       " 'nltk.stem.SnowballStemmer': 4,\n",
       " 'sklearn': 4,\n",
       " 'en_core_web_sm': 4,\n",
       " 'nltk.stem.snowball.SnowballStemmer': 4,\n",
       " 'typing.Dict': 4,\n",
       " 'spacy.tokenizer.Tokenizer': 4,\n",
       " 'ast.literal_eval': 4,\n",
       " 'en_core_sci_sm': 4,\n",
       " 'unidecode': 4,\n",
       " 'pycountry_convert': 3,\n",
       " 'scipy.interpolate.make_interp_spline': 3,\n",
       " 'scipy.interpolate.BSpline': 3,\n",
       " 'keras.layers.Activation': 3,\n",
       " 'keras.layers.LeakyReLU': 3,\n",
       " 'keras.models': 3,\n",
       " 'keras.optimizers.RMSprop': 3,\n",
       " 'keras.optimizers.Adam': 3,\n",
       " 'sklearn.metrics.accuracy_score': 3,\n",
       " 'sklearn.metrics.f1_score': 3,\n",
       " 'bokeh.plotting.output_file': 3,\n",
       " 'bokeh.models.Label': 3,\n",
       " 'Bio.Medline': 3,\n",
       " 'IPython.display.YouTubeVideo': 3,\n",
       " 'sklearn.model_selection.KFold': 3,\n",
       " 'lightgbm': 3,\n",
       " 'transformers.AutoTokenizer': 3,\n",
       " 'sklearn.decomposition': 3,\n",
       " 'ipywidgets.interact_manual': 3,\n",
       " 'sklearn.svm.SVR': 3,\n",
       " 'transformers.BertModel': 3,\n",
       " 'bokeh.models.CategoricalColorMapper': 3,\n",
       " 'bokeh.palettes.Spectral10': 3,\n",
       " 'bokeh.palettes.Category20c': 3,\n",
       " 'bokeh.palettes.magma': 3,\n",
       " 'IPython.utils.io': 3,\n",
       " 'ipywidgets.HBox': 3,\n",
       " 'os.path.isfile': 3,\n",
       " 'pandas.Timestamp': 3,\n",
       " 'urllib': 3,\n",
       " 'termcolor.colored': 3,\n",
       " 'spacy.tokens.Span': 3,\n",
       " 'pytextrank': 3,\n",
       " 'sklearn.preprocessing.MinMaxScaler': 3,\n",
       " 'spacy_langdetect.LanguageDetector': 3,\n",
       " 'sklearn.linear_model': 3,\n",
       " 'distance': 3,\n",
       " 'itertools.combinations': 3,\n",
       " 'argparse': 3,\n",
       " 'tensorflow.keras.layers.Dense': 3,\n",
       " 'tensorflow.keras.layers.Input': 3,\n",
       " 'tensorflow.keras.models.Model': 3,\n",
       " 'tensorflow.keras.optimizers.Adam': 3,\n",
       " 'subprocess': 3,\n",
       " 'bert_serving.client.BertClient': 3,\n",
       " 'gensim.models.FastText': 3,\n",
       " 'pyspark.sql.functionsasF': 3,\n",
       " 'pandas.plotting.register_matplotlib_converters': 3,\n",
       " 'gensim.parsing.preprocessing.STOPWORDS': 3,\n",
       " 'shutil': 3,\n",
       " 'gensim.models.ldamulticore.LdaMulticore': 3,\n",
       " 'os.walk': 3,\n",
       " 'nltk.probability.FreqDist': 3,\n",
       " 'spacy.pipeline.merge_entities': 3,\n",
       " 'io': 3,\n",
       " 'covid_19_utility_script.*': 3,\n",
       " 'branca': 2,\n",
       " 'cord.ResearchPapers': 2,\n",
       " 'concurrent.futures.ThreadPoolExecutor': 2,\n",
       " 'sklearn.metrics.classification_report': 2,\n",
       " 'bert.tokenization': 2,\n",
       " 'gensim.models.Doc2Vec': 2,\n",
       " 'tensorflow.keras': 2,\n",
       " 'cord19q.report.Report': 2,\n",
       " 'folium.plugins': 2,\n",
       " 'sklearn.preprocessing.PolynomialFeatures': 2,\n",
       " 'sklearn.base.BaseEstimator': 2,\n",
       " 'plotly.io': 2,\n",
       " 'xgboost': 2,\n",
       " 'calendar': 2,\n",
       " 'sklearn.datasets': 2,\n",
       " 'matplotlib.patches': 2,\n",
       " 'gensim.models.Phrases': 2,\n",
       " 'psutil': 2,\n",
       " 'sklearn.model_selection.RandomizedSearchCV': 2,\n",
       " 'covid19_tools': 2,\n",
       " 'ipywidgets.Box': 2,\n",
       " 'tqdm.notebook.trange': 2,\n",
       " 'io.StringIO': 2,\n",
       " 'spacy.matcher.PhraseMatcher': 2,\n",
       " 'faiss': 2,\n",
       " 'urllib.request.urlopen': 2,\n",
       " 'summa.summarizer.summarize': 2,\n",
       " 'summa.keywords.keywords': 2,\n",
       " 'gensim.parsing.preprocessing.remove_stopwords': 2,\n",
       " 'rake_nltk.Rake': 2,\n",
       " \"warnings#currentversionofseaborngeneratesabunchofwarningsthatwe'llignore\": 2,\n",
       " 'summarizer.Summarizer': 2,\n",
       " 'en_ner_bionlp13cg_md': 2,\n",
       " 're.finditer': 2,\n",
       " 'pylab.bone': 2,\n",
       " 'pylab.pcolor': 2,\n",
       " 'pylab.colorbar': 2,\n",
       " 'pylab.plot': 2,\n",
       " 'pylab.show': 2,\n",
       " 'pylab.rcParams': 2,\n",
       " 'pylab.savefig': 2,\n",
       " 'textstat': 2,\n",
       " 'statistics.*': 2,\n",
       " 'concurrent.futures': 2,\n",
       " 'rdflib': 2,\n",
       " 'functools.lru_cache': 2,\n",
       " 'top2vec.Top2Vec': 2,\n",
       " 'keras.models.Model': 2,\n",
       " 'keras.optimizers.SGD': 2,\n",
       " 'tqdm': 2,\n",
       " 'gzip': 2,\n",
       " 'fa2.ForceAtlas2': 2,\n",
       " 'sklearn.preprocessing.LabelEncoder': 2,\n",
       " 'altair': 2,\n",
       " 'tensorflow.keras.preprocessing.image.ImageDataGenerator': 2,\n",
       " 'tensorflow.keras.layers.Dropout': 2,\n",
       " 'tensorflow.keras.layers.Flatten': 2,\n",
       " 'corextopic.corextopicasct': 2,\n",
       " 'unicodedata': 2,\n",
       " 'uuid': 2,\n",
       " 'pyspark.sql.functions.lit': 2,\n",
       " 'pyspark.sql.types.(': 2,\n",
       " 'pyspark.sql.Window': 2,\n",
       " 'gensim.models.KeyedVectors': 2,\n",
       " 'sklearn.cluster.AgglomerativeClustering': 2,\n",
       " 'sklearn.feature_extraction': 2,\n",
       " 'sklearn.model_selection': 2,\n",
       " 'tqdm.tqdm_notebookastqdm': 2,\n",
       " \"pyLDAvis.gensim#don'tskipthis\": 2,\n",
       " 'nltk.pos_tag': 2,\n",
       " 'nltk.corpus.wordnetaswn': 2,\n",
       " 'tensorflow.keras.layers.BatchNormalization': 2,\n",
       " 'tensorflow.keras.layers.Activation': 2,\n",
       " 'tensorflow.keras.callbacks.ModelCheckpoint': 2,\n",
       " 'tensorflow.keras.callbacks.EarlyStopping': 2,\n",
       " 'IPython.display.Javascript': 2,\n",
       " 'gensim.models.phrases.Phrases': 2,\n",
       " 'gensim.models.phrases.Phraser': 2,\n",
       " 'fastai.vision.*': 2,\n",
       " 'pyspark.sql.functions.*': 2,\n",
       " 'keras': 2,\n",
       " 'keras.models.Sequential': 2,\n",
       " 'typing.Iterable': 2,\n",
       " 'transformers.pipeline': 2,\n",
       " 'textblob.Word': 2,\n",
       " 'sklearn.decomposition.LatentDirichletAllocationasLDA': 2,\n",
       " 'gensim.models.LdaModel': 2,\n",
       " 'gensim.models.LdaMulticore': 2,\n",
       " 'random.randint': 2,\n",
       " 'transformers.*': 2,\n",
       " 'nltk.sent_tokenize': 2,\n",
       " 'ipywidgets.interactive_output': 2,\n",
       " 'cdqa.utils.filters.filter_paragraphs': 2,\n",
       " 'cdqa.utils.download.download_model': 2,\n",
       " 'pyspark.ml.linalg.Vectors': 2,\n",
       " 'pyspark.ml.linalg.VectorUDT': 2,\n",
       " 'pyspark.sql.typesasT': 2,\n",
       " '__future__.print_function': 2,\n",
       " 'gensim.sklearn_api.phrases.PhrasesTransformer': 2,\n",
       " 'tensorflow.compat.v1': 2,\n",
       " 'google.cloud.storage': 2,\n",
       " 'google.cloud.bigquery': 2,\n",
       " 'nltk.stem.lancaster.LancasterStemmer': 2,\n",
       " 'bs4': 2,\n",
       " 'urllib.request': 2,\n",
       " 'bs4.BeautifulSoup': 2,\n",
       " 'PyPDF2': 2,\n",
       " 'datetime.datetimeasdt': 2,\n",
       " 'os.listdir': 2,\n",
       " 'os.path.join': 2,\n",
       " 'gensim.test.utils.common_texts': 2,\n",
       " 'fasttext': 2,\n",
       " 'glove.Corpus': 2,\n",
       " 'glove.Glove': 2,\n",
       " 'geopandas': 2,\n",
       " 'shapely.geometry.Point': 2,\n",
       " 'tika.parser': 2,\n",
       " 'scipy.optimize.curve_fit': 2,\n",
       " 'pandas.io.json.json_normalize': 2,\n",
       " 'nltk.data': 2,\n",
       " 'fastai.text.*': 2,\n",
       " 'unidecode.unidecode': 2,\n",
       " 'ipywidgets.widgets': 2,\n",
       " 'fbprophet.Prophet': 2,\n",
       " 'operator.itemgetter': 2,\n",
       " 'allennlp.predictors.predictor.Predictor': 2,\n",
       " 'ipywidgets.Image': 1,\n",
       " 'concurrent.futures.as_completed': 1,\n",
       " 'typing.Collection': 1,\n",
       " 'typing.Any': 1,\n",
       " 'functools.partial': 1,\n",
       " 'sklearn.naive_bayes.GaussianNB': 1,\n",
       " 'sklearn.naive_bayes.BernoulliNB': 1,\n",
       " 'sklearn.naive_bayes.MultinomialNB': 1,\n",
       " 'sklearn.model_selection.GridSearchCV': 1,\n",
       " 'bert': 1,\n",
       " 'bert.run_classifier': 1,\n",
       " 'bert.optimization': 1,\n",
       " 'bert.modeling': 1,\n",
       " 'matplotlib.patches.Rectangle': 1,\n",
       " 'matplotlib.ticker.FuncFormatter': 1,\n",
       " 'pyserini.search.pysearch': 1,\n",
       " 'transformers.BertForQuestionAnswering': 1,\n",
       " 'somoclu': 1,\n",
       " 'tensorflow.keras.preprocessing.text.Tokenizer': 1,\n",
       " 'tensorflow.keras.preprocessing.sequence.pad_sequences': 1,\n",
       " 'cord19q.etl.Etl': 1,\n",
       " 'cord19q.index.Index': 1,\n",
       " 'cord19q.highlights.Highlights': 1,\n",
       " 'cord19q.tokenizer.Tokenizer': 1,\n",
       " 'sqlite3': 1,\n",
       " 'cord19q.embeddings.Embeddings': 1,\n",
       " 'cord19q.query.Query': 1,\n",
       " 'plotly.graph_objs.*': 1,\n",
       " 'opencage.geocoder.OpenCageGeocode': 1,\n",
       " 'dask.dataframe': 1,\n",
       " 'hvplot.pandas': 1,\n",
       " 'holoviews': 1,\n",
       " 'sklearn.base.MetaEstimatorMixin': 1,\n",
       " 'sklearn.utils.metaestimators.if_delegate_has_method': 1,\n",
       " 'sklearn.datasets.load_files': 1,\n",
       " 'umap.UMAP': 1,\n",
       " 'gensim.sklearn_api.D2VTransformer': 1,\n",
       " 'gensim.sklearn_api.W2VTransformer': 1,\n",
       " 'kaggle_secrets.UserSecretsClient': 1,\n",
       " 'plotly.subplots': 1,\n",
       " 'catboost': 1,\n",
       " 'transformers.AutoModelWithLMHead': 1,\n",
       " 'sentence_transformers.models': 1,\n",
       " 'cleantext': 1,\n",
       " 'chembl_webresource_client.new_client.new_client': 1,\n",
       " 'rdkit': 1,\n",
       " 'rdkit.Chem': 1,\n",
       " 'rdkit.Chem.Draw': 1,\n",
       " 'py3Dmol#Amazinglibraryfor3Dvisualization': 1,\n",
       " 'rdkit.Chem.AllChem': 1,\n",
       " 'nltk.corpus.udhr': 1,\n",
       " 'urllib.parse.urlparse': 1,\n",
       " 'enchant': 1,\n",
       " 'weighted_levenshtein.lev': 1,\n",
       " 'weighted_levenshtein.osa': 1,\n",
       " 'weighted_levenshtein.dam_lev': 1,\n",
       " 'Levenshtein': 1,\n",
       " 'country_converter': 1,\n",
       " 'html': 1,\n",
       " 'bm25_index.BM25Index': 1,\n",
       " 'gensim.matutils': 1,\n",
       " 'sklearn.metrics.pairwise.cosine_distances': 1,\n",
       " 'sklearn.metrics.pairwise.manhattan_distances': 1,\n",
       " 'spacy#needstoupdatespacytoloadSciSpacymodel.': 1,\n",
       " 'transformers': 1,\n",
       " 'xml.etree.ElementTree': 1,\n",
       " 'colorama.Fore': 1,\n",
       " 'RAKE': 1,\n",
       " 'numpy.random.seed': 1,\n",
       " 'numpy.random.randint': 1,\n",
       " 'pandas.plotting.parallel_coordinates': 1,\n",
       " 'cord19q.models.Models': 1,\n",
       " '.OrderedDict': 1,\n",
       " 'medacy.model.model.Model': 1,\n",
       " 'en_core_med7_lg': 1,\n",
       " 'chart_studio.plotly': 1,\n",
       " 'heapq.nlargest': 1,\n",
       " 'scipy.sparse.csr.csr_matrix#needthisifyouwanttosavetfidf_matrix': 1,\n",
       " 'graph.KnowledgeGraph': 1,\n",
       " 'graph.Vertex': 1,\n",
       " 'walkers.RandomWalker': 1,\n",
       " 'rdf2vec.RDF2VecTransformer': 1,\n",
       " 'heapq': 1,\n",
       " 'scipy.stats.entropy': 1,\n",
       " 'hashlib.md5': 1,\n",
       " 'sklearn.base.ClassifierMixin': 1,\n",
       " 'sklearn.base.TransformerMixin': 1,\n",
       " 'joblib.Parallel': 1,\n",
       " 'joblib.delayed': 1,\n",
       " 'multiprocessing.pool.ThreadPool': 1,\n",
       " 'IPython.display.FileLink': 1,\n",
       " 'ktrain': 1,\n",
       " 'json##CODETOPRINTAJSONFILETOCHECKITSSTRUCTURE': 1,\n",
       " 'IPython.display.Latex': 1,\n",
       " 'keras.preprocessing.text.Tokenizer': 1,\n",
       " 'keras.preprocessing.sequence.pad_sequences': 1,\n",
       " 'time.time': 1,\n",
       " 'keras.backend': 1,\n",
       " 'keras.engine.topology.Layer': 1,\n",
       " 'keras.engine.topology.InputSpec': 1,\n",
       " 'keras.layers.Embedding': 1,\n",
       " 'keras.callbacks': 1,\n",
       " 'keras.initializers.VarianceScaling': 1,\n",
       " 'keras.utils.plot_model': 1,\n",
       " 'gensim.models.word2vec.Word2Vec': 1,\n",
       " 'pke.base.LoadFile': 1,\n",
       " 'pke.unsupervised.KPMiner': 1,\n",
       " 'pke.load_document_frequency_file': 1,\n",
       " 'networkx.algorithms.community.label_propagation_communities': 1,\n",
       " 'pyvis.network.Network': 1,\n",
       " 'flashtext.KeywordProcessor': 1,\n",
       " 'sklearn.svm.NuSVR': 1,\n",
       " 'catboost.CatBoostRegressor': 1,\n",
       " 'sklearn.model_selection.StratifiedKFold': 1,\n",
       " 'sklearn.model_selection.RepeatedKFold': 1,\n",
       " 'numba.jit': 1,\n",
       " 'catboost.CatBoostClassifier': 1,\n",
       " 'itertools.product': 1,\n",
       " 'altair.vega.v5': 1,\n",
       " 'yellowbrick.cluster.KElbowVisualizer': 1,\n",
       " 'keras.preprocessing.image.ImageDataGenerator': 1,\n",
       " 'keras.preprocessing.image.img_to_array': 1,\n",
       " 'keras.preprocessing.image.load_img': 1,\n",
       " 'imutils.paths': 1,\n",
       " 'tensorflow.keras.applications.VGG16': 1,\n",
       " 'tensorflow.keras.layers.AveragePooling2D': 1,\n",
       " 'tensorflow.keras.utils.to_categorical': 1,\n",
       " 'sklearn.preprocessing.LabelBinarizer': 1,\n",
       " 'ipywidgets.widgets#thisiswhatmakesthedataframeinteractive': 1,\n",
       " 'multiprocessing.cpu_count': 1,\n",
       " 'gensim.downloader': 1,\n",
       " 'altmetric.Altmetric': 1,\n",
       " 'sklearn.neighbors.nearest_centroid.NearestCentroid': 1,\n",
       " '': 1,\n",
       " 'tempfile': 1,\n",
       " 'matplotlib.mlab': 1,\n",
       " 'Levenshtein.ratioaslevenshtein_distance': 1,\n",
       " 'tqdm.notebook': 1,\n",
       " 'os#operatingsystem': 1,\n",
       " 'time.sleep': 1,\n",
       " 'sklearn.metrics.pairwise.linear_kernel': 1,\n",
       " 'sklearn.feature_extraction.text.CountVectorizerasBoW': 1,\n",
       " 'sklearn.feature_extraction.text.TfidfVectorizerasTF_IDF': 1,\n",
       " 'sklearn.linear_model.LogisticRegressionasLR': 1,\n",
       " 'sklearn.svm.SVC': 1,\n",
       " 'scipy.spatial.distance.cosineasdist': 1,\n",
       " 'tensorflow.keras.models.Sequential': 1,\n",
       " 'tensorflow.keras.layers.Conv2D': 1,\n",
       " 'tensorflow.keras.layers.SeparableConv2D': 1,\n",
       " 'tensorflow.keras.layers.MaxPool2D': 1,\n",
       " 'tensorflow.keras.layers.LeakyReLU': 1,\n",
       " 'tensorflow.keras.callbacks.ReduceLROnPlateau': 1,\n",
       " 'pandas_datareader.wb': 1,\n",
       " 'IPython.display.set_matplotlib_formats': 1,\n",
       " 'fastai.*': 1,\n",
       " 'IPython': 1,\n",
       " 'pyspark.SparkContext': 1,\n",
       " 'sklearn.metrics.r2_score': 1,\n",
       " 'pronouncing': 1,\n",
       " 'markovify': 1,\n",
       " 'keras.layers.LSTM': 1,\n",
       " 'keras.layers.core.Dense': 1,\n",
       " 'biobert_embedding.embedding.BiobertEmbedding': 1,\n",
       " 'nltk.FreqDist': 1,\n",
       " '.v5': 1,\n",
       " 'matplotlib.animation': 1,\n",
       " 'colorsys': 1,\n",
       " 'scipy.cluster.hierarchy.ward': 1,\n",
       " 'scipy.cluster.hierarchy.dendrogram': 1,\n",
       " 'scipy.cluster.hierarchy.fcluster': 1,\n",
       " 'scipy.cluster.hierarchy.single': 1,\n",
       " 'scipy.cluster.hierarchy.complete': 1,\n",
       " 'whoosh.index.create_in': 1,\n",
       " 'whoosh.fields.*': 1,\n",
       " 'whoosh.qparser.QueryParser': 1,\n",
       " 'whoosh.query.*': 1,\n",
       " 'IPython.display.Video': 1,\n",
       " 'scipy.sparse.coo_matrix': 1,\n",
       " 'tqdm.notebook.tqdm_notebook': 1,\n",
       " 'tabulate.tabulate': 1,\n",
       " 'glob#Retrievethefile/pathname': 1,\n",
       " 're#Regular-Expressiontofetchdatafromtext': 1,\n",
       " 'json#ReadingtheJSONDocuments': 1,\n",
       " 'string#Fordoingstringoperations': 1,\n",
       " 'sklearn.feature_extraction.text.HashingVectorizer#PerformingHashingVectorization': 1,\n",
       " 'sklearn.feature_extraction.text.TfidfVectorizer#Tfidfvectorfortextanalysis': 1,\n",
       " 'sklearn.model_selection.train_test_split#Fortrain-test-splitforthedataset': 1,\n",
       " 'sklearn.ensemble.RandomForestClassifier#Random-forest-classifier': 1,\n",
       " 'sklearn.neighbors.KNeighborsClassifier#KNNClassifier': 1,\n",
       " 'sklearn.svm#SupportVectorMachineclassifier': 1,\n",
       " 'sklearn.metrics#Moduletocheckthemodelaccuracy': 1,\n",
       " 'keras.layers.Dropout': 1,\n",
       " 'sklearn.svm': 1,\n",
       " 'sklearn.neighbors.KNeighborsClassifier': 1,\n",
       " 'matplotlib.image': 1,\n",
       " 'sklearn.metrics.pairwise': 1,\n",
       " 'scipy.sparse.hstack': 1,\n",
       " 'random.shuffle': 1,\n",
       " 'sklearn.manifold.Isomap': 1,\n",
       " 'sklearn.manifold.MDS': 1,\n",
       " 'sklearn.manifold.SpectralEmbedding': 1,\n",
       " 'sklearn.pipeline.FeatureUnion': 1,\n",
       " 'gensim.models.word2vec.LineSentence': 1,\n",
       " 'gensim.corpora.MmCorpus': 1,\n",
       " 'igraph.Graph': 1,\n",
       " 'igraph.plot': 1,\n",
       " 'bokeh.models.widgets.Slider': 1,\n",
       " 'bokeh.models.widgets.Dropdown': 1,\n",
       " 'bokeh.layouts.row': 1,\n",
       " 'tqdm.tnrange': 1,\n",
       " 'notebook': 1,\n",
       " 'IPython.html.widgets': 1,\n",
       " 'en_core_web_md': 1,\n",
       " 'flair.embeddings.ELMoEmbeddings': 1,\n",
       " 'flair.embeddings.PooledFlairEmbeddings': 1,\n",
       " 'flair.embeddings.Sentence': 1,\n",
       " 'flair.embeddings.DocumentPoolEmbeddings': 1,\n",
       " 'cdqa.pipeline.QAPipeline': 1,\n",
       " 'pyhash': 1,\n",
       " 'pyspark.ml.feature.MinHashLSH': 1,\n",
       " 'igraph': 1,\n",
       " 'statistics.mean': 1,\n",
       " 'plotly_express': 1,\n",
       " 'MulticoreTSNE.MulticoreTSNEasTSNE': 1,\n",
       " '__future__.unicode_literals': 1,\n",
       " 'spacy.util.minibatch': 1,\n",
       " 'spacy.util.compounding': 1,\n",
       " 'transformers.BertConfig': 1,\n",
       " 'transformers.BertForPreTraining': 1,\n",
       " 'transformers.load_tf_weights_in_bert': 1,\n",
       " 'pyLDAvis.enable_notebook': 1,\n",
       " 'pyLDAvis.display': 1,\n",
       " 'cdqa.utils.download.download_bnpp_data': 1,\n",
       " 'cdqa.pipeline.cdqa_sklearn.QAPipeline': 1,\n",
       " 'cdqa.utils.converters.generate_squad_examples': 1,\n",
       " 'vaderSentiment.vaderSentiment.SentimentIntensityAnalyzer': 1,\n",
       " 'gensim.models.keyedvectors': 1,\n",
       " 'annoy.AnnoyIndex': 1,\n",
       " 'typing.NoReturn': 1,\n",
       " 'typing.Union': 1,\n",
       " 'typing.Optional': 1,\n",
       " 'typing.Text': 1,\n",
       " 'typing.Generic': 1,\n",
       " 'typing.Callable': 1,\n",
       " 'gensim.summarization.bm25.BM25': 1,\n",
       " 'subprocess.check_output': 1,\n",
       " 'matplotlib.font_manager.weight_dict': 1,\n",
       " 'pandas_profiling.ProfileReport': 1,\n",
       " 'InferSent.models.InferSent': 1,\n",
       " 'umap.umap_': 1,\n",
       " 'hdbscan': 1,\n",
       " 'stat': 1,\n",
       " 'nltk.tokenize.sent_tokenize#': 1,\n",
       " 'corextopic.vis_topicasvt#jupyternotebookswillcomplainmatplotlibisbeingloadedtwice': 1,\n",
       " 'tflearn': 1,\n",
       " 'whoosh.fields.Schema': 1,\n",
       " 'whoosh.fields.TEXT': 1,\n",
       " 'whoosh.fields.ID': 1,\n",
       " 'whoosh.index': 1,\n",
       " 'bokeh.io.push_notebook': 1,\n",
       " 'bokeh.io.save': 1,\n",
       " 'bokeh.models.DatetimeTickFormatter': 1,\n",
       " 'bokeh.models.NumeralTickFormatter': 1,\n",
       " 'bokeh.palettes.Set1_9aspalette': 1,\n",
       " 'ipywidgets.IntSlider': 1,\n",
       " 'matplotlib.ticker.PercentFormatter': 1,\n",
       " 'nltk.tokenize.WordPunctTokenizer': 1,\n",
       " 'pathlib.Path#python3way': 1,\n",
       " 'p_tqdm.p_map': 1,\n",
       " 'dateparser.search.search_dates': 1,\n",
       " 'pandarallel.pandarallel': 1,\n",
       " 'gensim.test.utils.get_tmpfile': 1,\n",
       " 'time.time#Totimeouroperations': 1,\n",
       " 'sklearn.feature_extraction.text.TfidfVectorizer#tf-idfisacommonwayofturningatextintoavectoroftermfrequencies.Textsthataresemanticallyclosewillbecloseinthis(high-dimensional)space': 1,\n",
       " 'sklearn.manifold.TSNE#t-SNEisadimensionalityreductiontoolwhichisoptimizedtopreservedistances': 1,\n",
       " 'sklearn.manifold.i.e.pointsthatarecloseinthehigh-dimensionalspaceshouldbecloseinthelow-dimensionalspaceandviceversa': 1,\n",
       " 'sklearn.cluster.DBSCAN#densitybasedclusteringmethod.Itgroupstogetherpointsthatarecloselypackedtogether(pointswithmanynearbyneighbors)': 1,\n",
       " 'sklearn.cluster.markingasoutlierspointsthatliealoneinlow-densityregions(source:Wikipedia)': 1,\n",
       " 'wordcloud.ImageColorGenerator#fordrawingwordcloudsandalsosettingstopwordsforvectorization': 1,\n",
       " 'calmap': 1,\n",
       " 'shapely.geometry.Polygon': 1,\n",
       " 'IPython.core.interactiveshell.InteractiveShell': 1,\n",
       " 'pyspark.sql.types.*': 1,\n",
       " 'pyspark.sql.functions': 1,\n",
       " 'sklearn.feature_extraction.text.HashingVectorizer#Vectorizorforthewordsintheabstract': 1,\n",
       " 'sklearn.feature_extraction.text.TfidfVectorizer#Vectorizorforthetextintheabstract(tf-idf)': 1,\n",
       " 'scipy.optimize.minimize': 1,\n",
       " 'scipy.optimize.differential_evolution': 1,\n",
       " 'jinja2.Template': 1,\n",
       " 'getpass': 1,\n",
       " 'igraph.*': 1,\n",
       " \"nltk;nltk.download('stopwords')\": 1,\n",
       " 'protlearn': 1,\n",
       " 'tabula': 1,\n",
       " 'camelot': 1,\n",
       " 'fasttext.util': 1,\n",
       " 'keras.preprocessing.text': 1,\n",
       " 'nltk.cluster.KMeansClusterer': 1,\n",
       " 'sklearn.cluster.OPTICS': 1,\n",
       " 'mrcnn.utils': 1,\n",
       " 'mrcnn.visualize': 1,\n",
       " 'mrcnn.visualize.display_images': 1,\n",
       " 'mrcnn.model': 1,\n",
       " 'mrcnn.model.log': 1,\n",
       " 'nucleus': 1,\n",
       " 'typing.Pattern': 1,\n",
       " 'dill': 1,\n",
       " 'transformers.AutoModelForQuestionAnswering': 1,\n",
       " 'regex': 1,\n",
       " 'nltk.stem.RegexpStemmer': 1,\n",
       " 'spacy.lemmatizer.Lemmatizer': 1,\n",
       " 'spacy.lookups.Lookups': 1,\n",
       " 'mpld3': 1,\n",
       " 'pylab': 1,\n",
       " 'numpy.arange': 1,\n",
       " 'nltk.ngrams': 1,\n",
       " 'collections.*': 1,\n",
       " 'cotools': 1,\n",
       " 'cotools.text': 1,\n",
       " 'cotools.texts': 1,\n",
       " 'cotools.abstract': 1,\n",
       " 'cotools.abstracts': 1,\n",
       " 'collections.namedtuple': 1,\n",
       " 'dataclasses.dataclass': 1,\n",
       " 'support_funs_incubation.stopifnot': 1,\n",
       " 'support_funs_incubation.uwords': 1,\n",
       " 'support_funs_incubation.idx_find': 1,\n",
       " 'support_funs_incubation.find_beside': 1,\n",
       " 'support_funs_incubation.ljoin': 1,\n",
       " 'support_funs_incubation.sentence_find': 1,\n",
       " 'support_funs_incubation.record_vals': 1,\n",
       " 'colors.red': 1,\n",
       " 'colors.black': 1,\n",
       " 'colors.white#ansicolors': 1,\n",
       " 'abc.ABC': 1,\n",
       " 'abc.abstractmethod': 1,\n",
       " 'pprint.pprint#fordebugging': 1,\n",
       " 'tensorflow.keras.preprocessing.text.text_to_word_sequence': 1,\n",
       " 'tensorflow.keras.layers': 1,\n",
       " 'folium#tocreatemaps': 1,\n",
       " 'scipy.spatial.distance.cosine': 1,\n",
       " 'IPython.core.display.Image': 1,\n",
       " 'rank_bm25.BM25L': 1,\n",
       " 'range_key_dict.RangeKeyDict': 1,\n",
       " 'faiss.write_index': 1,\n",
       " 'sacremoses.MosesDetokenizer': 1,\n",
       " 'math.sqrt': 1,\n",
       " 'sklearn.preprocessing.MultiLabelBinarizer': 1,\n",
       " 'googletrans.Translator': 1,\n",
       " 'crossref.restful.Works': 1,\n",
       " 'adjustText.adjust_text': 1,\n",
       " 'sklearn.mixture': 1,\n",
       " 'langdetect.DetectorFactory': 1,\n",
       " 'sklearn.linear_model.BayesianRidge': 1,\n",
       " 'mplleaflet': 1,\n",
       " 'bokeh.tile_providers.STAMEN_TONER': 1,\n",
       " 'bokeh.plotting.ColumnDataSource': 1,\n",
       " 'datashader': 1,\n",
       " 'datashader.colors.viridis': 1,\n",
       " 'datashader.transfer_functionsastf': 1,\n",
       " 'transformers.AutoModel': 1,\n",
       " 'jsonschema': 1,\n",
       " 'nltk.tokenize.TreebankWordTokenizer': 1,\n",
       " 'sklearn.feature_extraction.text.ENGLISH_STOP_WORDSassklearn_stop_words': 1,\n",
       " 'scattertext': 1,\n",
       " 'scattertext.CorpusFromPandas': 1,\n",
       " 'scattertext.produce_scattertext_explorer': 1,\n",
       " 'textblob.Blobber': 1,\n",
       " 'textblob.classifiers.NaiveBayesClassifier': 1,\n",
       " 'textblob.taggers.NLTKTagger': 1,\n",
       " 'statsmodels.api': 1,\n",
       " 'nltk.corpus.comparative_sentences': 1,\n",
       " 'swifter': 1,\n",
       " 'spacy.tokens.DocBin': 1,\n",
       " 'spacy.tokens.Doc': 1,\n",
       " 'gensim.summarization.summarize': 1,\n",
       " 'gensim.summarization.summarize_corpus': 1,\n",
       " 'pathlib': 1,\n",
       " 'qgrid': 1,\n",
       " 'pke': 1,\n",
       " 'itertools.permutations': 1,\n",
       " 'sklearn;': 1,\n",
       " 'sys;': 1,\n",
       " 'nltk.corpus.stopwords;': 1,\n",
       " 'nltk;': 1,\n",
       " 'gensim.models.ldamodel': 1,\n",
       " 'gensim.corpora;': 1,\n",
       " 'sklearn.feature_extraction.text.TfidfTransformer;': 1,\n",
       " 'sklearn.decomposition.NMF;': 1,\n",
       " 'sklearn.preprocessing.normalize;': 1,\n",
       " 'pickle;': 1,\n",
       " 'umap.plot': 1,\n",
       " 'faiss.read_index': 1,\n",
       " 'ipywidgets.Dropdown': 1,\n",
       " 'ipywidgets.Label': 1,\n",
       " 'ipywidgets.HTMLaswidgetHTML': 1,\n",
       " 'gensim.models.coherencemodel.CoherenceModel': 1,\n",
       " 'language_detector.detect_language': 1,\n",
       " 'pkg_resources': 1,\n",
       " 'symspellpy.SymSpell': 1,\n",
       " 'symspellpy.Verbosity': 1,\n",
       " 'vec2graph.visualize': 1,\n",
       " 'html.parser.HTMLParser': 1,\n",
       " 'html2text': 1,\n",
       " 'joblib.dump': 1,\n",
       " 'joblib.load': 1,\n",
       " 'keras.preprocessing.text.hashing_trick': 1,\n",
       " 'keras.utils.to_categorical': 1,\n",
       " 'nltk.tokenize.ToktokTokenizer': 1,\n",
       " 'tensorflow.keras.layers.Embedding': 1,\n",
       " 'tensorflow.keras.layers.Lambda': 1,\n",
       " 'tensorflow.keras.layers.Dot': 1,\n",
       " 'tensorflow.keras.activations.tanh': 1,\n",
       " 'tensorflow.keras.activations.sigmoid': 1,\n",
       " 'tensorflow.keras.backend': 1,\n",
       " 'scipy.spatial.cKDTree': 1}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file(\"modules.html\")\n",
    "p = figure(x_range= list(all_modules.keys()), plot_height = 2000, plot_width = 10000, title = \"Modules Used for Covid-19 Data Analysis\", toolbar_location=None, tools=\"\")\n",
    "p.vbar(x=list(all_modules.keys()), top=list(all_modules.values()), width=0.5)\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "p.xaxis.major_label_orientation = \"vertical\"\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
